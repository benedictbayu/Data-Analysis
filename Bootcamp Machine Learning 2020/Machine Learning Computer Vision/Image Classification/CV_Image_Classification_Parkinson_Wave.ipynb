{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV Image Classification Parkinson Wave.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9jS_LtkG5I1",
        "colab_type": "text"
      },
      "source": [
        "# **Parkinson Detection using Image Classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T54bAX6lUk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage import feature\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2 as cv\n",
        "import pandas as pd\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NBjurCdltlL",
        "colab_type": "text"
      },
      "source": [
        "### **Metode Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exgKu3bWliL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(image, image_size=128):\n",
        "  image = cv.cvtColor(image, cv.COLOR_BGR2GRAY) #Ubah menjadi greyscale\n",
        "  image = cv.resize(image, (image_size, image_size)) #resize gambar menjadi suatu ukuran (default = 128)\n",
        "\n",
        "  image = cv.threshold(image, 0, 255, cv.THRESH_BINARY_INV | cv.THRESH_OTSU)[1] #melakukan thresholding dan mengambil gambar hasil thresholding\n",
        "\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aBDmxeZmgRO",
        "colab_type": "text"
      },
      "source": [
        "### **Feature Extraction**\n",
        "\n",
        "Mengekstrak feature dari gambar dengan image descriptor\n",
        "\n",
        "1. Histogram of Oriented Gradients (HOG)\n",
        "2. Local Binary Pattern (LBP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv0pJgrtme6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# From: https://www.pyimagesearch.com/2019/04/29/detecting-parkinsons-disease-with-opencv-computer-vision-and-the-spiral-wave-test/\n",
        "def quantify_image_hog(image): #HOG Features\n",
        "  features = feature.hog(image, orientations=9, pixels_per_cell=(10, 10), cells_per_block=(2, 2), transform_sqrt=True, block_norm='L1')\n",
        "\n",
        "  return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAhLwJIPnqG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# From: https://www.pyimagesearch.com/2015/12/07/local-binary-patterns-with-python-opencv/\n",
        "def quantify_image_lbp(image):\n",
        "  features = feature.local_binary_pattern(image, 24, 8, method='uniform')\n",
        "  \n",
        "  (hist, _) = np.histogram(features.flatten(), bins=np.arange(0, 26), range=(0, 26))\n",
        "\n",
        "  hist = hist.astype('float')\n",
        "  hist /= (hist.sum() + 1e-7)\n",
        "\n",
        "  return hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKpQo2OVpOOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing image\n",
        "\n",
        "image_test = cv.imread('drive/My Drive/Colab Test (Bootcamp ML 2020)/parkinsons/wave/training/parkinson/V01PO02.png')\n",
        "\n",
        "image_test_preprocessed = preprocess(image_test, image_size=128)\n",
        "\n",
        "cv2_imshow(image_test)\n",
        "cv2_imshow(image_test_preprocessed)\n",
        "\n",
        "features_hog = quantify_image_hog(image_test_preprocessed)\n",
        "features_lbp = quantify_image_lbp(image_test_preprocessed)\n",
        "\n",
        "print('HOG')\n",
        "print(features_hog, len(features_hog))\n",
        "print('LBP')\n",
        "print(features_lbp, len(features_lbp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkN5tXvFqUOu",
        "colab_type": "text"
      },
      "source": [
        "### **Split Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_vY7dVSqK4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_split(path, image_size=200, extraction_method='hog'):\n",
        "  image_paths = list(paths.list_images(path))\n",
        "  data = []\n",
        "  labels = []\n",
        "\n",
        "  for image_path in image_paths:\n",
        "    label = image_path.split(os.path.sep)[-2]\n",
        "\n",
        "    image = cv.imread(image_path)\n",
        "    image = preprocess(image, image_size=image_size)\n",
        "\n",
        "    if extraction_method == 'hog':\n",
        "      features = quantify_image_hog(image)\n",
        "    elif extraction_method == 'lbp':\n",
        "      features = quantify_image_lbp(image)\n",
        "\n",
        "    data.append(features)\n",
        "    labels.append(label)\n",
        "\n",
        "  return (np.array(data), np.array(labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEvZOQBzsAfU",
        "colab_type": "text"
      },
      "source": [
        "### **Load Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPTWDhCIr_ig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_dir = 'drive/My Drive/Colab Test (Bootcamp ML 2020)/parkinsons/wave'\n",
        "\n",
        "training_path = os.path.join(dataset_dir, 'training')\n",
        "testing_path = os.path.join(dataset_dir, 'testing')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0b3ULnZs7KC",
        "colab_type": "text"
      },
      "source": [
        "## **HOG dengan Image Size 128**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPEs0GsIs42i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#HOG 128\n",
        "resize_image_size_128 = 128\n",
        "extraction_method = 'hog'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO-dDwyathJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train) = load_split(training_path, image_size=resize_image_size_128, extraction_method=extraction_method)\n",
        "(X_test, y_test) = load_split(testing_path, image_size=resize_image_size_128, extraction_method=extraction_method)\n",
        "\n",
        "print('Data berhasil diupload!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw7upbvhuU1h",
        "colab_type": "text"
      },
      "source": [
        "**Label Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FzkvzcOt9uv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdO6SwTlukuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kscNmNJuluA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loOhqvBrummk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-np6F1lv8UF",
        "colab_type": "text"
      },
      "source": [
        "**Machine Learning Model**\n",
        "\n",
        "**1. LinearSVC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7YEya7Iv5qT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "lin_svc = LinearSVC()\n",
        "lin_svc.get_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyJVk8JOfNcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C = [int(x) for x in np.linspace(0, 50, 25)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayJJFqjRfZVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linsvc_grid = {'C' : C}\n",
        "\n",
        "print(linsvc_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kixErAIfN3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linsvc = LinearSVC()\n",
        "linsvc_random = RandomizedSearchCV(estimator=linsvc, param_distributions=linsvc_grid, n_iter=100, cv=3, verbose=2, random_state=10, n_jobs=-1)\n",
        "linsvc_random.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLpLnI08fefs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linsvc_random.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XaXU4NxxkJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lin_svc = LinearSVC(C=2)\n",
        "lin_svc.fit(X_train, y_train)\n",
        "prediksi_lin_svc_test = lin_svc.predict(X_test)\n",
        "cm = confusion_matrix(y_test, prediksi_lin_svc_test)\n",
        "cr = classification_report(y_test, prediksi_lin_svc_test)\n",
        "print('Nilai akurasi LinearSVC pada testing data adalah {:.3f}'.format(lin_svc.score(X_test, y_test)))\n",
        "print('Nilai F1 Score LinearSVC pada testing data adalah {:.3f}'.format(f1_score(y_test, prediksi_lin_svc_test, average='macro')))\n",
        "print('Nilai Precision Score LinearSVC pada testing data adalah {:.3f}'.format(precision_score(y_test, prediksi_lin_svc_test, average='macro')))\n",
        "print('Nilai Recall Score LinearSVC pada testing data adalah {:.3f}'.format(recall_score(y_test, prediksi_lin_svc_test, average='macro')))\n",
        "print()\n",
        "print(cr)\n",
        "print(cm)\n",
        "print('==================================================================================================================================================================')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHyvSniB2f_i",
        "colab_type": "text"
      },
      "source": [
        "**2. Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srKALpsT0Ii3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.get_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk4E8vXDf5GV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "penalty = ['l1', 'l2']\n",
        "C = np.logspace(-4,4,20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqdEA2i-20tt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg_grid = {'penalty' : penalty,\n",
        "               'C' : C}\n",
        "\n",
        "print(logreg_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loqrTt0HgY-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg = LogisticRegression()\n",
        "log_random = RandomizedSearchCV(estimator=logreg, param_distributions=logreg_grid, n_iter=100, cv=3, verbose=2, random_state=10, n_jobs=-1)\n",
        "log_random.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXa4WNAAglfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_random.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-eG1RbUglSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg = LogisticRegression(C=1438.44988828766, penalty='l2')\n",
        "logreg.fit(X_train, y_train)\n",
        "prediksi_logreg = logreg.predict(X_test)\n",
        "cm = confusion_matrix(y_test, prediksi_logreg)\n",
        "cr = classification_report(y_test, prediksi_logreg)\n",
        "print('Nilai akurasi Logistic Regression pada testing data adalah {:.3f}'.format(logreg.score(X_test, y_test)))\n",
        "print('Nilai F1 Score Logistic Regression pada testing data adalah {:.3f}'.format(f1_score(y_test, prediksi_logreg, average='macro')))\n",
        "print('Nilai Precision Score Logistic Regression pada testing data adalah {:.3f}'.format(precision_score(y_test, prediksi_logreg, average='macro')))\n",
        "print('Nilai Recall Score Logistic Regression pada testing data adalah {:.3f}'.format(recall_score(y_test, prediksi_logreg, average='macro')))\n",
        "print()\n",
        "print(cr)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8whj9k9G5WB-",
        "colab_type": "text"
      },
      "source": [
        "**3. Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZJTe2q04gBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCl_BwbR5cxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.get_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbEoVYpG6PUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s9IvAq45gmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "max_features = ['auto', 'sqrt']\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "bootstrap = [True, False]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIg3H3Eh6SXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "\n",
        "print(random_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5leL4gD6T7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=100, cv=3, verbose=2, random_state=10, n_jobs=-1)\n",
        "rf_random.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fsAq4-r6n0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf_random.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_S2VOIl8dzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf = RandomForestClassifier(n_estimators=200, bootstrap=True, max_depth=90, max_features='auto', min_samples_leaf=4, min_samples_split=5)\n",
        "rf.fit(X_train, y_train)\n",
        "prediksi_rf = rf.predict(X_test)\n",
        "cm = confusion_matrix(y_test, prediksi_rf)\n",
        "cr = classification_report(y_test, prediksi_rf)\n",
        "print('Nilai akurasi Random Forest pada testing data adalah {:.3f}'.format(rf.score(X_test, y_test)))\n",
        "print('Nilai F1 Score Random Forest pada testing data adalah {:.3f}'.format(f1_score(y_test, prediksi_rf, average='macro')))\n",
        "print('Nilai Precision Score Random Forest pada testing data adalah {:.3f}'.format(precision_score(y_test, prediksi_rf, average='macro')))\n",
        "print('Nilai Recall Score Random Forest pada testing data adalah {:.3f}'.format(recall_score(y_test, prediksi_rf, average='macro')))\n",
        "print()\n",
        "print(cr)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbKXzQBa_Q93",
        "colab_type": "text"
      },
      "source": [
        "Algoritma Random Forest memberikan nilai akurasi tertinggi yaitu 0.733 untuk dataset parkinson dengan image size 128 dan image descriptor HOG "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaJ7AJ_29Hnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing_paths = list(paths.list_images(testing_path))\n",
        "images = []\n",
        "for testingpath in testing_paths[:25]:\n",
        "  image = cv.imread(testingpath)\n",
        "  output = image.copy()\n",
        "  output = cv.resize(output, (128, 128))\n",
        "\n",
        "  image = preprocess(image, image_size=resize_image_size_128)\n",
        "\n",
        "  if extraction_method == 'hog':\n",
        "    features = quantify_image_hog(image)\n",
        "  elif extraction_method == 'lbp':\n",
        "    features = quantify_image_lbp(image)\n",
        "\n",
        "  preds = rf.predict([features])\n",
        "  label = le.inverse_transform(preds)[0]\n",
        "\n",
        "  color = (0, 255, 0) if label == 'healthy' else (0, 0, 255)\n",
        "  cv.putText(output, label, (3, 20), cv.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "  images.append(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8PQWIcz-Rct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imutils import build_montages\n",
        "\n",
        "montage = build_montages(images, (128, 128), (5, 5))[0]\n",
        "\n",
        "cv2_imshow(montage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXZmNNwxAO0M",
        "colab_type": "text"
      },
      "source": [
        "## **HOG dengan Image Size 300**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMrlXiLB-rOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#HOG 300\n",
        "resize_image_size_300 = 300\n",
        "extraction_method = 'hog'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQBMKMZ8AwgR",
        "colab_type": "text"
      },
      "source": [
        "**Spilt Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcAV-NIdAkIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train) = load_split(training_path, image_size=resize_image_size_300, extraction_method=extraction_method)\n",
        "(X_test, y_test) = load_split(testing_path, image_size=resize_image_size_300, extraction_method=extraction_method)\n",
        "\n",
        "print('Data berhasil diupload!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vfe6cc9zBUoO",
        "colab_type": "text"
      },
      "source": [
        "**Label Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XEkXdc_BFE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48mXCYTjBf_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_u0fXTSBmbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-_-kF2MBtEN",
        "colab_type": "text"
      },
      "source": [
        "**Machine Learning Model**\n",
        "\n",
        "**1. Linear SVC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9fN_gmdfFCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C = [int(x) for x in np.linspace(0, 50, 25)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTFd2OEJkCEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linsvc_grid = {'C' : C}\n",
        "\n",
        "print(linsvc_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZsqiy4jl0jg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linsvc = LinearSVC()\n",
        "linsvc_random = RandomizedSearchCV(estimator=linsvc, param_distributions=linsvc_grid, n_iter=100, cv=3, verbose=2, random_state=10, n_jobs=-1)\n",
        "linsvc_random.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1Z1ta_Fl4kR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linsvc_random.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yfv2Q1mPBqlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lin_svc = LinearSVC(C=2)\n",
        "lin_svc.fit(X_train, y_train)\n",
        "prediksi_lin_svc_test = lin_svc.predict(X_test)\n",
        "cm = confusion_matrix(y_test, prediksi_lin_svc_test)\n",
        "cr = classification_report(y_test, prediksi_lin_svc_test)\n",
        "print('Nilai akurasi LinearSVC pada testing data adalah {:.3f}'.format(lin_svc.score(X_test, y_test)))\n",
        "print('Nilai F1 Score LinearSVC pada testing data adalah {:.3f}'.format(f1_score(y_test, prediksi_lin_svc_test, average='macro')))\n",
        "print('Nilai Precision Score LinearSVC pada testing data adalah {:.3f}'.format(precision_score(y_test, prediksi_lin_svc_test, average='macro')))\n",
        "print('Nilai Recall Score LinearSVC pada testing data adalah {:.3f}'.format(recall_score(y_test, prediksi_lin_svc_test, average='macro')))\n",
        "print()\n",
        "print(cr)\n",
        "print(cm)\n",
        "print('==================================================================================================================================================================')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR90gF9vCDD-",
        "colab_type": "text"
      },
      "source": [
        "**2. Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VfwE_93mCM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.get_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m_GX8cJmv8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "penalty = ['l1', 'l2']\n",
        "C = np.logspace(-4,4,20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmfijka8nEjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg_grid = {'penalty' : penalty,\n",
        "               'C' : C}\n",
        "\n",
        "print(logreg_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJb7u8tBnFii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg = LogisticRegression()\n",
        "log_random = RandomizedSearchCV(estimator=logreg, param_distributions=logreg_grid, n_iter=100, cv=3, verbose=2, random_state=10, n_jobs=-1)\n",
        "log_random.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqnqmFmwnQMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_random.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMxnNF62B_kq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg = LogisticRegression(C=1438.44988828766, penalty='l2')\n",
        "logreg.fit(X_train, y_train)\n",
        "prediksi_logreg = logreg.predict(X_test)\n",
        "cm = confusion_matrix(y_test, prediksi_logreg)\n",
        "cr = classification_report(y_test, prediksi_logreg)\n",
        "print('Nilai akurasi Logistic Regression dengan pada testing data adalah {:.3f}'.format(logreg.score(X_test, y_test)))\n",
        "print('Nilai F1 Score Logistic Regression dengan pada testing data adalah {:.3f}'.format(f1_score(y_test, prediksi_logreg, average='macro')))\n",
        "print('Nilai Precision Score Logistic Regression dengan pada testing data adalah {:.3f}'.format(precision_score(y_test, prediksi_logreg, average='macro')))\n",
        "print('Nilai Recall Score Logistic Regression dengan pada testing data adalah {:.3f}'.format(recall_score(y_test, prediksi_logreg, average='macro')))\n",
        "print()\n",
        "print(cr)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHCX_7pnCeU3",
        "colab_type": "text"
      },
      "source": [
        "**3. Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1TjMJT9CPGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "max_features = ['auto', 'sqrt']\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "bootstrap = [True, False]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CddWtXUzCpJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "\n",
        "print(random_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjMFOFIVCsdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=100, cv=3, verbose=2, random_state=10, n_jobs=-1)\n",
        "rf_random.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmE_2BIKCw9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf_random.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnOHiTnjE7SB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf = RandomForestClassifier(bootstrap=True, max_depth=50, max_features='sqrt', min_samples_leaf=1, min_samples_split=10, n_estimators=1200, random_state=10)\n",
        "rf.fit(X_train, y_train)\n",
        "prediksi_rf = rf.predict(X_test)\n",
        "cm = confusion_matrix(y_test, prediksi_rf)\n",
        "cr = classification_report(y_test, prediksi_rf)\n",
        "print('Nilai akurasi Random Forest pada testing data adalah {:.3f}'.format(rf.score(X_test, y_test)))\n",
        "print('Nilai F1 Score Random Forest pada testing data adalah {:.3f}'.format(f1_score(y_test, prediksi_rf, average='macro')))\n",
        "print('Nilai Precision Score Random Forest pada testing data adalah {:.3f}'.format(precision_score(y_test, prediksi_rf, average='macro')))\n",
        "print('Nilai Recall Score Random Forest pada testing data adalah {:.3f}'.format(recall_score(y_test, prediksi_rf, average='macro')))\n",
        "print()\n",
        "print(cr)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8m2NaQsFuZO",
        "colab_type": "text"
      },
      "source": [
        "Model dengan algoritma LinearSVC dan Logistic Regression memberikan nilai akurasi terbaik yakni sebesar 0.733"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_iLBUeqFg3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing_paths = list(paths.list_images(testing_path))\n",
        "images = []\n",
        "for testingpath in testing_paths[:25]:\n",
        "  image = cv.imread(testingpath)\n",
        "  output = image.copy()\n",
        "  output = cv.resize(output, (300, 300))\n",
        "\n",
        "  image = preprocess(image, image_size=resize_image_size_300)\n",
        "\n",
        "  if extraction_method == 'hog':\n",
        "    features = quantify_image_hog(image)\n",
        "  elif extraction_method == 'lbp':\n",
        "    features = quantify_image_lbp(image)\n",
        "\n",
        "  preds = lin_svc.predict([features])\n",
        "  label = le.inverse_transform(preds)[0]\n",
        "\n",
        "  color = (0, 255, 0) if label == 'healthy' else (0, 0, 255)\n",
        "  cv.putText(output, label, (3, 20), cv.FONT_HERSHEY_SIMPLEX, 1, color, 3)\n",
        "  images.append(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxmFRnquF9Gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imutils import build_montages\n",
        "\n",
        "montage = build_montages(images, (300, 300), (5, 5))[0]\n",
        "\n",
        "cv2_imshow(montage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJUTf36_HGTt",
        "colab_type": "text"
      },
      "source": [
        "## **LBP dengan Image Size 128**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mkeO5SJGDdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LBP 128\n",
        "resize_image_size_lbp_128 = 128\n",
        "extraction_method_lbp = 'lbp'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g5jtOuOHSrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train_lbp, y_train_lbp) = load_split(training_path, image_size=resize_image_size_lbp_128, extraction_method=extraction_method_lbp)\n",
        "(X_test_lbp, y_test_lbp) = load_split(testing_path, image_size=resize_image_size_lbp_128, extraction_method=extraction_method_lbp)\n",
        "\n",
        "print('Data sudah diupload!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZf_Grt3J14y",
        "colab_type": "text"
      },
      "source": [
        "**Label Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gErO6gCMJoyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()\n",
        "y_train_lbp = le.fit_transform(y_train_lbp)\n",
        "y_test_lbp = le.transform(y_test_lbp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeNbgcl1KZG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_lbp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdc9-v9sKaUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_lbp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_FCwSHaMNm0",
        "colab_type": "text"
      },
      "source": [
        "**Machine Learning Model**\n",
        "\n",
        "**1. LinearSVC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvk4QM05TkeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lin_svc_lbp = LinearSVC()\n",
        "lin_svc_lbp.get_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alVpLQ6kTo_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C = [int(x) for x in np.linspace(0, 50, 25)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iigR5PrGUaUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linsvc_grid = {'C' : C}\n",
        "\n",
        "print(linsvc_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y2WFB9SUt5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linsvc_lbp = LinearSVC()\n",
        "lin_random_lbp = RandomizedSearchCV(estimator=linsvc_lbp, param_distributions=linsvc_grid, n_iter=100, cv=3, verbose=2, random_state=10, n_jobs=-1)\n",
        "lin_random_lbp.fit(X_train_lbp, y_train_lbp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOvyMG_WU7sq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lin_random_lbp.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyJU3ZOJKd8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lin_svc_lbp = LinearSVC(C=2, random_state=10)\n",
        "lin_svc_lbp.fit(X_train_lbp, y_train_lbp)\n",
        "prediksi_lin_svc_lbp = lin_svc_lbp.predict(X_test_lbp)\n",
        "cm_lbp = confusion_matrix(y_test_lbp, prediksi_lin_svc_lbp)\n",
        "cr_lbp = classification_report(y_test, prediksi_lin_svc_lbp)\n",
        "print('Nilai akurasi LinearSVC pada testing data adalah {:.3f}'.format(lin_svc_lbp.score(X_test_lbp, y_test_lbp)))\n",
        "print('Nilai F1 Score LinearSVC pada testing data adalah {:.3f}'.format(f1_score(y_test_lbp, prediksi_lin_svc_lbp, average='macro')))\n",
        "print('Nilai Precision Score LinearSVC pada testing data adalah {:.3f}'.format(precision_score(y_test_lbp, prediksi_lin_svc_lbp, average='macro')))\n",
        "print('Nilai Recall Score LinearSVC pada testing data adalah {:.3f}'.format(recall_score(y_test_lbp, prediksi_lin_svc_lbp, average='macro')))\n",
        "print()\n",
        "print(cr_lbp)\n",
        "print(cm_lbp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dus1sYIbM_NL",
        "colab_type": "text"
      },
      "source": [
        "**2. Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbHtaJBzSaPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg_lbp = LogisticRegression()\n",
        "logreg_lbp.get_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpu6LVntSVjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "penalty = ['l1', 'l2']\n",
        "C = np.logspace(-4,4,20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EosRiqUgSitY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_grid = {'penalty': penalty,\n",
        "            'C': C}\n",
        "\n",
        "print(log_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XpJFlfyS1mQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg_lbp = LogisticRegression()\n",
        "log_random_lbp = RandomizedSearchCV(estimator=logreg_lbp, param_distributions=log_grid, n_iter=100, cv=3, verbose=2, random_state=10, n_jobs=-1)\n",
        "log_random_lbp.fit(X_train_lbp, y_train_lbp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypTDPuiYS_Ym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_random_lbp.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufH2o_obTEB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg_lbp = LogisticRegression(solver='lbfgs', C=78.47599703514607, penalty='l2')\n",
        "logreg_lbp.fit(X_train_lbp, y_train_lbp)\n",
        "prediksi_logreg_lbp = logreg_lbp.predict(X_test_lbp)\n",
        "cm_lbp = confusion_matrix(y_test_lbp, prediksi_logreg_lbp)\n",
        "cr_lbp = classification_report(y_test_lbp, prediksi_logreg_lbp)\n",
        "print('Nilai akurasi Logistic Regression pada testing data adalah {:.3f}'.format(logreg_lbp.score(X_test_lbp, y_test_lbp)))\n",
        "print('Nilai F1 Score Logistic Regression pada testing data adalah {:.3f}'.format(f1_score(y_test_lbp, prediksi_logreg_lbp, average='macro')))\n",
        "print('Nilai Precision Score Logistic Regression pada testing data adalah {:.3f}'.format(precision_score(y_test_lbp, prediksi_logreg_lbp, average='macro')))\n",
        "print('Nilai Recall Score Logistic Regression pada testing data adalah {:.3f}'.format(recall_score(y_test_lbp, prediksi_logreg_lbp, average='macro')))\n",
        "print()\n",
        "print(cr_lbp)\n",
        "print(cm_lbp)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzuVYi4INv61",
        "colab_type": "text"
      },
      "source": [
        "**3. Random Forest Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKQ5_k8yNgiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "max_features = ['auto', 'sqrt']\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "bootstrap = [True, False]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6lwBW2lN_qr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "\n",
        "print(random_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW1VxesuOBDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf_lbp = RandomForestClassifier()\n",
        "rf_random_lbp = RandomizedSearchCV(estimator=rf_lbp, param_distributions=random_grid, n_iter=100, cv=3, verbose=2, random_state=10, n_jobs=-1)\n",
        "rf_random_lbp.fit(X_train_lbp, y_train_lbp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjVS4wSDOVa3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf_random_lbp.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MevINCTrRPpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf_lbp = RandomForestClassifier(bootstrap=True, max_depth=50, max_features='auto', min_samples_leaf=2, min_samples_split=5, n_estimators=400, random_state=10)\n",
        "rf_lbp.fit(X_train_lbp, y_train_lbp)\n",
        "prediksi_rf_lbp = rf_lbp.predict(X_test_lbp)\n",
        "cm_lbp = confusion_matrix(y_test_lbp, prediksi_rf_lbp)\n",
        "cr_lbp = classification_report(y_test_lbp, prediksi_rf_lbp)\n",
        "print('Nilai akurasi Random Forest pada testing data adalah {:.3f}'.format(rf_lbp.score(X_test_lbp, y_test_lbp)))\n",
        "print('Nilai F1 Score Random Forest pada testing data adalah {:.3f}'.format(f1_score(y_test_lbp, prediksi_rf_lbp, average='macro')))\n",
        "print('Nilai Precision Score Random Forest pada testing data adalah {:.3f}'.format(precision_score(y_test_lbp, prediksi_rf_lbp, average='macro')))\n",
        "print('Nilai Recall Score Random Forest pada testing data adalah {:.3f}'.format(recall_score(y_test_lbp, prediksi_rf_lbp, average='macro')))\n",
        "print()\n",
        "print(cr_lbp)\n",
        "print(cm_lbp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zss9dZkvVWL9",
        "colab_type": "text"
      },
      "source": [
        "Untuk ketiga algoritma memberikan nilai akurasi yang sama yakni 0.5, yang mana bukanlah hasil yang baik, akan tetapi algoritma Random Forest memberikan nilai f1, precision, dan recall yang lebih baik dibandingkan LinearSVC dan Logistic Regression sehingga algoritma Random Forest akan dijadikan sebagai algoritma terbaik"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhCmypc0R_ZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing_paths = list(paths.list_images(testing_path))\n",
        "images = []\n",
        "for testingpath in testing_paths[:30]:\n",
        "  image = cv.imread(testingpath)\n",
        "  output = image.copy()\n",
        "  output = cv.resize(output, (128, 128))\n",
        "\n",
        "  image = preprocess(image, image_size=resize_image_size_lbp_128)\n",
        "\n",
        "  if extraction_method_lbp == 'hog':\n",
        "    features = quantify_image_hog(image)\n",
        "  elif extraction_method_lbp == 'lbp':\n",
        "    features = quantify_image_lbp(image)\n",
        "\n",
        "  preds = rf_lbp.predict([features])\n",
        "  label = le.inverse_transform(preds)[0]\n",
        "\n",
        "  color = (0, 255, 0) if label == 'healthy' else (0, 0, 255)\n",
        "  cv.putText(output, label, (3, 20), cv.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "  images.append(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOiBeniIWIFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imutils import build_montages\n",
        "\n",
        "montage = build_montages(images, (128, 128), (5, 5))[0]\n",
        "\n",
        "cv2_imshow(montage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_8R26FXWan4",
        "colab_type": "text"
      },
      "source": [
        "## **LBP dengan Image Size 300**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjPXY6aFWK8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LBP 300\n",
        "resize_image_size_lbp_300 = 300\n",
        "extraction_method_lbp = 'lbp'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLI01IOdWmsB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train_lbp, y_train_lbp) = load_split(training_path, image_size=resize_image_size_lbp_300, extraction_method=extraction_method_lbp)\n",
        "(X_test_lbp, y_test_lbp) = load_split(testing_path, image_size=resize_image_size_lbp_300, extraction_method=extraction_method_lbp)\n",
        "\n",
        "print('Data berhasil diupload!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvpMjqwrXAYI",
        "colab_type": "text"
      },
      "source": [
        "**Label Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5XsJV3ZW8uK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()\n",
        "y_train_lbp = le.fit_transform(y_train_lbp)\n",
        "y_test_lbp = le.transform(y_test_lbp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiFJQ7YvXJF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_lbp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDASU9ZKXKXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_lbp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0nLziuDXMk2",
        "colab_type": "text"
      },
      "source": [
        "**1. LinearSVC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8qZckvmXLQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linsvc_lbp = LinearSVC()\n",
        "linsvc_lbp.get_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Daht5n_yXUVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C = [int(x) for x in np.linspace(0, 50, 25)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClW-QSG2Xi0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linsvc_grid = {'C' : C}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwPRmHgyXmAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linsvc_lbp = LinearSVC()\n",
        "lin_random_lbp = RandomizedSearchCV(estimator=linsvc_lbp, param_distributions=linsvc_grid, n_iter=100, cv=3, verbose=2, random_state=10, n_jobs=-1)\n",
        "lin_random_lbp.fit(X_train_lbp, y_train_lbp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhM6obsZXtRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lin_random_lbp.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBFymGdtXv3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lin_svc_lbp = LinearSVC(C=43, random_state=10)\n",
        "lin_svc_lbp.fit(X_train_lbp, y_train_lbp)\n",
        "prediksi_lin_svc_lbp = lin_svc_lbp.predict(X_test_lbp)\n",
        "cm_lbp = confusion_matrix(y_test_lbp, prediksi_lin_svc_lbp)\n",
        "cr_lbp = classification_report(y_test, prediksi_lin_svc_lbp)\n",
        "print('Nilai akurasi LinearSVC pada testing data adalah {:.3f}'.format(lin_svc_lbp.score(X_test_lbp, y_test_lbp)))\n",
        "print('Nilai F1 Score LinearSVC pada testing data adalah {:.3f}'.format(f1_score(y_test_lbp, prediksi_lin_svc_lbp, average='macro')))\n",
        "print('Nilai Precision Score LinearSVC pada testing data adalah {:.3f}'.format(precision_score(y_test_lbp, prediksi_lin_svc_lbp, average='macro')))\n",
        "print('Nilai Recall Score LinearSVC pada testing data adalah {:.3f}'.format(recall_score(y_test_lbp, prediksi_lin_svc_lbp, average='macro')))\n",
        "print()\n",
        "print(cr_lbp)\n",
        "print(cm_lbp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJL-R8OJYgRi",
        "colab_type": "text"
      },
      "source": [
        "**2. Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep-xYq-bX0w1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg_lbp = LogisticRegression()\n",
        "logreg_lbp.get_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnuEkWILYlqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "penalty = ['l1', 'l2']\n",
        "C = np.logspace(-4,4,20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzzcry8LYqMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_grid = {'penalty': penalty, 'C': C}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2xRczoWYurD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg_lbp = LogisticRegression()\n",
        "log_random_lbp = RandomizedSearchCV(estimator=logreg_lbp, param_distributions=log_grid, n_iter=100, cv=3, verbose=2, random_state=10, n_jobs=-1)\n",
        "log_random_lbp.fit(X_train_lbp, y_train_lbp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWDZS2wGY05v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_random_lbp.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVcB_H48Y3IX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg_lbp = LogisticRegression(C=3792.690190732246, penalty='l2')\n",
        "logreg_lbp.fit(X_train_lbp, y_train_lbp)\n",
        "prediksi_logreg_lbp = logreg_lbp.predict(X_test_lbp)\n",
        "cm_lbp = confusion_matrix(y_test_lbp, prediksi_logreg_lbp)\n",
        "cr_lbp = classification_report(y_test_lbp, prediksi_logreg_lbp)\n",
        "print('Nilai akurasi Logistic Regression pada testing data adalah {:.3f}'.format(logreg_lbp.score(X_test_lbp, y_test_lbp)))\n",
        "print('Nilai F1 Score Logistic Regression pada testing data adalah {:.3f}'.format(f1_score(y_test_lbp, prediksi_logreg_lbp, average='macro')))\n",
        "print('Nilai Precision Score Logistic Regression pada testing data adalah {:.3f}'.format(precision_score(y_test_lbp, prediksi_logreg_lbp, average='macro')))\n",
        "print('Nilai Recall Score Logistic Regression pada testing data adalah {:.3f}'.format(recall_score(y_test_lbp, prediksi_logreg_lbp, average='macro')))\n",
        "print()\n",
        "print(cr_lbp)\n",
        "print(cm_lbp)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aV9p7adZDNn",
        "colab_type": "text"
      },
      "source": [
        "**3. Random Forest Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbBsWYCKZAzk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "max_features = ['auto', 'sqrt']\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "bootstrap = [True, False]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPclX_EBZIyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "\n",
        "print(random_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taL2ilepZMOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf_lbp = RandomForestClassifier()\n",
        "rf_random_lbp = RandomizedSearchCV(estimator=rf_lbp, param_distributions=random_grid, n_iter=100, cv=3, verbose=2, random_state=10, n_jobs=-1)\n",
        "rf_random_lbp.fit(X_train_lbp, y_train_lbp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "houjtomxZQyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf_random_lbp.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A1-nO2VbffD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf_lbp = RandomForestClassifier(bootstrap=False, max_depth=60, max_features='sqrt', min_samples_leaf=2, min_samples_split=5, n_estimators=1200, random_state=10)\n",
        "rf_lbp.fit(X_train_lbp, y_train_lbp)\n",
        "prediksi_rf_lbp = rf_lbp.predict(X_test_lbp)\n",
        "cm_lbp = confusion_matrix(y_test_lbp, prediksi_rf_lbp)\n",
        "cr_lbp = classification_report(y_test_lbp, prediksi_rf_lbp)\n",
        "print('Nilai akurasi Random Forest pada testing data adalah {:.3f}'.format(rf_lbp.score(X_test_lbp, y_test_lbp)))\n",
        "print('Nilai F1 Score Random Forest pada testing data adalah {:.3f}'.format(f1_score(y_test_lbp, prediksi_rf_lbp, average='macro')))\n",
        "print('Nilai Precision Score Random Forest pada testing data adalah {:.3f}'.format(precision_score(y_test_lbp, prediksi_rf_lbp, average='macro')))\n",
        "print('Nilai Recall Score Random Forest pada testing data adalah {:.3f}'.format(recall_score(y_test_lbp, prediksi_rf_lbp, average='macro')))\n",
        "print()\n",
        "print(cr_lbp)\n",
        "print(cm_lbp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xjBBknqcTVy",
        "colab_type": "text"
      },
      "source": [
        "Algoritma Logistic Regression dan Random Forest memberikan nilai akurasi terbaik, begitu pula dengan metric-metric lainnya pun algoritma Random Forest dan Logistic Regression yang hasilnya paling baik"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv4sGDQvbrKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing_paths = list(paths.list_images(testing_path))\n",
        "images = []\n",
        "for testingpath in testing_paths[:30]:\n",
        "  image = cv.imread(testingpath)\n",
        "  output = image.copy()\n",
        "  output = cv.resize(output, (300, 300))\n",
        "\n",
        "  image = preprocess(image, image_size=resize_image_size_lbp_300)\n",
        "\n",
        "  if extraction_method_lbp == 'hog':\n",
        "    features = quantify_image_hog(image)\n",
        "  elif extraction_method_lbp == 'lbp':\n",
        "    features = quantify_image_lbp(image)\n",
        "\n",
        "  preds = logreg_lbp.predict([features])\n",
        "  label = le.inverse_transform(preds)[0]\n",
        "\n",
        "  color = (0, 255, 0) if label == 'healthy' else (0, 0, 255)\n",
        "  cv.putText(output, label, (3, 20), cv.FONT_HERSHEY_SIMPLEX, 0.9, color, 3)\n",
        "  images.append(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7og6oONdD82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imutils import build_montages\n",
        "\n",
        "montage = build_montages(images, (300, 300), (5, 5))[0]\n",
        "\n",
        "cv2_imshow(montage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T__FdJObdT03",
        "colab_type": "text"
      },
      "source": [
        "### **Kesimpulan**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mehgAIHGP8J-",
        "colab_type": "text"
      },
      "source": [
        "1. HOG dengan Image size 128 -> Model terbaik adalah Random Forest dengan akurasi 0.733\n",
        "2. HOG dengan Image size 300 -> Model terbaik adalah LinearSVC dan Logistic Regression dengan akurasi 0.733\n",
        "3. LBP dengan Image size 128 -> Model Linear SVC, Logistic Regression, dan Random Forest memberikan hasil akurasi yang sama kurang baiknya yaitu 0.5\n",
        "4. LBP dengan Image size 300 -> Model Logistic Regression dan Random Forest memberikan nilai akurasi terbaik yaitu 0.7\n",
        "\n",
        "**Model terbaik adalah Random Forest dengan image descriptor HOG dan image size 128 serta LinearSVC dengan image descriptor HOG dan image size 300**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10exRbuPQ-4l",
        "colab_type": "text"
      },
      "source": [
        "# **Image Classification Parkinson Wave dengan Tambahan Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EEnHM4ZP5YT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_dir = 'drive/My Drive/Colab Test (Bootcamp ML 2020)/parkinsons/wave'\n",
        "\n",
        "training_path = os.path.join(dataset_dir, 'training_tambahan')\n",
        "testing_path = os.path.join(dataset_dir, 'testing')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ7bwzsaRw-u",
        "colab_type": "text"
      },
      "source": [
        "Akan digunakan Metode Preprocess dengan HOG dan image size 300 dengan algoritma Linear SVC dan Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vun8EyG7ZJQV",
        "colab_type": "text"
      },
      "source": [
        "## **HOG dan Image Size 300 dengan Algoritma LinearSVC dan Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkrtZUs4ZI74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resize_image_size_300 = 300 \n",
        "extraction_method = 'hog'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QplHwB0jYgE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train) = load_split(training_path, image_size=resize_image_size_300, extraction_method=extraction_method)\n",
        "(X_test, y_test) = load_split(testing_path, image_size=resize_image_size_300, extraction_method=extraction_method)\n",
        "\n",
        "print('Data berhasil diupload!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhsCpdmlZmux",
        "colab_type": "text"
      },
      "source": [
        "**Label Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98Ds69YkZh6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9B9X8EhZn_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(y_train))\n",
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z33-lkHmZq-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(y_test))\n",
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yutly1ycZwut",
        "colab_type": "text"
      },
      "source": [
        "**Machine Learning Model**\n",
        "\n",
        "**1. LinearSVC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR6wCXIAZtde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import LinearSVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF_k5uafaEh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linsvc = LinearSVC()\n",
        "linsvc.get_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAMLlNe6aV7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C = [int(x) for x in np.linspace(0, 50, 25)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuVdxtvBaW_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linsvc_grid = {'C' : C}\n",
        "\n",
        "print(linsvc_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqSRoK1DaeqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linsvc = LinearSVC()\n",
        "linsvc_random = RandomizedSearchCV(estimator=linsvc, param_distributions=linsvc_grid, n_iter=100, cv=3, verbose=2, random_state=10, n_jobs=-1)\n",
        "linsvc_random.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5EqIanaaodt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linsvc_random.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DtlgyKVar1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linsvc = LinearSVC(C=2)\n",
        "linsvc.fit(X_train, y_train)\n",
        "prediksi_linsvc = linsvc.predict(X_test)\n",
        "cm = confusion_matrix(y_test, prediksi_linsvc)\n",
        "cr = classification_report(y_test, prediksi_linsvc)\n",
        "print('Nilai akurasi LinearSVC pada testing data adalah {:.3f}'.format(linsvc.score(X_test, y_test)))\n",
        "print('Nilai F1 Score LinearSVC pada testing data adalah {:.3f}'.format(f1_score(y_test, prediksi_linsvc, average='macro')))\n",
        "print('Nilai Precision Score LinearSVC pada testing data adalah {:.3f}'.format(precision_score(y_test, prediksi_linsvc, average='macro')))\n",
        "print('Nilai Recall Score LinearSVC pada testing data adalah {:.3f}'.format(recall_score(y_test, prediksi_linsvc, average='macro')))\n",
        "print()\n",
        "print(cr)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncTZE-ydbLL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing_paths = list(paths.list_images(testing_path))\n",
        "images = []\n",
        "for testingpath in testing_paths[:25]:\n",
        "  image = cv.imread(testingpath)\n",
        "  output = image.copy()\n",
        "  output = cv.resize(output, (300, 300))\n",
        "\n",
        "  image = preprocess(image, image_size=resize_image_size_300)\n",
        "\n",
        "  if extraction_method == 'hog':\n",
        "    features = quantify_image_hog(image)\n",
        "  elif extraction_method == 'lbp':\n",
        "    features = quantify_image_lbp(image)\n",
        "\n",
        "  preds = linsvc.predict([features])\n",
        "  label = le.inverse_transform(preds)[0]\n",
        "\n",
        "  color = (0, 255, 0) if label == 'healthy' else (0, 0, 255)\n",
        "  cv.putText(output, label, (3, 20), cv.FONT_HERSHEY_SIMPLEX, 0.7, color, 3)\n",
        "  images.append(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPYbdvC7bbd4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imutils import build_montages\n",
        "\n",
        "montage = build_montages(images, (300, 300), (5, 5))[0]\n",
        "\n",
        "cv2_imshow(montage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uib8c2MlpxXa",
        "colab_type": "text"
      },
      "source": [
        "**2. Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhnoiPDMpwy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.get_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojMedatAp5mg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "penalty = ['l1', 'l2']\n",
        "C = np.logspace(-4,4,20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpZPA-4DqCRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_grid = {'penalty': penalty, 'C': C}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoFwH4aQqcPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg = LogisticRegression()\n",
        "log_random = RandomizedSearchCV(estimator=logreg, param_distributions=log_grid, n_iter=100, cv=3, verbose=2, random_state=10, n_jobs=-1)\n",
        "log_random.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0urFEKSqr-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_random.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apcrACe2qPts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg = LogisticRegression(C=3792.690190732246, penalty='l2')\n",
        "logreg.fit(X_train, y_train)\n",
        "prediksi_logreg = logreg.predict(X_test)\n",
        "cm = confusion_matrix(y_test, prediksi_logreg)\n",
        "cr = classification_report(y_test, prediksi_logreg)\n",
        "print('Nilai akurasi Logistic Regression pada testing data adalah {:.3f}'.format(logreg.score(X_test, y_test)))\n",
        "print('Nilai F1 Score Logistic Regression pada testing data adalah {:.3f}'.format(f1_score(y_test, prediksi_logreg, average='macro')))\n",
        "print('Nilai Precision Score Logistic Regression pada testing data adalah {:.3f}'.format(precision_score(y_test, prediksi_logreg, average='macro')))\n",
        "print('Nilai Recall Score Logistic Regression pada testing data adalah {:.3f}'.format(recall_score(y_test, prediksi_logreg, average='macro')))\n",
        "print()\n",
        "print(cr)\n",
        "print(cm)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD6-1IecrU11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing_paths = list(paths.list_images(testing_path))\n",
        "images = []\n",
        "for testingpath in testing_paths[:25]:\n",
        "  image = cv.imread(testingpath)\n",
        "  output = image.copy()\n",
        "  output = cv.resize(output, (300, 300))\n",
        "\n",
        "  image = preprocess(image, image_size=resize_image_size_300)\n",
        "\n",
        "  if extraction_method == 'hog':\n",
        "    features = quantify_image_hog(image)\n",
        "  elif extraction_method == 'lbp':\n",
        "    features = quantify_image_lbp(image)\n",
        "\n",
        "  preds = logreg.predict([features])\n",
        "  label = le.inverse_transform(preds)[0]\n",
        "\n",
        "  color = (0, 255, 0) if label == 'healthy' else (0, 0, 255)\n",
        "  cv.putText(output, label, (3, 20), cv.FONT_HERSHEY_SIMPLEX, 0.7, color, 3)\n",
        "  images.append(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNe5PJFUrYA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imutils import build_montages\n",
        "\n",
        "montage = build_montages(images, (300, 300), (5, 5))[0]\n",
        "\n",
        "cv2_imshow(montage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzZGvXjBb39J",
        "colab_type": "text"
      },
      "source": [
        "## **Kesimpulan**\n",
        "\n",
        "**HOG dengan Image size 300** :\n",
        "1. **LinearSVC** mengalami **peningkatan** akurasi dari **0.733** (sebelum penambahan data training) menjadi **0.767** (setelah penambahan data training)\n",
        "\n",
        "2. **Logistic Regression** mengalami **peningkatan** akurasi dari **0.733** (sebelum penambahan data training) menjadi **0.767** (setelah penambahan data training)"
      ]
    }
  ]
}