{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Santa Dataset VGG16 & VGG19 with RMSProp Optimizer (BEST MODEL).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL7Jp8TxSrqi"
      },
      "source": [
        "## **Santa Dataset VGG16 with RMSProp Optimizer**\n",
        "\n",
        "**Benedictus Bayu Pramudhito**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nne7TrwrJ020",
        "outputId": "db5396ba-0bab-4ff3-d9f5-5c6ecf0250ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR37W7tFchKF"
      },
      "source": [
        "zip_path = '/content/drive/My\\ Drive/santa-dataset.zip'\n",
        "\n",
        "!cp {zip_path} /content/\n",
        "\n",
        "!cd /content/\n",
        "\n",
        "!unzip -q /content/santa-dataset.zip -d /content\n",
        "\n",
        "!rm /content/santa-dataset.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FwE2WEKlEKQ"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vdl88-zjxM4R"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keMDICRGrhNs"
      },
      "source": [
        "# Baseline CNN model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nov8K3vg-hie"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0O7kh6rmJj9",
        "outputId": "b8dd650b-92db-4e07-8ec8-958a228673ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "opt = SGD(lr=0.001, momentum=0.9)\n",
        "\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 200, 200, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 100, 100, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 100, 100, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 50, 50, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 25, 25, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 80000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               10240128  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 10,333,505\n",
            "Trainable params: 10,333,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeGSbxxk29SO",
        "outputId": "b37c628f-d6d1-42f0-b3ba-e842115c0543",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "dataset_dir = '/content/'\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "train_iterator = datagen.flow_from_directory(os.path.join(dataset_dir, 'train'), class_mode='binary', batch_size=128, target_size=(200, 200))\n",
        "test_iterator = datagen.flow_from_directory(os.path.join(dataset_dir, 'test'), class_mode='binary', batch_size=128, target_size=(200, 200))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 662 images belonging to 2 classes.\n",
            "Found 260 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uk8mTSp_oJe"
      },
      "source": [
        "**Training with Baseline CNN Layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znPhLUV4ma06",
        "outputId": "de760f9d-9820-4c60-82b1-155322fac022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_base_model = model.fit_generator(train_iterator, steps_per_epoch=len(train_iterator), validation_data=test_iterator, validation_steps=len(test_iterator), epochs=75)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-9-97d030b73ef6>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/75\n",
            "6/6 [==============================] - 58s 10s/step - loss: 0.7556 - accuracy: 0.5619 - val_loss: 0.9726 - val_accuracy: 0.5346\n",
            "Epoch 2/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.7086 - accuracy: 0.6360 - val_loss: 0.7464 - val_accuracy: 0.5000\n",
            "Epoch 3/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.6396 - accuracy: 0.6088 - val_loss: 0.6043 - val_accuracy: 0.6885\n",
            "Epoch 4/75\n",
            "6/6 [==============================] - 57s 9s/step - loss: 0.5360 - accuracy: 0.7085 - val_loss: 0.5039 - val_accuracy: 0.7654\n",
            "Epoch 5/75\n",
            "6/6 [==============================] - 58s 10s/step - loss: 0.4315 - accuracy: 0.8021 - val_loss: 0.5141 - val_accuracy: 0.7385\n",
            "Epoch 6/75\n",
            "6/6 [==============================] - 57s 9s/step - loss: 0.3648 - accuracy: 0.8625 - val_loss: 0.4240 - val_accuracy: 0.8308\n",
            "Epoch 7/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.3060 - accuracy: 0.9048 - val_loss: 0.3607 - val_accuracy: 0.9038\n",
            "Epoch 8/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.2653 - accuracy: 0.9290 - val_loss: 0.3559 - val_accuracy: 0.9000\n",
            "Epoch 9/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.2455 - accuracy: 0.9169 - val_loss: 0.3417 - val_accuracy: 0.9154\n",
            "Epoch 10/75\n",
            "6/6 [==============================] - 57s 10s/step - loss: 0.2288 - accuracy: 0.9245 - val_loss: 0.3195 - val_accuracy: 0.9231\n",
            "Epoch 11/75\n",
            "6/6 [==============================] - 65s 11s/step - loss: 0.2108 - accuracy: 0.9335 - val_loss: 0.3077 - val_accuracy: 0.9115\n",
            "Epoch 12/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.2061 - accuracy: 0.9305 - val_loss: 0.3326 - val_accuracy: 0.8885\n",
            "Epoch 13/75\n",
            "6/6 [==============================] - 57s 10s/step - loss: 0.2630 - accuracy: 0.8822 - val_loss: 0.3395 - val_accuracy: 0.8808\n",
            "Epoch 14/75\n",
            "6/6 [==============================] - 68s 11s/step - loss: 0.1797 - accuracy: 0.9456 - val_loss: 0.3224 - val_accuracy: 0.8885\n",
            "Epoch 15/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.1768 - accuracy: 0.9426 - val_loss: 0.2794 - val_accuracy: 0.9269\n",
            "Epoch 16/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.1663 - accuracy: 0.9396 - val_loss: 0.2893 - val_accuracy: 0.9231\n",
            "Epoch 17/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.1367 - accuracy: 0.9592 - val_loss: 0.2803 - val_accuracy: 0.9231\n",
            "Epoch 18/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.1249 - accuracy: 0.9653 - val_loss: 0.2786 - val_accuracy: 0.9231\n",
            "Epoch 19/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.1348 - accuracy: 0.9562 - val_loss: 0.2915 - val_accuracy: 0.9077\n",
            "Epoch 20/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.1442 - accuracy: 0.9502 - val_loss: 0.2957 - val_accuracy: 0.9077\n",
            "Epoch 21/75\n",
            "6/6 [==============================] - 54s 9s/step - loss: 0.1313 - accuracy: 0.9547 - val_loss: 0.2666 - val_accuracy: 0.9231\n",
            "Epoch 22/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.1196 - accuracy: 0.9562 - val_loss: 0.2599 - val_accuracy: 0.9192\n",
            "Epoch 23/75\n",
            "6/6 [==============================] - 58s 10s/step - loss: 0.1105 - accuracy: 0.9622 - val_loss: 0.2654 - val_accuracy: 0.9192\n",
            "Epoch 24/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0974 - accuracy: 0.9698 - val_loss: 0.2720 - val_accuracy: 0.9231\n",
            "Epoch 25/75\n",
            "6/6 [==============================] - 57s 10s/step - loss: 0.0977 - accuracy: 0.9713 - val_loss: 0.2679 - val_accuracy: 0.9192\n",
            "Epoch 26/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0953 - accuracy: 0.9698 - val_loss: 0.2604 - val_accuracy: 0.9231\n",
            "Epoch 27/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0837 - accuracy: 0.9804 - val_loss: 0.2605 - val_accuracy: 0.9231\n",
            "Epoch 28/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0945 - accuracy: 0.9713 - val_loss: 0.2642 - val_accuracy: 0.9115\n",
            "Epoch 29/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0934 - accuracy: 0.9683 - val_loss: 0.2670 - val_accuracy: 0.9231\n",
            "Epoch 30/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0806 - accuracy: 0.9773 - val_loss: 0.3241 - val_accuracy: 0.9038\n",
            "Epoch 31/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0786 - accuracy: 0.9713 - val_loss: 0.3125 - val_accuracy: 0.9115\n",
            "Epoch 32/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0707 - accuracy: 0.9743 - val_loss: 0.3083 - val_accuracy: 0.9115\n",
            "Epoch 33/75\n",
            "6/6 [==============================] - 54s 9s/step - loss: 0.0612 - accuracy: 0.9879 - val_loss: 0.2864 - val_accuracy: 0.9115\n",
            "Epoch 34/75\n",
            "6/6 [==============================] - 65s 11s/step - loss: 0.0549 - accuracy: 0.9894 - val_loss: 0.2653 - val_accuracy: 0.9231\n",
            "Epoch 35/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0511 - accuracy: 0.9924 - val_loss: 0.2680 - val_accuracy: 0.9231\n",
            "Epoch 36/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0454 - accuracy: 0.9909 - val_loss: 0.2662 - val_accuracy: 0.9269\n",
            "Epoch 37/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0457 - accuracy: 0.9909 - val_loss: 0.2670 - val_accuracy: 0.9154\n",
            "Epoch 38/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0421 - accuracy: 0.9940 - val_loss: 0.2684 - val_accuracy: 0.9231\n",
            "Epoch 39/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0407 - accuracy: 0.9940 - val_loss: 0.2748 - val_accuracy: 0.9192\n",
            "Epoch 40/75\n",
            "6/6 [==============================] - 67s 11s/step - loss: 0.0407 - accuracy: 0.9955 - val_loss: 0.2793 - val_accuracy: 0.9192\n",
            "Epoch 41/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0345 - accuracy: 0.9985 - val_loss: 0.2709 - val_accuracy: 0.9308\n",
            "Epoch 42/75\n",
            "6/6 [==============================] - 66s 11s/step - loss: 0.0341 - accuracy: 0.9970 - val_loss: 0.2729 - val_accuracy: 0.9192\n",
            "Epoch 43/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.2874 - val_accuracy: 0.9077\n",
            "Epoch 44/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0305 - accuracy: 0.9985 - val_loss: 0.3162 - val_accuracy: 0.9077\n",
            "Epoch 45/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0328 - accuracy: 0.9970 - val_loss: 0.2861 - val_accuracy: 0.9077\n",
            "Epoch 46/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0285 - accuracy: 0.9970 - val_loss: 0.2759 - val_accuracy: 0.9231\n",
            "Epoch 47/75\n",
            "6/6 [==============================] - 66s 11s/step - loss: 0.0266 - accuracy: 0.9985 - val_loss: 0.2832 - val_accuracy: 0.9154\n",
            "Epoch 48/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.2962 - val_accuracy: 0.9077\n",
            "Epoch 49/75\n",
            "6/6 [==============================] - 57s 9s/step - loss: 0.0241 - accuracy: 0.9985 - val_loss: 0.2958 - val_accuracy: 0.9077\n",
            "Epoch 50/75\n",
            "6/6 [==============================] - 66s 11s/step - loss: 0.0263 - accuracy: 0.9985 - val_loss: 0.3092 - val_accuracy: 0.9077\n",
            "Epoch 51/75\n",
            "6/6 [==============================] - 57s 10s/step - loss: 0.0322 - accuracy: 0.9985 - val_loss: 0.3360 - val_accuracy: 0.9077\n",
            "Epoch 52/75\n",
            "6/6 [==============================] - 57s 9s/step - loss: 0.0338 - accuracy: 0.9955 - val_loss: 0.3785 - val_accuracy: 0.9000\n",
            "Epoch 53/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0314 - accuracy: 0.9955 - val_loss: 0.3889 - val_accuracy: 0.8962\n",
            "Epoch 54/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0332 - accuracy: 0.9924 - val_loss: 0.3116 - val_accuracy: 0.9115\n",
            "Epoch 55/75\n",
            "6/6 [==============================] - 65s 11s/step - loss: 0.0294 - accuracy: 0.9985 - val_loss: 0.2834 - val_accuracy: 0.9269\n",
            "Epoch 56/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 0.9308\n",
            "Epoch 57/75\n",
            "6/6 [==============================] - 66s 11s/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9308\n",
            "Epoch 58/75\n",
            "6/6 [==============================] - 67s 11s/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.3161 - val_accuracy: 0.9115\n",
            "Epoch 59/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.3128 - val_accuracy: 0.9077\n",
            "Epoch 60/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.3032 - val_accuracy: 0.9192\n",
            "Epoch 61/75\n",
            "6/6 [==============================] - 54s 9s/step - loss: 0.0224 - accuracy: 0.9985 - val_loss: 0.3008 - val_accuracy: 0.9346\n",
            "Epoch 62/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.9192\n",
            "Epoch 63/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 0.9231\n",
            "Epoch 64/75\n",
            "6/6 [==============================] - 54s 9s/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.9192\n",
            "Epoch 65/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.3043 - val_accuracy: 0.9231\n",
            "Epoch 66/75\n",
            "6/6 [==============================] - 65s 11s/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.3104 - val_accuracy: 0.9192\n",
            "Epoch 67/75\n",
            "6/6 [==============================] - 57s 10s/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.3118 - val_accuracy: 0.9192\n",
            "Epoch 68/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.9192\n",
            "Epoch 69/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9077\n",
            "Epoch 70/75\n",
            "6/6 [==============================] - 65s 11s/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.3087 - val_accuracy: 0.9308\n",
            "Epoch 71/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.3124 - val_accuracy: 0.9231\n",
            "Epoch 72/75\n",
            "6/6 [==============================] - 65s 11s/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.3453 - val_accuracy: 0.9038\n",
            "Epoch 73/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.3109 - val_accuracy: 0.9231\n",
            "Epoch 74/75\n",
            "6/6 [==============================] - 54s 9s/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.3206 - val_accuracy: 0.9192\n",
            "Epoch 75/75\n",
            "6/6 [==============================] - 54s 9s/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.3228 - val_accuracy: 0.9192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaPbEQ2RxSDa",
        "outputId": "bf717f0e-dd35-4dfb-c8a0-db1f6a71f048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_loss(history_base_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3iUVdrA4d+ZySST3kmHBAwgEFpoijRhBVHBjr2sZe26lk9cXddVt6i76rp2XXtB1oqKbSkiivTeOyQBUiCQXmbO98cZIIQAKTOZSea5r2suZt4y80wS3uc9XWmtEUII4b8s3g5ACCGEd0kiEEIIPyeJQAgh/JwkAiGE8HOSCIQQws8FeDuApoqLi9Pp6enNOresrIzQ0FD3BuRmbSFGaBtxSozuITG6h7djXLx4caHWOr7BnVprjzyAN4B8YNUx9ivgOWATsALo35j3zc7O1s01a9asZp/bWtpCjFq3jTglRveQGN3D2zECi/QxrquerBp6Cxh3nP1nApmux43ASx6MRQghxDF4LBForecAe49zyETgHVey+hWIUkoleSoeIYQQDfNmY3EKsLPO6xzXNiGEEK1IaQ9OMaGUSge+0lr3amDfV8DftdZzXa9nAPdrrRc1cOyNmOojEhISsqdMmdKseEpLSwkLC2vWua2lLcQIbSNOidE9fCVGpRShoaFYrdaj9mmtUUp5IarGa60YHQ4HZWVl1L+2jxo1arHWekBD53iz11AukFbndapr21G01q8CrwIMGDBAjxw5slkfOHv2bJp7bmtpCzFC24hTYnQPX4lx69athIeHExsbe9QFtaSkhPDwcC9F1jitEaPWmqKiIkpKSsjIyGj0ed6sGpoGXKWMIcB+rfUuL8YjhPBhlZWVDSYBcZhSitjYWCorK5t0nsdKBEqpD4GRQJxSKgf4E2AD0Fq/DEwHxmO6j5YD13oqFiFE+yBJ4MSa8zPyWCLQWl96gv0auNVTn3+U7fPI2PIOjBgB8sckhBCH+M8UE3lL6LTjE6gs9nYkQog2yhcazT3BfxJBaAfzb2mBd+MQQggf4z+JIMw1xUaZJAIhRMtorbnvvvvo1asXWVlZfPTRRwDs2rWL4cOH07dvX3r16sVPP/2Ew+HgmmuuYfDgwWRlZfHMM894OfqjtblJ55ot9GAiyPduHEKIFvvzl6tZk3fg0GuHw9Hg+IKm6JEcwZ/O6dmoYz/99FOWLVvG8uXLKSwsZODAgQwfPpwPPviAsWPH8uCDD+JwOCgvL2fZsmXk5uYyf/58wsPDKS72vepp/ykRSNWQEMJN5s6dy6WXXorVaiUhIYERI0awcOFCBg4cyJtvvskjjzzCypUrCQ8Pp3PnzmzZsoV7772Xb7/9loiICG+HfxT/KRGExKCxoKREIESbV//O3VcGlA0fPpw5c+bw9ddfc80113D33Xdz1VVXsXz5cj7//HNefvllpk6dyhtvvOHtUI/gPyUCi5UaW7i0EQghWmzYsGF89NFHOBwOCgoKmDNnDoMGDWL79u0kJCRwww03cP3117NkyRIKCwtxOp1MnDiRxx9/nCVLlng7/KP4T4kAqA6MIlCqhoQQLXTeeecxb948+vTpg1KKJ598ksTERN5++22eeuopbDYbYWFhvPPOO+Tm5nLttddSW1uLxWLhb3/7m7fDP4rfJQJpLBZCNFdpaSlgRu8+9dRTPPXUU0fsv/rqq7n66quPOm/JkiU+U33VEP+pGgJqbJFSNSSEEPX4VSKoDoySXkNCCFGP/yWCmjKoLvN2KEII4TP8KhHU2CLNE6keEkKIQ/wqEVQHRpknUj0khBCH+GcikJ5DQghxiF8lAqkaEkKIo/lVIpCqISFEazne2gXbtm2jV69erRjN8flVItAWG9gjpWpICCHq8KuRxYCZjlqqhoRo276ZDLtXHnoZ7KgFawsvZ4lZcObfj7l78uTJpKWlceutZoXdRx55hICAAGbNmsW+ffuoqanh8ccfZ+LEiU362MrKSm6++WYWLVpEQEAATz/9NKNGjWL16tVce+21VFdX43Q6+eSTT0hOTubiiy8mJycHh8PBH//4RyZNmtSirw1+mQg6SNWQEKLJJk2axF133XUoEUydOpXvvvuOO+64g4iICAoLCxkyZAgTJkxo0gLyL7zwAkopVq5cybp16zjjjDPYsGEDL7/8MnfeeSeXX3451dXVOBwOpk+fTnJyMl9//TUA+/fvd8t3879EEBYP+Wu9HYUQoiXq3blXtMI8Pv369SM/P5+8vDwKCgqIjo4mMTGR3//+98yZMweLxUJubi579uwhMTGx0e87d+5cbr/9dgC6d+9Op06d2LBhA6eccgp/+ctfyMnJ4fzzzyczM5OsrCzuuece7r//fs4++2yGDRvmlu/mV20EgFQNCSGa7aKLLuLjjz/mo48+YtKkSbz//vsUFBSwePFili1bRkJCApWVlW75rMsuu4xp06YRHBzM+PHjmTlzJl27dmXJkiVkZWXx0EMP8eijj7rls/yvRBDaASr2gaMGrDZvRyOEaEMmTZrEDTfcQGFhIT/++CNTp06lQ4cO2Gw2Zs2axfbt25v8nsOGDeP999/n9NNPZ8OGDezYsYNu3bqxZcsWOnfuzB133MGOHTtYsWIF3bt3JyYmhiuuuIKoqChef/11t3wv/0sEdRexj0j2bixCiDalZ8+elJSUkJKSQlJSEpdffjnnnHMOWVlZDBgwgO7duzf5PW+55RZuvvlmsrKyCAgI4K233iIoKIipU6fy7rvvYrPZSExM5A9/+AMLFy7kvvvuw2KxYLPZeOmll9zyvfwvERxcxL40XxKBEKLJVq483FspLi6OefPmNXjcwbULGpKens6qVasAsNvtvPnmm0cdM3nyZCZPnnzEtrFjxzJ27NjmhH1cfthG4FrEvqzQu3EIIYSP8L8SwaGqIRlUJoTwrJUrV3LllVcC4HQ6sVgsBAUFMX/+fC9HdiT/SwR1q4aEEG2K1rpJffS9LSsri2XLlgG02lKVWusmn+N/VUOBYRAQLF1IhWhj7HY7RUVFzbrQ+QutNUVFRdjt9iad538lAqVM9ZAkAiHalNTUVHJycigoOPr/bmVlZZMvfq2ttWK02+2kpqY26Rz/SwRgqoekakiINsVms5GRkdHgvtmzZ9OvX79WjqhpfDlG/6saAtNzSHoNCSEE4K+JICxeeg0JIYSLRxOBUmqcUmq9UmqTUmpyA/s7KqVmKaWWKqVWKKXGezKeQ0LjTYnA6WyVjxNCCF/msUSglLICLwBnAj2AS5VSPeod9hAwVWvdD7gEeNFT8RwhtANoh5lzSAgh/JwnSwSDgE1a6y1a62pgClB/xQYNRLieRwJ5HoznMBlUJoQQhyhP9clVSl0IjNNaX+96fSUwWGt9W51jkoDvgWggFBijtV7cwHvdCNwIkJCQkD1lypRmxVRaWkpYWBhR+1bQd/kfWdbnMYqjezfrvTzlYIy+ri3EKTG6h8ToHt6OcdSoUYu11gMa3Km19sgDuBB4vc7rK4Hn6x1zN3CP6/kpwBrAcrz3zc7O1s01a9Ys82TPWq3/FKH1iv82+7085VCMPq4txCkxuofE6B7ejhFYpI9xXfVk1VAukFbndaprW13XAVMBtNbzADsQ58GYjLCDE8/JoDIhhPBkIlgIZCqlMpRSgZjG4Gn1jtkBjAZQSp2MSQSevzrbo0BZZVCZEELgwUSgta4FbgO+A9ZiegetVko9qpSa4DrsHuAGpdRy4EPgGlcRxrMsFlmyUgghXDw6xYTWejowvd62h+s8XwMM9WQMxyTzDQkhBOCvI4tB5hsSQggXv0oEFbV1ap1kviEhhAD8KBG8/tMW7v2xnLKqWrPh4HxDMre5EMLP+U0i6NcxirIa+HSpqwdraDzUVkJViXcDE0IIL/ObRNC/YzSdIiy888s2M5jt4CL20k4ghPBzfpMIlFKM6RjAxvxSftlcBNGdzI7ibV6NSwghvM1vEgHA4KQAYkIDeeuXbRDT2Wzcu9WrMQkhhLf5VSIItCouGZjGjLV72FkdDrYQ2LvF22EJIYRX+VUiALhiSCeUUrw3f4cpFUgiEEL4Ob9LBMlRwZzRI4EpC3fiiEqXRCCE8Ht+lwgArj41nf0VNWyoiYd928Dp8HZIQgjhNX6ZCAZnxNA9MZzvdoWCoxoO1J8dWwgh/IdfJgKlFFedks78/ZFmg1QPCSH8mF8mAoAzeiawXSeaF5IIhBB+zG8TQVxYEB1SMqgiUBKBEMKv+W0iABjVPZFtzg5U52/2dihCCOE1fp4I4tmuE6jcs8HboQghhNf4dSLolRzJnoAU7KU7wOn0djhCCOEVfp0ILBZFSGImgboax4E8b4cjhBBe4deJACClS08ANq1d4eVIhBDCO/w+EfTo1ReArRtXejkSIYTwDr9PBBEd0qklgAO50mAshPBPfp8IsFgpCUklrHwHu/dXejsaIYRodZIIAFtcF9LVHmavl2UrhRD+RxIBEJrUlXTLHmat2+PtUIQQotVJIgBUbBdCqGTdps1U1cqU1EII/yKJACAmA4D4mlyWbC/2cjBCCNG6JBHAoYXs0y17WJW738vBCCFE65JEABDZESwB9LQXsSpPEoEQwr9IIgCwBkBUR3raC1mdd8Db0QghRKuSRHBQTGc6sYfNBaWUV9d6OxohhGg1kggOiulMTHUOWmvW7irxdjRCCNFqPJoIlFLjlFLrlVKblFKTj3HMxUqpNUqp1UqpDzwZz3HFdMZWU0I0JayWdgIhhB8J8NQbK6WswAvAb4AcYKFSaprWek2dYzKBB4ChWut9SqkOnornhFw9h/qEFLE6V9oJhBD+w5MlgkHAJq31Fq11NTAFmFjvmBuAF7TW+wC01t6b46HDyQCMiNwjPYeEEH5Faa0988ZKXQiM01pf73p9JTBYa31bnWM+BzYAQwEr8IjW+tsG3utG4EaAhISE7ClTpjQrptLSUsLCwhreqTVDf76S+bZBXF18Ha/8JoQAi2rW57TEcWP0IW0hTonRPSRG9/B2jKNGjVqstR7Q0D6PVQ01UgCQCYwEUoE5SqksrfURw3u11q8CrwIMGDBAjxw5slkfNnv2bI57bs5AsgrzcGhI7NafXimRzfqcljhhjD6iLcQpMbqHxOgevhyjJ6uGcoG0Oq9TXdvqygGmaa1rtNZbMaWDTA/GdHxJfYko2UQgNayR8QRCCD/hyUSwEMhUSmUopQKBS4Bp9Y75HFMaQCkVB3QFtngwpuNL7oty1tAvKE96Dgkh/IbHEoHWuha4DfgOWAtM1VqvVko9qpSa4DrsO6BIKbUGmAXcp7Uu8lRMJ5Rklq08PTKPVVIiEEL4CY+2EWitpwPT6217uM5zDdztenhfVEcIjmaAbTv/2nUAh1Nj9UKDsRBCtCYZWVyXUpDUl841GymvdrC1sMzbEQkhhMdJIqgvuS9RpabBWNoJhBD+QBJBfUmmwbhXQI7MRCqE8AuSCOpLNg3GoyN3SYlACOEXJBHUF9UJ7FEMDNrOqtwDeGrktRBC+ApJBPUpBcl96VK7if0VNeQWV3g7IiGE8ChJBA1J6ku0q8F4lcxEKoRo5yQRNCS5LxZnDd0tO1kj7QRCiHauUYlAKRWqlLK4nndVSk1QStk8G5oXuUYYj4rIk55DQoh2r7ElgjmAXSmVAnwPXAm85amgvC46HexRDLbvlEQghGj3GpsIlNa6HDgfeFFrfRHQ03NheZlSkNSHTMcmdh+opLC0CpxO2P4LVMl6xkKI9qXRiUApdQpwOfC1a5vVMyH5iOS+xJZtJpAadi/4DF4ZDm+eCT897e3IhBDCrRo76dxdmLWFP3PNINoZM1to+5XUF4uzmm8CJ9Nlzi6IzoDINNjxq7cjE0IIt2pUiUBr/aPWeoLW+glXo3Gh1voOD8fmXakDQVkJtdbyXsK9cNtCOPkcyFsKjhpvRyeEEG7T2F5DHyilIpRSocAqYI1S6j7PhuZlUWlw+yIey3iH/5QNA6vNJIfaCti90tvRCSGE2zS2jaCH1voAcC7wDZCB6TnUvsV0pltKPFsLyyitqoW0QWZ7zkLvxiWEEG7U2ERgc40bOBfXGsOAX0zC0zM5AoC1uw5ARAqEJ8HOBV6OSggh3KexieAVYBsQCsxRSnUC/KKDfc/kSABW5+433UpTB0KOJAIhRPvR2Mbi57TWKVrr8drYDozycGw+ISEiiNjQwMMDy9IGQfEOKNnj3cCEEMJNGttYHKmUeloptcj1+CemdNDuKaXokRxxeDH7VGknEEK0L42tGnoDKAEudj0OAG96Kihf0zM5ko17SqiqdUBSH7DYpHpICNFuNHZAWRet9QV1Xv9ZKbXMEwH5op7JEdQ6NRv3lNIrJdIkg51SIhBCtA+NLRFUKKVOO/hCKTUU8JsVW3qluBqMD05JnTZIBpYJIdqNxiaCm4AXlFLblFLbgOeB33ksKh/TKSaEsKCAww3GMrBMCNGONLbX0HKtdR+gN9Bba90PON2jkfkQi0VxclL4kT2HQBqMhRDtQpNWKNNaH3CNMAa42wPx+KyeyZGs3XUAh1NDZCqEJ8vAMiFEu9CSpSqV26JoA3okR1Be7WBbUZnZkCYDy4QQ7UNLEoFfTDFx0MGpJlbluhqMUwfKwDIhRLtw3ESglCpRSh1o4FECJLdSjD4hs0M4dpuFJdv3mQ0ysEwI0U4cNxForcO11hENPMK11o0dg9AuBAZYGNoljhnr8tFaHx5YtnO+t0MTQogWaUnVkN8ZfXICOfsq2LCnFGx26DgENn7v7bCEEKJFJBE0weiTOwDwv7WudoGTz4GCdVC4yYtRCSFEy3g0ESilximl1iulNimlJh/nuAuUUlopNcCT8bRUQoSdrJRIZhxMBN3PMv+u+9J7QQkhRAt5LBEopazAC8CZQA/gUqVUjwaOCwfuBNpEZfvp3TuwdGcxRaVVZjxBcj9Y+5W3wxJCiGbzZIlgELBJa71Fa10NTAEmNnDcY8ATQKUHY3GbMScnoDXMWl9gNnQ/G3IXwYE87wYmhBDN5MmePynAzjqvc4DBdQ9QSvUH0rTWXyul7jvWGymlbgRuBEhISGD27NnNCqi0tLTZ5x6ktSYqSDFlziriSjYRUpbAIGDDl8+SlzK+Re/trhhbQ1uIU2J0D4nRPXw6Rq21Rx7AhcDrdV5fCTxf57UFmA2ku17PBgac6H2zs7N1c82aNavZ59Y1+ZMVuscfv9GVNbVmw3PZWr89wS3v7a4YPa0txCkxuscxY6yt0Xrp+1ovfKNV42lIm/45thJgkT7GddWTVUO5QFqd16mubQeFA72A2a4ZTYcA03y9wRhgzMkdKKt2MH/LXrPh5LNh21yo2OfdwIRoDU4nrPoEXhwCn98MX98Nlfu9HZVoAU8mgoVAplIqQykVCFwCTDu4U2u9X2sdp7VO11qnA78CE7TWizwYk1uc2iWOoAALM9flmw3dzwFnLWz4zruBCeFpOxfCK8Ph49+CJQCG3QvaCdt/8XZkogU8lgi01rXAbcB3wFpgqtZ6tVLqUaXUBE99bmsIDrRy2klx/G/tHlPNldzPzEa6VrqRinbMUWMSQMVeOP81uPlnGH4fBNhh6xxvRydawKPTRGitpwPT6217+BjHjvRkLO42+uQEZqzLZ8OeUrolhpsxBUvfg+pyCAzxdnhCuN+qT2H/Drh0CnQ702yzWM0I+y0/ejc20SIysriZjh5lfLZZtWzzTC9GJYSHOJ0w9xno0AMyxx65L2M45K+G0gLvxCZaTBJBMyVE2OmTFsW3q3abDZ2Ggj0K/vcIzPqbuUOqLvdqjEK4zYZvoWAtDL0LLPUuGxkjzL/bfmr9uIRbSCJogbOzkliZu59thWVgtcFZ/zTVQnOehHcmwN87wpTLoWS3t0MVovm0hrlPQ1RH6HXB0fuT+kJQBGyV6qG2ShJBC5zVOwmAr1a4RhVnXQi/mwP3b4PLP4YhN8GmGfDiKTINhWizoopXmXU3Tr0DrA00K1oDTIlYGozbLEkELZAcFUx2p2i+WrHryB32SMj8DZzxuEkMUWnw0eUw7XaoKvVOsEI0U8cdH0NoPPS74tgHdR4Be7dA8c5jHyMOy18HMx83PbF8gCSCFjqndxLrdpewKb+k4QPiu8J1/4PTfg9L3oXXToeywuZ9WOEmWPwWHNh1wkOFcIu8pcTsWwZDbgFb8LGPyxhu/pVSwYk5auGT62HOU7DwP96OBpBE0GLjs5JQCr5cfpyLc0AgjHkErvwMirfD+xc1vmRQvBN+/pcZxPN8Nnx5J7w2CvKWuSN8IY5Na/jxSWqtITDwuuMf26EHhMRJO0FjLHwN9qyEyDSY9dfm3xi6kSSCFuoQYWdwRgxfrcg7OIfSsXUZBRe+CbuWwdSrTlwsXP8t/KsP/PCwGcU59q9w1TTz/M0zYd3X7vsiQtS35B1YP50dHS8w1Z3Ho5QpFWydYxKIaNiBXTDzL9BlNFzxCdSUwczHvB2VJAJ3OLt3MpsLyli3+xjVQ3V1Hw9nPwubZ8AXt5n+2Q0p3Aif3gCJveCOZXDDTDjlVlMXe/0MiO9ueiTNe0H+4wHkLIKaCm9H0X7sWQ3f/B9kjGBHx/Mad07GcCjZZf52RcO+fxAc1TD+KYjvBoNuhMVvN66EX3kAqss8EpYkAjc4s1ciVoviy+WNXJMg+2oY9RCsmAI//BGcjiP3V+6HDy8FayBMeh9iMo7cH54A13xtlsr87g+w4FX3fJG2atvP8PpoeGEQrPlCEmNLVZXCf68xXUIveB2UtXHndXaNJ/C36qGaClgxFdZ/c9y/vei9y8xkfcPuhtguZuOI+yEkFr65/8hz85bCl3fBO+fC84Pgr6nw9zRY+bFHvoJHp5jwF7FhQZzaJZavVuzivrHdUEqd+KTh90JZPsx73sxcOv4fkDbQTOD16e9g31a46gvT46ghgSFw0dvw7kT46Z/Q/2qw2d37xdqKFR+BLdRcuKZeBenDYNzfvR2V+238wdw5Dr/XVMV4yvR7zV39VV9AWAdgTePOi84w9d5bf4RBNzTvsx215q7ZWWtKvQcfYfHNez9P2rfNNPYufffwzMOdhsK4v0FSnyOPra0ic+MrENPZDMo7KDgKRj8MX95hkkRkmmlE3vQDBIaZUkN8N+hyOkQkQ6pnJmeWROAm5/RO5v8+WcHK3P30To068QlKwZlPQtpg+P4h+M8Y6HMZXYrKIOcbsy/9tOO/h8UCw+6Bdyaa0kX2NW75Lm1KbZUpBZx8Nkx8EZa8bbrlvTKM/mFdoGwkpGRDSn+I6+rZC6gn7d1q7tKrSyG6E/S+2DOfs/Q9WP4hjJh8+A6/sZQyo4zXfWXuko/Xy+hY5j4N8182F8HqOh0qUrLN33rXM48e2exOTqe5G98801RzVRZDRbEppTtrzTFKmVL87pWgLOZvb+D1ULTZ1Pe/MsJ0te11AeSvhd0rIGcRIRV5cMGnR9+w9bsCFv3HTOntqDYlhNEPm/c8UduMm0gicJOxPRN58POVfLk8r3GJAMwfVNaF0HWcuQuY9wJpzhroc5mpO2yMjBFmZOfPz0G/K80kYP5k0wzznzXrIjOwaeB10PM8mP8yjuVfm4vawtfMsb0nwbkve/ZC4glOB3x2k7noJPWB6feZ+vjwRPd9Rk0lzPqLKaGmD4MR/9e89+kzCZa9Bz/8CcY/2bRz85bCj09ArwtNldSBPChYZy6ki96EKZeZ3kmn3W1+xw0NbmtIRTHkLobiHbB/p/m3rND8/CLTTKk7KNxMC7P+GyjdDSgIjjZ37PYoc0G2BgLaVYWjTcks+1qITDGfkzHcxDXnKZj/iikpAIQlQGJvNsSMputJo4+Oz2KFs5+Br+42CT77GggMbdrProUkEbhJZIiN0d0TmLoohztGZxJutzX+5KAw+M2fod8VbJ7+PF3OfqLxd65KwWl3mbvFdV9Bj4aWhW7HVv7X3EF1Hnl4W0gMjPoDy9WpjBw+zFRzLP/AdMO1R8GZTfj5+oKf/wU7f4XzXjUlm5dPg69+D5d84J7vkbPI3I0WbjAXoTMeb/4NRcZwGHwzzH8JThoDXc9o3Hk1FaZKNDTeNKQqZS6wkSlw0mg45XZTdTL3afj0ehNvZIrrQt6R9H0OiMyByFSzrabcVKVt+h/s+BW0qx1OWc15IXHm+5bsMtWxYKoXTxptZhLOPMP8HTVVcBSM/YupGivaDAm9TJsekDd7Nl2PdV5KNvzOe20rkgjc6JZRXfh29W7embedW0ed1PQ3iMtkZ8fz6NLUuv6TJ5i6x7nPmOfuusgdyDN3aSW7TBuEtQnJrTVUlZo7uL6XHTs2ixU6dIcxfzZ31vOeN/XNw4+5RLZv2bXc9DXvca65W1QKTn/IVCeu/G/TqogO7IJfXzA9Tyw28zOrLIZlH5j1NK741FwIW2rMI6ad4Itb4OZ5javfn/EoFK43MTR0AbYGmNJG1kVmArycBWaMzf6dsHkmnUp2w/YpR5+XmAVD7zTVXDFdIDzpyJKEo8b8nZcXQoee7mtni043jzZCEoEb9U6NYlS3eF7/aQvXnJpOaFAr/XgtVjMPzFd3mX7cdet2q0oBbYq+jbF1Dvz6EuQucRWRXUp2mwuQL1k/3Uz9nXXRiY9VCn7zmKkSmPm4uSMccK3nY2yJmkr49EZT4jn7mcMJfsgtsGaaq4poxKE7zmPS2tT9f/eguVMOjjJ10Y5ac6fc93JzF+uu+mib3VTtvDoKpt1m1i843s3J1jnw64sw8IYTJyKLxXTB7j7+iM1zZv7AiH6ZsD/HPLQ2pcSIpOO/n9Vm2lyiOzXqq7VXkgjc7PbRmZz/4i+8++t2bhrRpfU+uM+l5s7x52dNIigtgHn/hgWvA9o0SA252ZQcGlJRbAauLXnb3B12HmlWXkvpD4veMD2TMseank2+YuV/TTVA2uDGHW+xwMTnzQpbX99t7jx9tSqtpsKMIi9YZwYe1b1Ltljh3BfhpaHwxa3moht8jHapfdvN+2yZZXq0TPj34a6LnpTQE37zKHx7v+ne3HmkqYopWG96xNVUmIb+2ipT6ow9yRzfTNpia3N34b5EEoGb9e8YzbDMOF6bs4WrTulESAAhGJwAABsISURBVGAr/YhtdnOhn/Fn+PxWWP2p+c/W6wLTyLXoTVjwmqn/7D3JFJHD4k2d7JbZ8PU9ULrHFKNHPnBkj4/47qav/mc3wk1zW70hq0Flhaah+NTbm9b4a7W5ut2eCx9fB5eGQuYYz8VZV8U+CIo8cbz5a82SkPlrzO/ipAbii8s0dfnf3Af/6m1+DoNvMiU/pxO2/wzLp5i/A2UxU6Rn/7Z1G8oH/850g/ymXsNzWILpFRQQZB4JPc13kZX9vEYSgQfcNSaTC16axwfzd3D9sGPcgXvCwOtMO8HyDyDrYtPdLt7VPDXmTyYRLPqPaVSuL6GXaXxM6X/0PnsEnPcSvHW2KTWc9U/Pfo/GWPO5qdZoTLVQfYEhcNlUePtsMyvsFZ9C+lD3xud0wu7lsGO+qc/eucDUZ8eeZLoF9r3s6KoYrU3p67s/mAv65Z8cP0kNvtEsEznrr6a6a96LZpDh5pnmswLDoOf5MHLyscejeJJScN4rZqLEyDSTvOIyG19NKVqNJAIPyO4Uw9CTYnn5xy1cMaQTdlsrdem0R8J1P5hJ7upXAYUnwug/muRQsA7Ki6A0H8oKzIW+35XHbwxOP81McTHvedd6tY3409Ea8pYcnhMpuZ95RKS0vEF75ScQf7K5m2yO4Ci48nN4czx8MAmu/sL03GgJRy3s+AXWfmnWnyhxjTSPSIHUgabBfeP38O1kmPEY9L6YjntrYfp0c+zebWYysi6nm26uJ6r7B0jqDZdNgZzFMPuvpi2gyyjTYNttvPfvskPjTDdL4dMkEXjIHadnMunVX/lg/g5+e1rGiU9wlw7dj78/MKThu/7GOP2Ppjrm81uJ6nIbOIcd3c3QUWsu/mu+MA2a+3eYSfK0PtyFLzTedDPsc5m5aDWmq2JViRlUtXez6Q664xcTT0sSSmgcXPU5vDEO3j3fTOpXXmhGjO7dagY0hcYffgSFu+q1K0xDbnWp6XVTvs9U+xzIMQOPAoJNo+fJfzJ98g/2MwcYcZ+pE1/wOiz/kM61lZAXaRJ1eCKMe8KMIWlqFU5qtmlLcDr8byyJaDFJBB4yuHMsQzrH8PQPG+iTFkV2p+gWv2dljYMHPl3JTSO60C3RC8Vrmx3OfwXeOoe+yx+CTc9BjwmmhFC8w1RJbJ1jLoYWm7nIj7zf3Jnags1EZnlLTY+kDd+afuHhSdDnEnMXrCymT7fW5gK7exXsWWX+3b/jyFgiO5rzWioiGa6eBm+cabo7ghlIFJ1uLvzFO8xgpLLCw4nMGmgu9rZg04gbHG3mg0obZBJAl9HHvxNP7gfnvgDjn2TOTz8xfPS4ln+PgyQJiGaQROBBz0zqy6Wv/srVbyzg7d8OJLtTMwao1DFjbT6fLc0lLiyQB8/q4aYomyipD9yzltWfP0tPNsDS92Hh62ZfRKoZx9BllLmwB9dLfqkDDs+VUltlksGyD8yo6LnPHP1ZygKxmaanUvbVpn49prN5BIW57ztFp8Mt80xJIDq94R44TqcpCQTY3XexDQzFafXT+aGET5FE4EFJkcFMufEULnvtV676zwLe+u0gBqY3Pxl8sSwXgAXb9rkrxOYJDKWgw1AY+aAZnLT9F3MBjT2p8VU1AUGm62aPiVCyx7RbKAUo829gqOmt1Jz5apojOAqC+x57v8XiG72lhPAASQQelhhpZ8qNQ7jkNVMyeOOagQzpHNvk99lfXsPs9QXYbRZW5e6nrKq29QasHU9gqFmfuSXCExrXMCqE8Ig2NvtW29QhwiSDpEg7V7+xoPHrFtTx7epdVDuc3DryJBxOzdIdxR6IVAjhjyQRtJIO4Xam/u4UeqdGcvuHS3nmhw04nY1fQOWLZXmkx4ZwzdB0LAoWbC3yYLRCCH8iiaAVxYYF8d71g7kwO5V/zdjI7VOWUlHtOOF5u/dXMm9LERP7phBut9EzOZL5W/e2QsRCCH8giaCVBQVYeerC3jxwZnemr9zFpFfnUVBSddxzvlqRh9YwoW8yAIMyYli2s5iq2hMnESGEOBFJBF6glOJ3I7rw2pUD2LinlAtf/oXtRcdelPqLZXlkpUTSJd50mRyUEUNVrZOVOftbK2QhRDsmicCLxvRI4IMbBnOgooYLXvqFVblHX9g3F5SyMnc/E12lAeBQF1SpHhJCuIMkAi/r1zGaj28+laAAK5NemcfqwiOre6Yty0MpOLv34UQQExpIZocwFm6TRCCEaDmPJgKl1Dil1Hql1Cal1OQG9t+tlFqjlFqhlJqhlPLL1SG6xIfx6S2nkhYTwj8WVTLu2Tk89PlKvliWyxfLcjmlcyyJkUeOQB2YEcPibftwNKHnkRBCNMRjiUApZQVeAM4EegCXKqXqz4uwFBigte4NfAw0cbXr9iMhws7Um07hvEwb8eFBfLYklzunLGNbUfkR1UIHDc6IoaSqlrW7DnghWiFEe+LJoamDgE1a6y0ASqkpwERgzcEDtNaz6hz/K3CFB+PxeRF2GxO6BDJy5GBqHU7W7S5hc0Ep47OOXm7vYDvBgq176ZXipiUGhRB+SWntmaoFpdSFwDit9fWu11cCg7XWtx3j+OeB3VrrxxvYdyNwI0BCQkL2lCkNLFLdCKWlpYSFuXGyMg9oSoz3/lhOpwgLt/dr/YnL2tvP0lskRveQGE9s1KhRi7XWAxrcqbX2yAO4EHi9zusrgeePcewVmBJB0IneNzs7WzfXrFmzmn1ua2lKjL//aKnu/+j32ul0ei6gY2hvP0tvkRjdQ2I8MWCRPsZ11ZONxblA3fXxUl3bjqCUGgM8CEzQWh9/ZJU4wqD0GIrKqtlccOwxCEIIcSKebCNYCGQqpTIwCeAS4LK6Byil+gGvYKqQ8j0YS7s0KMO0E/xt+lpOy4wjPS6UznGhpEWHYLG0cClIIYTf8Fgi0FrXKqVuA74DrMAbWuvVSqlHMUWUacBTQBjwX2Xmsd+htZ7gqZjam4y4UM7okcC8zUXMWHc4j2Z2COOeM7oytmciqqVrAwsh2j2PTmivtZ4OTK+37eE6z8d48vPbO6UUr141AK01RWXVbC0sY/3uEt78eSs3vbeErJRI7h3bjeGZcZIQhBDHJCOL2wGlFHFhQQxMj+GKIZ347q7h/OOiPuwtq+bqNxZwz3+XH2yUF0KIo0giaIcCrBYuzE5l5r0juHF4Zz5dksu0ZiyGI4TwD5II2rGgACv3j+tOv45RPPzFavIPVHo7JCGED5JE0M5ZLYp/XNSHyhoHD3y6UqqIhBBHkUTgB7rEh/F/47ozY10+Hy/OadK5xeXV/LihgOpap4eiE0J4m0d7DQnfce2p6Xy3ejePfrmGoSfFkRwVfNzjd+2v4PWftvLhgh2UVzvonhjO3y/oTd+0qFaKWAjRWqRE4CcsFsU/LuyDQ2tufm8xm/JLGzxuS0Ep9/13OcOfnMVbv2xjbM9EnrygN8XlNZz/4s889tUayqtrWzl6IYQnSYnAj3SMDeGfF/Xh/z5Zwbhn53Dt0HTuGJ1JuN3GpvxSnp+5kWnL8wgMsHD54E5cd1oGaTEhAIzLSuSJb9bxn7lb+X7Nbi5IdzLSu19HCOEmkgj8zJlZSQzMiOGpb9fz+tytfLY0j+xOUXy/Zg/2ACs3DOvMDcM7ExcWdMR5EXYbfzkviwl9kvnDZyt5dkkFy8oW8MezexxaS1kI0TZJ1ZAfigsL4okLe/P5LUNJiwnmp42F3Di8M3PvH8UD408+KgnUNbhzLN/eNZxLuweyeNs+xj07h79OX0txeXUrfgMhhDtJicCP9UmL4rNbhqK1btIUFDarhbHpNu6+4BT+8d16XvtpC+/O286kgWn8dmgGHWNDPBi1EMLdpEQgmj0PUXy4KVl8c+cwxmcl8f787Yz8xyxueX8xG/aUuDlKIYSnSCIQLdY9MYJ/XtyHufefzu9GdGHuxkLOeu4n/j1jIzUOGX8ghK+TRCDcJiHCzv3jujPr3pGM7ZnIP3/YwLkv/MzqvP3eDk0IcRzSRiDcLjYsiOcv68/ZvXfz0OermPj8z2SlRuJwamocmlqHk5CgAFKi7KREBZMSFUy/jtH0OcZgNYdTs62oDLvNSrg9gLDAAFl4Rwg3kkQgPGZcr0SGdI7hn99vYGthGQFWRYDFgs2qKK2qZd3uEmaszafKNX3FWb2T+MP4k0lxjXrWWjN7fQFPfLuOdbuPbHOICwvijtEnccXgTpIUhGghSQTCo6JCAnns3F7H3K+1prC0mvfnb+el2ZuZsXYPN43owtCT4nj6+w3M21JEx5gQHju3FzaLSSAHKmtZuHUvD3+xms+X5vL3C3rTNSG8Fb+VEO2LJALhVUop4sODuGtMVy4akMZfp6/l2f9t5Nn/bSQ2NJA/T+jJpYM6EhhwZHOW1ppPl+Ty+NdrOOu5n7hpRBdGdI0nIcJOfHgQdpvVS99IiLZHEoHwGSlRwbxwWX+uGlLEhj0lnNsvhXC7rcFjlVJckJ3KyG7xPPbVGv49cxP/nrnp0P6oEBvdI50EpRUxpHOMLNUpxHFIIhA+Z3DnWAZ3jm3UsbFhQTx7ST9uH53Jzr3l5JdUkX+gkh17y/lyWQ6XvvYr6bEhTBrYkUkD04gJDfRw9EK0PZIIRLvQJT7sqDmPxkTvpTQ6kykLdvLEt+t4bsZGLhmUxg3DOp9wGm4h/IkkAtFuBVoV5/dP5fz+qWzYU8IrP5qpMN77dTvn9UvhqlPS6ZkcIdVGwu9JIhB+oWtCOP+8uA+//00mr83ZwpSFO5m6KIfU6GDO6JHIGT0TGNApmgCrjLEU/kcSgfArqdEh/HliL+4c05Uf1uzmu9V7eG/+dt74eSvBNivdk8LpkRRBj+QI+qRG0SMpQsYpiHZPEoHwSzGhga4G5I6UVtXy4/oCFm3fy5q8A0xbnsf783cAZuDayG7xjOwWT/+O0SgFtQ6NU2usFkVyZLAkCtHmSSIQfi8sKICzeidxVu8kwIxRyNlXwYKte5m9oYAf1uzh48U5DZ4bEmilW2I43RPDyewQTlx4ENEhNqKCA4kMtmG1Hk4SCkiMsEviED5HEoEQ9SilSIsJIS0mhAuyU6l1OFmeU8zaXSVYLco8lKKq1smGPSWs232Ab1bt5sPynSd87/jwIMac3IHf9Ejg1C5xrfBthDgxSQRCnECA1UJ2pxiyO8Uc8xitNUVl1ewrq6a4oobi8hr2V9TgdOpDx1Q5nPy6pYgvl+/iwwU7CbZZiQp0ErlsDjarmYMpIthGYoSdxEg7iRF24sKCiA61ERkcSHSIDaUUecUV7Npfya79FVTVOOmVEknv1EhCg9z737myxsGvW4r4YVsNS75fz97yavaV1aCUGfyXEh1McmQwIUFW9pZVU1RaTWFpFTUOTbfEMHokRdI5PhSbNMD7PEkEQriBUoq4sKDjLvMJcOWQTlTVOvh1y15mrctnzZadRMWEUOvUVNc6KSipYlXufgpLm7b0p0WZnlG9UiJJijQJJD48iNjQQKJDTTVVZLDtuFNvVNU62L2/knmbi5ixLp+5GwupqHGY77d+E9EhJhk5nJrv1+yhuvbotSYsCqwWRY3DJMDAAAs9kiK4eEAa5/VLIThQpv7wRZIIhGhlQQFWRnSNZ0TXeGbPLmDkyAFHHVNd6yS/pJKi0mr2lVezv6KGfWXVODUkR9lJigwmKcpOgMXC8pxilu0oZtnOYn7cUEBRaRV1CiJHCAywEGG3EW4PINweQEiglf0Vtew5UMnessPJJyUqmIsGpHJ69w6UbF/N+DEjsdZp23A6TQkor7iCsupa4sJM0okKCURrzZbCMtbkHWDNrgPM2VDAHz5byRPfruOSgWlcOqgj4fYAyqsdVNY4qKp1EmG3ERceSEhg4y9JlTUOcvaVs2NvOSvya+m2v4LECLuMC2kGSQRC+KDAAAup0SGkRp94/edR3TowqluHQ68dTs2+8moKSqooLK1if4Wppiour+FARQ0HKmspraqlpLKG0spakiLt9E2LIslVHZWVGkn3xPBDF9TZu9YckQQALBYzWWB8eEMlIEXXhHC6JoRzbr8UHjizOwu37eOtX7by+tytvDJnyzG/S7DNSlx4IDEhgUSGBBLlKsk4tD4U+4GKGvYcqGT3gUp0nYT37JKZxIQG0iMpgq4J4WTEhdApNpT02FCSo+wyRuQ4JBEI0c5YLY2rpmotSikGZcQwKCOGvOIKvl+9G6UUwYFWgm1WAgMsHKioodDVxlBYWkVxeQ3FFTXsKCqjuKKGAIsyJZlgGxH2ADrHx9IpJpSOscF0jAll8ZIl2BO7HCqFfLBgO5U1h6uuLMo01CdG2OngmqE20NUuE2C1YLNasNssBNushARasdushzoFWFz/2gIsBFotBAYoAq3WQx0HLIpDx1iUwmIxvwOnNiW7GoeT6lonG/c50OvzKXUl4lqHk6iQQGLDAokNNW1BEXYbQQGWVi/VeDQRKKXGAf8CrMDrWuu/19sfBLwDZANFwCSt9TZPxiSE8J7kqGCuGZrh9vct2Wpl5Cnph15rrckvqWJbYRnb95azc2+5qxRRxY6icpZs30e1w0mtQ1PrdB5q0/C4+QtPeIjVoggNtBIaFECA1SSXgwnpztGZnNMn2e1heSwRKKWswAvAb4AcYKFSaprWek2dw64D9mmtT1JKXQI8AUzyVExCCP+glCIhwk5ChL1RM9lqramqdVJR7aCixkF5tQOH0wwcdDjN42CD/sE7/No6+5364HPTfuLUGqVMFV+g1ZR61q9ZxamD+hMeFHDoIr+vrIaisqpDbUEllbWUVbke1Q6cTo1Da5zavG9USMPTsreUJ0sEg4BNWustAEqpKcBEoG4imAg84nr+MfC8UkpprVspPQshhEkcdpupEor20GfY8tfSv+OR794h3A54f3U95alrrlLqQmCc1vp61+srgcFa69vqHLPKdUyO6/Vm1zGF9d7rRuBGgISEhOwpU6Y0K6bS0lLCwsJOfKAXtYUYoW3EKTG6h8ToHt6OcdSoUYu11kd3UaONNBZrrV8FXgUYMGCAHjlyZLPeZ/bs2TT33NbSFmKEthGnxOgeEqN7+HKMnuxPlQuk1Xmd6trW4DFKqQAgEtNoLIQQopV4MhEsBDKVUhlKqUDgEmBavWOmAVe7nl8IzJT2ASGEaF0eqxrSWtcqpW4DvsN0H31Da71aKfUosEhrPQ34D/CuUmoTsBeTLIQQQrQij7YRaK2nA9PrbXu4zvNK4CJPxiCEEOL4ZMy1EEL4OUkEQgjh5zw2jsBTlFIFwPZmnh4HFJ7wKO9qCzFC24hTYnQPidE9vB1jJ611fEM72lwiaAml1KJjDajwFW0hRmgbcUqM7iExuocvxyhVQ0II4eckEQghhJ/zt0TwqrcDaIS2ECO0jTglRveQGN3DZ2P0qzYCIYQQR/O3EoEQQoh6JBEIIYSf85tEoJQap5Rar5TapJSa7O14AJRSbyil8l3rMhzcFqOU+kEptdH1r6fWyWhsjGlKqVlKqTVKqdVKqTt9LU6llF0ptUAptdwV459d2zOUUvNdv/OPXJMfepVSyqqUWqqU+soXY1RKbVNKrVRKLVNKLXJt85nfdZ04o5RSHyul1iml1iqlTvGlOJVS3Vw/w4OPA0qpu3wpxrr8IhHUWTbzTKAHcKlSqod3owLgLWBcvW2TgRla60xghuu1N9UC92itewBDgFtdPztfirMKOF1r3QfoC4xTSg3BLH36jNb6JGAfZmlUb7sTWFvntS/GOEpr3bdOn3df+l0f9C/gW611d6AP5mfqM3Fqrde7foZ9MWuylwOf+VKMR9Bat/sHcArwXZ3XDwAPeDsuVyzpwKo6r9cDSa7nScB6b8dYL94vMOtQ+2ScQAiwBBiMGcUZ0NDfgJdiS8X85z8d+ApQPhjjNiCu3jaf+l1j1i3Ziquzi6/GWSeuM4CffTlGvygRACnAzjqvc1zbfFGC1nqX6/luIMGbwdSllEoH+gHz8bE4XVUuy4B84AdgM1Csta51HeILv/Nngf8DnK7XsfhejBr4Xim12LVELPjY7xrIAAqAN13VbK8rpULxvTgPugT40PXcJ2P0l0TQJmlz2+AT/XuVUmHAJ8BdWusDdff5Qpxaa4c2xfBUYBDQ3Zvx1KeUOhvI11ov9nYsJ3Ca1ro/phr1VqXU8Lo7feF3jZk+vz/wkta6H1BGvSoWH4kTV5vPBOC/9ff5SozgP4mgMctm+oo9SqkkANe/+V6OB6WUDZME3tdaf+ra7HNxAmiti4FZmGqWKNcSqOD93/lQYIJSahswBVM99C98K0a01rmuf/MxddqD8L3fdQ6Qo7We73r9MSYx+FqcYBLqEq31HtdrX4zRbxJBY5bN9BV1l++8GlMn7zVKKYVZSW6t1vrpOrt8Jk6lVLxSKsr1PBjThrEWkxAudB3m1Ri11g9orVO11umYv7+ZWuvL8aEYlVKhSqnwg88xddur8KHfNYDWejewUynVzbVpNLAGH4vT5VIOVwuBb8boH43FroaZ8cAGTN3xg96OxxXTh8AuoAZzl3Mdpt54BrAR+B8Q4+UYT8MUX1cAy1yP8b4UJ9AbWOqKcRXwsGt7Z2ABsAlTNA/y9u/cFddI4Ctfi9EVy3LXY/XB/ye+9LuuE2tfYJHrd/45EO1rcQKhQBEQWWebT8V48CFTTAghhJ/zl6ohIYQQxyCJQAgh/JwkAiGE8HOSCIQQws9JIhBCCD8niUCIepRSjnozR7ptYjClVHrd2WaF8AUBJz5ECL9Toc10FUL4BSkRCNFIrrn6n3TN179AKXWSa3u6UmqmUmqFUmqGUqqja3uCUuoz1zoJy5VSp7reyqqUes21dsL3rtHQQniNJAIhjhZcr2poUp19+7XWWcDzmNlEAf4NvK217g28Dzzn2v4c8KM26yT0x4zWBcgEXtBa9wSKgQs8/H2EOC4ZWSxEPUqpUq11WAPbt2EWwNnimohvt9Y6VilViJljvsa1fZfWOk4pVQCkaq2r6rxHOvCDNguToJS6H7BprR/3/DcTomFSIhCiafQxnjdFVZ3nDqStTniZJAIhmmZSnX/nuZ7/gplRFOBy4CfX8xnAzXBo4ZzI1gpSiKaQOxEhjhbsWu3soG+11ge7kEYrpVZg7uovdW27HbNa1n2YlbOudW2/E3hVKXUd5s7/Zsxss0L4FGkjEKKRXG0EA7TWhd6ORQh3kqohIYTwc1IiEEIIPyclAiGE8HOSCIQQws9JIhBCCD8niUAIIfycJAIhhPBz/w8TslA0K2u2yAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDiFRYEgB01W"
      },
      "source": [
        "### **Fine Tuning Method**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD1dQz6WnmIz"
      },
      "source": [
        "**Image Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EApcJT87lUQq",
        "outputId": "b86ef5a9-bbda-4b45-bb7c-f4c79fc13005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "dataset_dir = '/content/'\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "\n",
        "train_augmented_iteration = train_datagen.flow_from_directory(os.path.join(dataset_dir, 'train'), class_mode='binary', batch_size=128, target_size=(224, 224))\n",
        "test_augmented_iteration = test_datagen.flow_from_directory(os.path.join(dataset_dir, 'test'), class_mode='binary', batch_size=128, target_size=(224, 224))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 662 images belonging to 2 classes.\n",
            "Found 260 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxRasE8c_ldC"
      },
      "source": [
        "**Fine Tuning with RMSProp Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YfzbpROnaOx"
      },
      "source": [
        "from tensorflow.keras.applications import vgg16\n",
        "from tensorflow.keras.layers import Dropout"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fue5L5AT_z5-",
        "outputId": "505ad911-45bb-4d42-9fd5-7620251eb3f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "vgg_conv = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in vgg_conv.layers[:]:\n",
        "  layer.trainable = False\n",
        "\n",
        "fine_tuned_model = Sequential()\n",
        "\n",
        "fine_tuned_model.add(vgg_conv)\n",
        "\n",
        "fine_tuned_model.add(Flatten())\n",
        "fine_tuned_model.add(Dense(1024, activation='relu'))\n",
        "fine_tuned_model.add(Dropout(0.5))\n",
        "fine_tuned_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "fine_tuned_model.summary()\n",
        "\n",
        "opt = RMSprop(learning_rate=0.0001, momentum=0.9)\n",
        "\n",
        "fine_tuned_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 1025      \n",
            "=================================================================\n",
            "Total params: 40,406,849\n",
            "Trainable params: 25,692,161\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKYLHYsTA33h",
        "outputId": "9e046d84-1eec-439d-dd8f-a68517c477dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_model = fine_tuned_model.fit_generator(train_augmented_iteration, steps_per_epoch=len(train_augmented_iteration), validation_data=test_augmented_iteration, validation_steps=len(test_augmented_iteration), epochs=50)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "6/6 [==============================] - 24s 4s/step - loss: 1.1515 - accuracy: 0.7145 - val_loss: 0.2460 - val_accuracy: 0.9231\n",
            "Epoch 2/50\n",
            "6/6 [==============================] - 20s 3s/step - loss: 0.2580 - accuracy: 0.9184 - val_loss: 0.2839 - val_accuracy: 0.9115\n",
            "Epoch 3/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.3281 - accuracy: 0.9079 - val_loss: 0.1821 - val_accuracy: 0.9577\n",
            "Epoch 4/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.1717 - accuracy: 0.9592 - val_loss: 0.2307 - val_accuracy: 0.9423\n",
            "Epoch 5/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.1454 - accuracy: 0.9517 - val_loss: 0.2341 - val_accuracy: 0.9423\n",
            "Epoch 6/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.1285 - accuracy: 0.9562 - val_loss: 0.2155 - val_accuracy: 0.9538\n",
            "Epoch 7/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0810 - accuracy: 0.9773 - val_loss: 0.2009 - val_accuracy: 0.9654\n",
            "Epoch 8/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.1069 - accuracy: 0.9743 - val_loss: 0.2062 - val_accuracy: 0.9654\n",
            "Epoch 9/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0711 - accuracy: 0.9743 - val_loss: 0.2046 - val_accuracy: 0.9500\n",
            "Epoch 10/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0538 - accuracy: 0.9789 - val_loss: 0.1593 - val_accuracy: 0.9654\n",
            "Epoch 11/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.0469 - accuracy: 0.9804 - val_loss: 0.2187 - val_accuracy: 0.9385\n",
            "Epoch 12/50\n",
            "6/6 [==============================] - 17s 3s/step - loss: 0.0350 - accuracy: 0.9894 - val_loss: 0.1750 - val_accuracy: 0.9692\n",
            "Epoch 13/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0876 - accuracy: 0.9743 - val_loss: 0.1941 - val_accuracy: 0.9692\n",
            "Epoch 14/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0599 - accuracy: 0.9743 - val_loss: 0.2476 - val_accuracy: 0.9423\n",
            "Epoch 15/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0293 - accuracy: 0.9879 - val_loss: 0.2066 - val_accuracy: 0.9615\n",
            "Epoch 16/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0244 - accuracy: 0.9909 - val_loss: 0.1940 - val_accuracy: 0.9577\n",
            "Epoch 17/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0280 - accuracy: 0.9940 - val_loss: 0.2202 - val_accuracy: 0.9538\n",
            "Epoch 18/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0369 - accuracy: 0.9879 - val_loss: 0.1411 - val_accuracy: 0.9731\n",
            "Epoch 19/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0367 - accuracy: 0.9819 - val_loss: 0.1457 - val_accuracy: 0.9692\n",
            "Epoch 20/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0808 - accuracy: 0.9789 - val_loss: 0.2326 - val_accuracy: 0.9500\n",
            "Epoch 21/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0422 - accuracy: 0.9879 - val_loss: 0.1555 - val_accuracy: 0.9731\n",
            "Epoch 22/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0398 - accuracy: 0.9894 - val_loss: 0.1675 - val_accuracy: 0.9654\n",
            "Epoch 23/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.0172 - accuracy: 0.9940 - val_loss: 0.1694 - val_accuracy: 0.9654\n",
            "Epoch 24/50\n",
            "6/6 [==============================] - 21s 4s/step - loss: 0.0202 - accuracy: 0.9909 - val_loss: 0.1488 - val_accuracy: 0.9731\n",
            "Epoch 25/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.0382 - accuracy: 0.9864 - val_loss: 0.1893 - val_accuracy: 0.9692\n",
            "Epoch 26/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.0234 - accuracy: 0.9940 - val_loss: 0.2517 - val_accuracy: 0.9538\n",
            "Epoch 27/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0552 - accuracy: 0.9804 - val_loss: 0.1720 - val_accuracy: 0.9692\n",
            "Epoch 28/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0331 - accuracy: 0.9849 - val_loss: 0.1681 - val_accuracy: 0.9731\n",
            "Epoch 29/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0365 - accuracy: 0.9864 - val_loss: 0.1899 - val_accuracy: 0.9769\n",
            "Epoch 30/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0203 - accuracy: 0.9879 - val_loss: 0.2212 - val_accuracy: 0.9654\n",
            "Epoch 31/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0360 - accuracy: 0.9879 - val_loss: 0.2038 - val_accuracy: 0.9692\n",
            "Epoch 32/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0411 - accuracy: 0.9864 - val_loss: 0.2186 - val_accuracy: 0.9731\n",
            "Epoch 33/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0346 - accuracy: 0.9909 - val_loss: 0.2582 - val_accuracy: 0.9538\n",
            "Epoch 34/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0316 - accuracy: 0.9849 - val_loss: 0.1826 - val_accuracy: 0.9731\n",
            "Epoch 35/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0369 - accuracy: 0.9879 - val_loss: 0.1842 - val_accuracy: 0.9692\n",
            "Epoch 36/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0704 - accuracy: 0.9849 - val_loss: 0.3724 - val_accuracy: 0.9346\n",
            "Epoch 37/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.1357 - accuracy: 0.9517 - val_loss: 0.4369 - val_accuracy: 0.9231\n",
            "Epoch 38/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.1028 - accuracy: 0.9713 - val_loss: 0.6321 - val_accuracy: 0.9038\n",
            "Epoch 39/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0781 - accuracy: 0.9743 - val_loss: 0.3175 - val_accuracy: 0.9500\n",
            "Epoch 40/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0184 - accuracy: 0.9955 - val_loss: 0.2789 - val_accuracy: 0.9654\n",
            "Epoch 41/50\n",
            "6/6 [==============================] - 20s 3s/step - loss: 0.0258 - accuracy: 0.9909 - val_loss: 0.2583 - val_accuracy: 0.9654\n",
            "Epoch 42/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0566 - accuracy: 0.9864 - val_loss: 0.4038 - val_accuracy: 0.9308\n",
            "Epoch 43/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0275 - accuracy: 0.9909 - val_loss: 0.2493 - val_accuracy: 0.9731\n",
            "Epoch 44/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0082 - accuracy: 0.9955 - val_loss: 0.2541 - val_accuracy: 0.9692\n",
            "Epoch 45/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0206 - accuracy: 0.9970 - val_loss: 0.2965 - val_accuracy: 0.9577\n",
            "Epoch 46/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.0122 - accuracy: 0.9970 - val_loss: 0.2348 - val_accuracy: 0.9692\n",
            "Epoch 47/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.0071 - accuracy: 0.9970 - val_loss: 0.2670 - val_accuracy: 0.9615\n",
            "Epoch 48/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0028 - accuracy: 0.9985 - val_loss: 0.2464 - val_accuracy: 0.9731\n",
            "Epoch 49/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0232 - accuracy: 0.9955 - val_loss: 0.2962 - val_accuracy: 0.9538\n",
            "Epoch 50/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0122 - accuracy: 0.9955 - val_loss: 0.2417 - val_accuracy: 0.9731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7e4zB4hDcwm",
        "outputId": "f375c46d-72a3-48a8-c0f1-8ea679e8a5b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plot_loss(history_model)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnadRSelOtML"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "history_dataframe = pd.DataFrame(history_model.history)\n",
        "history_dataframe['epoch'] = history_model.epoch"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heflxEZgD3T3",
        "outputId": "7cbe2601-25d9-4102-a4ff-5f881bdf2733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.036891</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.141145</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.036678</td>\n",
              "      <td>0.981873</td>\n",
              "      <td>0.145738</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.020238</td>\n",
              "      <td>0.990937</td>\n",
              "      <td>0.148840</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.042236</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.155499</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.053793</td>\n",
              "      <td>0.978852</td>\n",
              "      <td>0.159293</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.039815</td>\n",
              "      <td>0.989426</td>\n",
              "      <td>0.167536</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.033119</td>\n",
              "      <td>0.984894</td>\n",
              "      <td>0.168054</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.017203</td>\n",
              "      <td>0.993958</td>\n",
              "      <td>0.169443</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.055166</td>\n",
              "      <td>0.980363</td>\n",
              "      <td>0.172033</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.034990</td>\n",
              "      <td>0.989426</td>\n",
              "      <td>0.175037</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.328145</td>\n",
              "      <td>0.907855</td>\n",
              "      <td>0.182070</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.031564</td>\n",
              "      <td>0.984894</td>\n",
              "      <td>0.182563</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.036917</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.184233</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.038220</td>\n",
              "      <td>0.986405</td>\n",
              "      <td>0.189299</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.036508</td>\n",
              "      <td>0.986405</td>\n",
              "      <td>0.189898</td>\n",
              "      <td>0.976923</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.024403</td>\n",
              "      <td>0.990937</td>\n",
              "      <td>0.193965</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.087646</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.194083</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.080980</td>\n",
              "      <td>0.977341</td>\n",
              "      <td>0.200884</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.035983</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.203840</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.071147</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.204627</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.106919</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.206196</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.029287</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.206646</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.128486</td>\n",
              "      <td>0.956193</td>\n",
              "      <td>0.215512</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.986405</td>\n",
              "      <td>0.218613</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.046927</td>\n",
              "      <td>0.980363</td>\n",
              "      <td>0.218742</td>\n",
              "      <td>0.938462</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.027984</td>\n",
              "      <td>0.993958</td>\n",
              "      <td>0.220170</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.020287</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.221205</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.171666</td>\n",
              "      <td>0.959215</td>\n",
              "      <td>0.230689</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.080776</td>\n",
              "      <td>0.978852</td>\n",
              "      <td>0.232648</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.145379</td>\n",
              "      <td>0.951662</td>\n",
              "      <td>0.234050</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.012207</td>\n",
              "      <td>0.996979</td>\n",
              "      <td>0.234758</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.012204</td>\n",
              "      <td>0.995468</td>\n",
              "      <td>0.241711</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.151487</td>\n",
              "      <td>0.714502</td>\n",
              "      <td>0.246014</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.002768</td>\n",
              "      <td>0.998489</td>\n",
              "      <td>0.246404</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.059893</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.247594</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.027452</td>\n",
              "      <td>0.990937</td>\n",
              "      <td>0.249323</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.023356</td>\n",
              "      <td>0.993958</td>\n",
              "      <td>0.251703</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.008224</td>\n",
              "      <td>0.995468</td>\n",
              "      <td>0.254138</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.034606</td>\n",
              "      <td>0.990937</td>\n",
              "      <td>0.258239</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.025836</td>\n",
              "      <td>0.990937</td>\n",
              "      <td>0.258280</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.007107</td>\n",
              "      <td>0.996979</td>\n",
              "      <td>0.266969</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.018388</td>\n",
              "      <td>0.995468</td>\n",
              "      <td>0.278945</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.258043</td>\n",
              "      <td>0.918429</td>\n",
              "      <td>0.283871</td>\n",
              "      <td>0.911538</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.023193</td>\n",
              "      <td>0.995468</td>\n",
              "      <td>0.296193</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.020559</td>\n",
              "      <td>0.996979</td>\n",
              "      <td>0.296503</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.078068</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.317547</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.070379</td>\n",
              "      <td>0.984894</td>\n",
              "      <td>0.372404</td>\n",
              "      <td>0.934615</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.056602</td>\n",
              "      <td>0.986405</td>\n",
              "      <td>0.403830</td>\n",
              "      <td>0.930769</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.135743</td>\n",
              "      <td>0.951662</td>\n",
              "      <td>0.436899</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.102783</td>\n",
              "      <td>0.971299</td>\n",
              "      <td>0.632065</td>\n",
              "      <td>0.903846</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy  epoch\n",
              "17  0.036891  0.987915  0.141145      0.973077     17\n",
              "18  0.036678  0.981873  0.145738      0.969231     18\n",
              "23  0.020238  0.990937  0.148840      0.973077     23\n",
              "20  0.042236  0.987915  0.155499      0.973077     20\n",
              "9   0.053793  0.978852  0.159293      0.965385      9\n",
              "21  0.039815  0.989426  0.167536      0.965385     21\n",
              "27  0.033119  0.984894  0.168054      0.973077     27\n",
              "22  0.017203  0.993958  0.169443      0.965385     22\n",
              "26  0.055166  0.980363  0.172033      0.969231     26\n",
              "11  0.034990  0.989426  0.175037      0.969231     11\n",
              "2   0.328145  0.907855  0.182070      0.957692      2\n",
              "33  0.031564  0.984894  0.182563      0.973077     33\n",
              "34  0.036917  0.987915  0.184233      0.969231     34\n",
              "24  0.038220  0.986405  0.189299      0.969231     24\n",
              "28  0.036508  0.986405  0.189898      0.976923     28\n",
              "15  0.024403  0.990937  0.193965      0.957692     15\n",
              "12  0.087646  0.974320  0.194083      0.969231     12\n",
              "6   0.080980  0.977341  0.200884      0.965385      6\n",
              "30  0.035983  0.987915  0.203840      0.969231     30\n",
              "8   0.071147  0.974320  0.204627      0.950000      8\n",
              "7   0.106919  0.974320  0.206196      0.965385      7\n",
              "14  0.029287  0.987915  0.206646      0.961538     14\n",
              "5   0.128486  0.956193  0.215512      0.953846      5\n",
              "31  0.041111  0.986405  0.218613      0.973077     31\n",
              "10  0.046927  0.980363  0.218742      0.938462     10\n",
              "16  0.027984  0.993958  0.220170      0.953846     16\n",
              "29  0.020287  0.987915  0.221205      0.965385     29\n",
              "3   0.171666  0.959215  0.230689      0.942308      3\n",
              "19  0.080776  0.978852  0.232648      0.950000     19\n",
              "4   0.145379  0.951662  0.234050      0.942308      4\n",
              "45  0.012207  0.996979  0.234758      0.969231     45\n",
              "49  0.012204  0.995468  0.241711      0.973077     49\n",
              "0   1.151487  0.714502  0.246014      0.923077      0\n",
              "47  0.002768  0.998489  0.246404      0.973077     47\n",
              "13  0.059893  0.974320  0.247594      0.942308     13\n",
              "42  0.027452  0.990937  0.249323      0.973077     42\n",
              "25  0.023356  0.993958  0.251703      0.953846     25\n",
              "43  0.008224  0.995468  0.254138      0.969231     43\n",
              "32  0.034606  0.990937  0.258239      0.953846     32\n",
              "40  0.025836  0.990937  0.258280      0.965385     40\n",
              "46  0.007107  0.996979  0.266969      0.961538     46\n",
              "39  0.018388  0.995468  0.278945      0.965385     39\n",
              "1   0.258043  0.918429  0.283871      0.911538      1\n",
              "48  0.023193  0.995468  0.296193      0.953846     48\n",
              "44  0.020559  0.996979  0.296503      0.957692     44\n",
              "38  0.078068  0.974320  0.317547      0.950000     38\n",
              "35  0.070379  0.984894  0.372404      0.934615     35\n",
              "41  0.056602  0.986405  0.403830      0.930769     41\n",
              "36  0.135743  0.951662  0.436899      0.923077     36\n",
              "37  0.102783  0.971299  0.632065      0.903846     37"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQZDsf_dP_EG",
        "outputId": "6bdeb7fe-11e4-4568-b8f5-96eb38ff57ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_dataframe.sort_values(by='val_accuracy', ascending=False)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.036508</td>\n",
              "      <td>0.986405</td>\n",
              "      <td>0.189898</td>\n",
              "      <td>0.976923</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.012204</td>\n",
              "      <td>0.995468</td>\n",
              "      <td>0.241711</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.031564</td>\n",
              "      <td>0.984894</td>\n",
              "      <td>0.182563</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.986405</td>\n",
              "      <td>0.218613</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.033119</td>\n",
              "      <td>0.984894</td>\n",
              "      <td>0.168054</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.020238</td>\n",
              "      <td>0.990937</td>\n",
              "      <td>0.148840</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.042236</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.155499</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.036891</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.141145</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.027452</td>\n",
              "      <td>0.990937</td>\n",
              "      <td>0.249323</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.002768</td>\n",
              "      <td>0.998489</td>\n",
              "      <td>0.246404</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.036917</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.184233</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.034990</td>\n",
              "      <td>0.989426</td>\n",
              "      <td>0.175037</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.087646</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.194083</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.008224</td>\n",
              "      <td>0.995468</td>\n",
              "      <td>0.254138</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.035983</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.203840</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.012207</td>\n",
              "      <td>0.996979</td>\n",
              "      <td>0.234758</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.036678</td>\n",
              "      <td>0.981873</td>\n",
              "      <td>0.145738</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.055166</td>\n",
              "      <td>0.980363</td>\n",
              "      <td>0.172033</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.038220</td>\n",
              "      <td>0.986405</td>\n",
              "      <td>0.189299</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.017203</td>\n",
              "      <td>0.993958</td>\n",
              "      <td>0.169443</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.020287</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.221205</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.018388</td>\n",
              "      <td>0.995468</td>\n",
              "      <td>0.278945</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.053793</td>\n",
              "      <td>0.978852</td>\n",
              "      <td>0.159293</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.080980</td>\n",
              "      <td>0.977341</td>\n",
              "      <td>0.200884</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.025836</td>\n",
              "      <td>0.990937</td>\n",
              "      <td>0.258280</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.106919</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.206196</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.039815</td>\n",
              "      <td>0.989426</td>\n",
              "      <td>0.167536</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.007107</td>\n",
              "      <td>0.996979</td>\n",
              "      <td>0.266969</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.029287</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.206646</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.020559</td>\n",
              "      <td>0.996979</td>\n",
              "      <td>0.296503</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.024403</td>\n",
              "      <td>0.990937</td>\n",
              "      <td>0.193965</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.328145</td>\n",
              "      <td>0.907855</td>\n",
              "      <td>0.182070</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.023193</td>\n",
              "      <td>0.995468</td>\n",
              "      <td>0.296193</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.023356</td>\n",
              "      <td>0.993958</td>\n",
              "      <td>0.251703</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.034606</td>\n",
              "      <td>0.990937</td>\n",
              "      <td>0.258239</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.027984</td>\n",
              "      <td>0.993958</td>\n",
              "      <td>0.220170</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.128486</td>\n",
              "      <td>0.956193</td>\n",
              "      <td>0.215512</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.078068</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.317547</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.080776</td>\n",
              "      <td>0.978852</td>\n",
              "      <td>0.232648</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.071147</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.204627</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.059893</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.247594</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.145379</td>\n",
              "      <td>0.951662</td>\n",
              "      <td>0.234050</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.171666</td>\n",
              "      <td>0.959215</td>\n",
              "      <td>0.230689</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.046927</td>\n",
              "      <td>0.980363</td>\n",
              "      <td>0.218742</td>\n",
              "      <td>0.938462</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.070379</td>\n",
              "      <td>0.984894</td>\n",
              "      <td>0.372404</td>\n",
              "      <td>0.934615</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.056602</td>\n",
              "      <td>0.986405</td>\n",
              "      <td>0.403830</td>\n",
              "      <td>0.930769</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.135743</td>\n",
              "      <td>0.951662</td>\n",
              "      <td>0.436899</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.151487</td>\n",
              "      <td>0.714502</td>\n",
              "      <td>0.246014</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.258043</td>\n",
              "      <td>0.918429</td>\n",
              "      <td>0.283871</td>\n",
              "      <td>0.911538</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.102783</td>\n",
              "      <td>0.971299</td>\n",
              "      <td>0.632065</td>\n",
              "      <td>0.903846</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy  epoch\n",
              "28  0.036508  0.986405  0.189898      0.976923     28\n",
              "49  0.012204  0.995468  0.241711      0.973077     49\n",
              "33  0.031564  0.984894  0.182563      0.973077     33\n",
              "31  0.041111  0.986405  0.218613      0.973077     31\n",
              "27  0.033119  0.984894  0.168054      0.973077     27\n",
              "23  0.020238  0.990937  0.148840      0.973077     23\n",
              "20  0.042236  0.987915  0.155499      0.973077     20\n",
              "17  0.036891  0.987915  0.141145      0.973077     17\n",
              "42  0.027452  0.990937  0.249323      0.973077     42\n",
              "47  0.002768  0.998489  0.246404      0.973077     47\n",
              "34  0.036917  0.987915  0.184233      0.969231     34\n",
              "11  0.034990  0.989426  0.175037      0.969231     11\n",
              "12  0.087646  0.974320  0.194083      0.969231     12\n",
              "43  0.008224  0.995468  0.254138      0.969231     43\n",
              "30  0.035983  0.987915  0.203840      0.969231     30\n",
              "45  0.012207  0.996979  0.234758      0.969231     45\n",
              "18  0.036678  0.981873  0.145738      0.969231     18\n",
              "26  0.055166  0.980363  0.172033      0.969231     26\n",
              "24  0.038220  0.986405  0.189299      0.969231     24\n",
              "22  0.017203  0.993958  0.169443      0.965385     22\n",
              "29  0.020287  0.987915  0.221205      0.965385     29\n",
              "39  0.018388  0.995468  0.278945      0.965385     39\n",
              "9   0.053793  0.978852  0.159293      0.965385      9\n",
              "6   0.080980  0.977341  0.200884      0.965385      6\n",
              "40  0.025836  0.990937  0.258280      0.965385     40\n",
              "7   0.106919  0.974320  0.206196      0.965385      7\n",
              "21  0.039815  0.989426  0.167536      0.965385     21\n",
              "46  0.007107  0.996979  0.266969      0.961538     46\n",
              "14  0.029287  0.987915  0.206646      0.961538     14\n",
              "44  0.020559  0.996979  0.296503      0.957692     44\n",
              "15  0.024403  0.990937  0.193965      0.957692     15\n",
              "2   0.328145  0.907855  0.182070      0.957692      2\n",
              "48  0.023193  0.995468  0.296193      0.953846     48\n",
              "25  0.023356  0.993958  0.251703      0.953846     25\n",
              "32  0.034606  0.990937  0.258239      0.953846     32\n",
              "16  0.027984  0.993958  0.220170      0.953846     16\n",
              "5   0.128486  0.956193  0.215512      0.953846      5\n",
              "38  0.078068  0.974320  0.317547      0.950000     38\n",
              "19  0.080776  0.978852  0.232648      0.950000     19\n",
              "8   0.071147  0.974320  0.204627      0.950000      8\n",
              "13  0.059893  0.974320  0.247594      0.942308     13\n",
              "4   0.145379  0.951662  0.234050      0.942308      4\n",
              "3   0.171666  0.959215  0.230689      0.942308      3\n",
              "10  0.046927  0.980363  0.218742      0.938462     10\n",
              "35  0.070379  0.984894  0.372404      0.934615     35\n",
              "41  0.056602  0.986405  0.403830      0.930769     41\n",
              "36  0.135743  0.951662  0.436899      0.923077     36\n",
              "0   1.151487  0.714502  0.246014      0.923077      0\n",
              "1   0.258043  0.918429  0.283871      0.911538      1\n",
              "37  0.102783  0.971299  0.632065      0.903846     37"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHzrFCooJTEw"
      },
      "source": [
        "**Kita ingin mencari loss yang terendah, loss ini terhadap val_lossnya**\n",
        "\n",
        "Nilai val_accuracy tertinggi pada model berada pada epoch 28 yaitu sebesar 0.976923 akan tetapi kita harus tinjau juga berdasarkan val_lossnya. Berdasarkan grafik epoch terhadap loss pada arsitektur CNN dengan vgg16 dan image augmentation, terlihat bahwa garis loss dan val_loss nya cenderung stabil dengan epoch 50 namun terjadi peningkatan pada epoch 34 hingga mulai turun kembali pada epoch 36. Terlihat adanya perbedaan jarak antara loss dan val_lossnya dengan 50 epoch yang tidak begitu besar yang berarti model yang kita buat ini cukup bagus. Nilai val_loss terendah diperoleh saat epochnya sekitar 17, dimana diperoleh val_loss: 0.141145 dan val_accuracy: 0.973077, sedikit lebih kecil dibanding val_accuracy tertingginya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tueZY9DsFJGJ"
      },
      "source": [
        "## **Santa Dataset with VGG19 Using RMSProp Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZQwKGNgA3c0"
      },
      "source": [
        "from tensorflow.keras.applications import vgg16, vgg19\n",
        "from tensorflow.keras.layers import Dropout"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2M0dF5CA9fW",
        "outputId": "437444bd-3904-4689-e50e-76ec28831fda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "vgg_conv = vgg19.VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in vgg_conv.layers[:]:\n",
        "  layer.trainable = False\n",
        "\n",
        "fine_tuned_model = Sequential()\n",
        "\n",
        "fine_tuned_model.add(vgg_conv)\n",
        "\n",
        "fine_tuned_model.add(Flatten())\n",
        "fine_tuned_model.add(Dense(4096, activation='relu'))\n",
        "fine_tuned_model.add(Dropout(0.5))\n",
        "fine_tuned_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "fine_tuned_model.summary()\n",
        "\n",
        "opt = RMSprop(learning_rate=0.0001, momentum=0.9)\n",
        "\n",
        "fine_tuned_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 2s 0us/step\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Functional)           (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 4097      \n",
            "=================================================================\n",
            "Total params: 122,793,025\n",
            "Trainable params: 102,768,641\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsEgc806BCVL",
        "outputId": "ff028437-f4fa-4a47-9d63-68696bdaed33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_vgg19_model = fine_tuned_model.fit_generator(train_augmented_iteration, steps_per_epoch=len(train_augmented_iteration), validation_data=test_augmented_iteration, validation_steps=len(test_augmented_iteration), epochs=50)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-13-2216f978a036>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/50\n",
            "6/6 [==============================] - 28s 5s/step - loss: 4.8237 - accuracy: 0.5121 - val_loss: 0.5455 - val_accuracy: 0.8308\n",
            "Epoch 2/50\n",
            "6/6 [==============================] - 24s 4s/step - loss: 1.1412 - accuracy: 0.8051 - val_loss: 1.3638 - val_accuracy: 0.8269\n",
            "Epoch 3/50\n",
            "6/6 [==============================] - 26s 4s/step - loss: 0.7242 - accuracy: 0.8882 - val_loss: 0.4438 - val_accuracy: 0.9192\n",
            "Epoch 4/50\n",
            "6/6 [==============================] - 23s 4s/step - loss: 0.6753 - accuracy: 0.8973 - val_loss: 0.3593 - val_accuracy: 0.9346\n",
            "Epoch 5/50\n",
            "6/6 [==============================] - 27s 5s/step - loss: 0.5546 - accuracy: 0.9079 - val_loss: 0.6570 - val_accuracy: 0.9077\n",
            "Epoch 6/50\n",
            "6/6 [==============================] - 23s 4s/step - loss: 0.4149 - accuracy: 0.9215 - val_loss: 0.4343 - val_accuracy: 0.9154\n",
            "Epoch 7/50\n",
            "6/6 [==============================] - 23s 4s/step - loss: 0.3658 - accuracy: 0.9260 - val_loss: 0.2886 - val_accuracy: 0.9538\n",
            "Epoch 8/50\n",
            "6/6 [==============================] - 24s 4s/step - loss: 0.2085 - accuracy: 0.9456 - val_loss: 0.4774 - val_accuracy: 0.9231\n",
            "Epoch 9/50\n",
            "6/6 [==============================] - 24s 4s/step - loss: 0.2237 - accuracy: 0.9305 - val_loss: 0.2733 - val_accuracy: 0.9577\n",
            "Epoch 10/50\n",
            "6/6 [==============================] - 23s 4s/step - loss: 0.1612 - accuracy: 0.9607 - val_loss: 0.2979 - val_accuracy: 0.9462\n",
            "Epoch 11/50\n",
            "6/6 [==============================] - 24s 4s/step - loss: 0.1440 - accuracy: 0.9683 - val_loss: 0.6123 - val_accuracy: 0.9115\n",
            "Epoch 12/50\n",
            "6/6 [==============================] - 24s 4s/step - loss: 0.1702 - accuracy: 0.9562 - val_loss: 0.3561 - val_accuracy: 0.9538\n",
            "Epoch 13/50\n",
            "6/6 [==============================] - 23s 4s/step - loss: 0.0759 - accuracy: 0.9743 - val_loss: 0.3730 - val_accuracy: 0.9269\n",
            "Epoch 14/50\n",
            "6/6 [==============================] - 23s 4s/step - loss: 0.1150 - accuracy: 0.9668 - val_loss: 0.2303 - val_accuracy: 0.9500\n",
            "Epoch 15/50\n",
            "6/6 [==============================] - 27s 4s/step - loss: 0.1138 - accuracy: 0.9637 - val_loss: 0.2399 - val_accuracy: 0.9500\n",
            "Epoch 16/50\n",
            "6/6 [==============================] - 23s 4s/step - loss: 0.0435 - accuracy: 0.9834 - val_loss: 0.2308 - val_accuracy: 0.9500\n",
            "Epoch 17/50\n",
            "6/6 [==============================] - 24s 4s/step - loss: 0.0588 - accuracy: 0.9758 - val_loss: 0.2235 - val_accuracy: 0.9577\n",
            "Epoch 18/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.0596 - accuracy: 0.9758 - val_loss: 0.2147 - val_accuracy: 0.9577\n",
            "Epoch 19/50\n",
            "6/6 [==============================] - 24s 4s/step - loss: 0.0527 - accuracy: 0.9864 - val_loss: 0.2095 - val_accuracy: 0.9577\n",
            "Epoch 20/50\n",
            "6/6 [==============================] - 24s 4s/step - loss: 0.0754 - accuracy: 0.9743 - val_loss: 0.2122 - val_accuracy: 0.9538\n",
            "Epoch 21/50\n",
            "6/6 [==============================] - 27s 4s/step - loss: 0.0910 - accuracy: 0.9713 - val_loss: 0.2833 - val_accuracy: 0.9538\n",
            "Epoch 22/50\n",
            "6/6 [==============================] - 23s 4s/step - loss: 0.1452 - accuracy: 0.9653 - val_loss: 0.5560 - val_accuracy: 0.8962\n",
            "Epoch 23/50\n",
            "6/6 [==============================] - 26s 4s/step - loss: 0.1858 - accuracy: 0.9532 - val_loss: 0.2275 - val_accuracy: 0.9577\n",
            "Epoch 24/50\n",
            "6/6 [==============================] - 23s 4s/step - loss: 0.0795 - accuracy: 0.9773 - val_loss: 0.2533 - val_accuracy: 0.9423\n",
            "Epoch 25/50\n",
            "6/6 [==============================] - 24s 4s/step - loss: 0.0956 - accuracy: 0.9728 - val_loss: 0.4971 - val_accuracy: 0.9192\n",
            "Epoch 26/50\n",
            "6/6 [==============================] - 26s 4s/step - loss: 0.0806 - accuracy: 0.9728 - val_loss: 0.2208 - val_accuracy: 0.9615\n",
            "Epoch 27/50\n",
            "6/6 [==============================] - 23s 4s/step - loss: 0.0328 - accuracy: 0.9894 - val_loss: 0.2239 - val_accuracy: 0.9654\n",
            "Epoch 28/50\n",
            "6/6 [==============================] - 24s 4s/step - loss: 0.1022 - accuracy: 0.9698 - val_loss: 0.2894 - val_accuracy: 0.9615\n",
            "Epoch 29/50\n",
            "6/6 [==============================] - 24s 4s/step - loss: 0.0613 - accuracy: 0.9789 - val_loss: 0.2961 - val_accuracy: 0.9423\n",
            "Epoch 30/50\n",
            "6/6 [==============================] - 27s 4s/step - loss: 0.0740 - accuracy: 0.9773 - val_loss: 0.2453 - val_accuracy: 0.9654\n",
            "Epoch 31/50\n",
            "6/6 [==============================] - 24s 4s/step - loss: 0.0465 - accuracy: 0.9819 - val_loss: 0.3367 - val_accuracy: 0.9423\n",
            "Epoch 32/50\n",
            "6/6 [==============================] - 24s 4s/step - loss: 0.0888 - accuracy: 0.9728 - val_loss: 0.2499 - val_accuracy: 0.9577\n",
            "Epoch 33/50\n",
            "6/6 [==============================] - 27s 5s/step - loss: 0.0922 - accuracy: 0.9728 - val_loss: 0.3512 - val_accuracy: 0.9231\n",
            "Epoch 34/50\n",
            "6/6 [==============================] - 23s 4s/step - loss: 0.0658 - accuracy: 0.9743 - val_loss: 0.2987 - val_accuracy: 0.9346\n",
            "Epoch 35/50\n",
            "6/6 [==============================] - 24s 4s/step - loss: 0.0589 - accuracy: 0.9849 - val_loss: 0.1964 - val_accuracy: 0.9577\n",
            "Epoch 36/50\n",
            "6/6 [==============================] - 23s 4s/step - loss: 0.0242 - accuracy: 0.9894 - val_loss: 0.2331 - val_accuracy: 0.9500\n",
            "Epoch 37/50\n",
            "6/6 [==============================] - 23s 4s/step - loss: 0.0447 - accuracy: 0.9804 - val_loss: 0.3553 - val_accuracy: 0.9308\n",
            "Epoch 38/50\n",
            "6/6 [==============================] - 23s 4s/step - loss: 0.0604 - accuracy: 0.9804 - val_loss: 0.3224 - val_accuracy: 0.9500\n",
            "Epoch 39/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.0266 - accuracy: 0.9940 - val_loss: 0.2240 - val_accuracy: 0.9615\n",
            "Epoch 40/50\n",
            "6/6 [==============================] - 27s 5s/step - loss: 0.0564 - accuracy: 0.9789 - val_loss: 0.1948 - val_accuracy: 0.9654\n",
            "Epoch 41/50\n",
            "6/6 [==============================] - 24s 4s/step - loss: 0.0261 - accuracy: 0.9864 - val_loss: 0.1894 - val_accuracy: 0.9654\n",
            "Epoch 42/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.0314 - accuracy: 0.9924 - val_loss: 0.1821 - val_accuracy: 0.9615\n",
            "Epoch 43/50\n",
            "6/6 [==============================] - 27s 5s/step - loss: 0.0550 - accuracy: 0.9849 - val_loss: 0.2404 - val_accuracy: 0.9615\n",
            "Epoch 44/50\n",
            "6/6 [==============================] - 27s 5s/step - loss: 0.0329 - accuracy: 0.9849 - val_loss: 0.1940 - val_accuracy: 0.9692\n",
            "Epoch 45/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.0218 - accuracy: 0.9894 - val_loss: 0.1979 - val_accuracy: 0.9577\n",
            "Epoch 46/50\n",
            "6/6 [==============================] - 23s 4s/step - loss: 0.0173 - accuracy: 0.9924 - val_loss: 0.2321 - val_accuracy: 0.9615\n",
            "Epoch 47/50\n",
            "6/6 [==============================] - 23s 4s/step - loss: 0.0302 - accuracy: 0.9924 - val_loss: 0.2503 - val_accuracy: 0.9577\n",
            "Epoch 48/50\n",
            "6/6 [==============================] - 23s 4s/step - loss: 0.0473 - accuracy: 0.9849 - val_loss: 0.2068 - val_accuracy: 0.9538\n",
            "Epoch 49/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.0477 - accuracy: 0.9834 - val_loss: 0.2260 - val_accuracy: 0.9615\n",
            "Epoch 50/50\n",
            "6/6 [==============================] - 24s 4s/step - loss: 0.0330 - accuracy: 0.9924 - val_loss: 0.2051 - val_accuracy: 0.9577\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB5n3JLFBx5d",
        "outputId": "53f5060d-8f5e-4107-adbd-c68472573c46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "plot_loss(history_vgg19_model)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB1U7OjZHMqB"
      },
      "source": [
        "history_dataframe = pd.DataFrame(history_vgg19_model.history)\n",
        "history_dataframe['epoch'] = history_vgg19_model.epoch"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk36O2t9HST-",
        "outputId": "51e33c12-11b9-4944-b9ee-2b3825c30262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.031350</td>\n",
              "      <td>0.992447</td>\n",
              "      <td>0.182093</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.026082</td>\n",
              "      <td>0.986405</td>\n",
              "      <td>0.189445</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.032924</td>\n",
              "      <td>0.984894</td>\n",
              "      <td>0.194026</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.056392</td>\n",
              "      <td>0.978852</td>\n",
              "      <td>0.194843</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.058871</td>\n",
              "      <td>0.984894</td>\n",
              "      <td>0.196375</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.021797</td>\n",
              "      <td>0.989426</td>\n",
              "      <td>0.197914</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.033016</td>\n",
              "      <td>0.992447</td>\n",
              "      <td>0.205108</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.047311</td>\n",
              "      <td>0.984894</td>\n",
              "      <td>0.206819</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.052740</td>\n",
              "      <td>0.986405</td>\n",
              "      <td>0.209485</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.075357</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.212189</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.059586</td>\n",
              "      <td>0.975831</td>\n",
              "      <td>0.214666</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.080565</td>\n",
              "      <td>0.972810</td>\n",
              "      <td>0.220768</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.058761</td>\n",
              "      <td>0.975831</td>\n",
              "      <td>0.223541</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.032761</td>\n",
              "      <td>0.989426</td>\n",
              "      <td>0.223894</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.026559</td>\n",
              "      <td>0.993958</td>\n",
              "      <td>0.223965</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.047723</td>\n",
              "      <td>0.983384</td>\n",
              "      <td>0.225987</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.185825</td>\n",
              "      <td>0.953172</td>\n",
              "      <td>0.227504</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.114988</td>\n",
              "      <td>0.966767</td>\n",
              "      <td>0.230254</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.043524</td>\n",
              "      <td>0.983384</td>\n",
              "      <td>0.230779</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.017254</td>\n",
              "      <td>0.992447</td>\n",
              "      <td>0.232073</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.024169</td>\n",
              "      <td>0.989426</td>\n",
              "      <td>0.233132</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.113783</td>\n",
              "      <td>0.963746</td>\n",
              "      <td>0.239930</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.054952</td>\n",
              "      <td>0.984894</td>\n",
              "      <td>0.240449</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.074030</td>\n",
              "      <td>0.977341</td>\n",
              "      <td>0.245334</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.088797</td>\n",
              "      <td>0.972810</td>\n",
              "      <td>0.249901</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.030177</td>\n",
              "      <td>0.992447</td>\n",
              "      <td>0.250291</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.079525</td>\n",
              "      <td>0.977341</td>\n",
              "      <td>0.253320</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.223734</td>\n",
              "      <td>0.930514</td>\n",
              "      <td>0.273262</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.090975</td>\n",
              "      <td>0.971299</td>\n",
              "      <td>0.283292</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.365798</td>\n",
              "      <td>0.925982</td>\n",
              "      <td>0.288595</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.102205</td>\n",
              "      <td>0.969788</td>\n",
              "      <td>0.289355</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.061308</td>\n",
              "      <td>0.978852</td>\n",
              "      <td>0.296149</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.161236</td>\n",
              "      <td>0.960725</td>\n",
              "      <td>0.297949</td>\n",
              "      <td>0.946154</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.065810</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.298689</td>\n",
              "      <td>0.934615</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.060366</td>\n",
              "      <td>0.980363</td>\n",
              "      <td>0.322351</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.046505</td>\n",
              "      <td>0.981873</td>\n",
              "      <td>0.336731</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.092157</td>\n",
              "      <td>0.972810</td>\n",
              "      <td>0.351210</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.044743</td>\n",
              "      <td>0.980363</td>\n",
              "      <td>0.355267</td>\n",
              "      <td>0.930769</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.170186</td>\n",
              "      <td>0.956193</td>\n",
              "      <td>0.356104</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.675317</td>\n",
              "      <td>0.897281</td>\n",
              "      <td>0.359347</td>\n",
              "      <td>0.934615</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.075863</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.372953</td>\n",
              "      <td>0.926923</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.414903</td>\n",
              "      <td>0.921450</td>\n",
              "      <td>0.434332</td>\n",
              "      <td>0.915385</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.724213</td>\n",
              "      <td>0.888218</td>\n",
              "      <td>0.443783</td>\n",
              "      <td>0.919231</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.208487</td>\n",
              "      <td>0.945619</td>\n",
              "      <td>0.477387</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.095614</td>\n",
              "      <td>0.972810</td>\n",
              "      <td>0.497110</td>\n",
              "      <td>0.919231</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.823690</td>\n",
              "      <td>0.512085</td>\n",
              "      <td>0.545515</td>\n",
              "      <td>0.830769</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.145163</td>\n",
              "      <td>0.965257</td>\n",
              "      <td>0.556029</td>\n",
              "      <td>0.896154</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.143981</td>\n",
              "      <td>0.968278</td>\n",
              "      <td>0.612305</td>\n",
              "      <td>0.911538</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.554561</td>\n",
              "      <td>0.907855</td>\n",
              "      <td>0.657011</td>\n",
              "      <td>0.907692</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.141156</td>\n",
              "      <td>0.805136</td>\n",
              "      <td>1.363776</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy  epoch\n",
              "41  0.031350  0.992447  0.182093      0.961538     41\n",
              "40  0.026082  0.986405  0.189445      0.965385     40\n",
              "43  0.032924  0.984894  0.194026      0.969231     43\n",
              "39  0.056392  0.978852  0.194843      0.965385     39\n",
              "34  0.058871  0.984894  0.196375      0.957692     34\n",
              "44  0.021797  0.989426  0.197914      0.957692     44\n",
              "49  0.033016  0.992447  0.205108      0.957692     49\n",
              "47  0.047311  0.984894  0.206819      0.953846     47\n",
              "18  0.052740  0.986405  0.209485      0.957692     18\n",
              "19  0.075357  0.974320  0.212189      0.953846     19\n",
              "17  0.059586  0.975831  0.214666      0.957692     17\n",
              "25  0.080565  0.972810  0.220768      0.961538     25\n",
              "16  0.058761  0.975831  0.223541      0.957692     16\n",
              "26  0.032761  0.989426  0.223894      0.965385     26\n",
              "38  0.026559  0.993958  0.223965      0.961538     38\n",
              "48  0.047723  0.983384  0.225987      0.961538     48\n",
              "22  0.185825  0.953172  0.227504      0.957692     22\n",
              "13  0.114988  0.966767  0.230254      0.950000     13\n",
              "15  0.043524  0.983384  0.230779      0.950000     15\n",
              "45  0.017254  0.992447  0.232073      0.961538     45\n",
              "35  0.024169  0.989426  0.233132      0.950000     35\n",
              "14  0.113783  0.963746  0.239930      0.950000     14\n",
              "42  0.054952  0.984894  0.240449      0.961538     42\n",
              "29  0.074030  0.977341  0.245334      0.965385     29\n",
              "31  0.088797  0.972810  0.249901      0.957692     31\n",
              "46  0.030177  0.992447  0.250291      0.957692     46\n",
              "23  0.079525  0.977341  0.253320      0.942308     23\n",
              "8   0.223734  0.930514  0.273262      0.957692      8\n",
              "20  0.090975  0.971299  0.283292      0.953846     20\n",
              "6   0.365798  0.925982  0.288595      0.953846      6\n",
              "27  0.102205  0.969788  0.289355      0.961538     27\n",
              "28  0.061308  0.978852  0.296149      0.942308     28\n",
              "9   0.161236  0.960725  0.297949      0.946154      9\n",
              "33  0.065810  0.974320  0.298689      0.934615     33\n",
              "37  0.060366  0.980363  0.322351      0.950000     37\n",
              "30  0.046505  0.981873  0.336731      0.942308     30\n",
              "32  0.092157  0.972810  0.351210      0.923077     32\n",
              "36  0.044743  0.980363  0.355267      0.930769     36\n",
              "11  0.170186  0.956193  0.356104      0.953846     11\n",
              "3   0.675317  0.897281  0.359347      0.934615      3\n",
              "12  0.075863  0.974320  0.372953      0.926923     12\n",
              "5   0.414903  0.921450  0.434332      0.915385      5\n",
              "2   0.724213  0.888218  0.443783      0.919231      2\n",
              "7   0.208487  0.945619  0.477387      0.923077      7\n",
              "24  0.095614  0.972810  0.497110      0.919231     24\n",
              "0   4.823690  0.512085  0.545515      0.830769      0\n",
              "21  0.145163  0.965257  0.556029      0.896154     21\n",
              "10  0.143981  0.968278  0.612305      0.911538     10\n",
              "4   0.554561  0.907855  0.657011      0.907692      4\n",
              "1   1.141156  0.805136  1.363776      0.826923      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE_A7Ul6HgwC",
        "outputId": "d6f5a3e0-9789-42a4-88a3-c7e3466e9e59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_dataframe.sort_values(by='val_accuracy', ascending=False)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.032924</td>\n",
              "      <td>0.984894</td>\n",
              "      <td>0.194026</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.026082</td>\n",
              "      <td>0.986405</td>\n",
              "      <td>0.189445</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.032761</td>\n",
              "      <td>0.989426</td>\n",
              "      <td>0.223894</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.074030</td>\n",
              "      <td>0.977341</td>\n",
              "      <td>0.245334</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.056392</td>\n",
              "      <td>0.978852</td>\n",
              "      <td>0.194843</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.031350</td>\n",
              "      <td>0.992447</td>\n",
              "      <td>0.182093</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.102205</td>\n",
              "      <td>0.969788</td>\n",
              "      <td>0.289355</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.026559</td>\n",
              "      <td>0.993958</td>\n",
              "      <td>0.223965</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.080565</td>\n",
              "      <td>0.972810</td>\n",
              "      <td>0.220768</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.054952</td>\n",
              "      <td>0.984894</td>\n",
              "      <td>0.240449</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.017254</td>\n",
              "      <td>0.992447</td>\n",
              "      <td>0.232073</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.047723</td>\n",
              "      <td>0.983384</td>\n",
              "      <td>0.225987</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.052740</td>\n",
              "      <td>0.986405</td>\n",
              "      <td>0.209485</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.021797</td>\n",
              "      <td>0.989426</td>\n",
              "      <td>0.197914</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.058871</td>\n",
              "      <td>0.984894</td>\n",
              "      <td>0.196375</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.088797</td>\n",
              "      <td>0.972810</td>\n",
              "      <td>0.249901</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.030177</td>\n",
              "      <td>0.992447</td>\n",
              "      <td>0.250291</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.185825</td>\n",
              "      <td>0.953172</td>\n",
              "      <td>0.227504</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.033016</td>\n",
              "      <td>0.992447</td>\n",
              "      <td>0.205108</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.059586</td>\n",
              "      <td>0.975831</td>\n",
              "      <td>0.214666</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.223734</td>\n",
              "      <td>0.930514</td>\n",
              "      <td>0.273262</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.058761</td>\n",
              "      <td>0.975831</td>\n",
              "      <td>0.223541</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.075357</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.212189</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.365798</td>\n",
              "      <td>0.925982</td>\n",
              "      <td>0.288595</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.090975</td>\n",
              "      <td>0.971299</td>\n",
              "      <td>0.283292</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.170186</td>\n",
              "      <td>0.956193</td>\n",
              "      <td>0.356104</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.047311</td>\n",
              "      <td>0.984894</td>\n",
              "      <td>0.206819</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.043524</td>\n",
              "      <td>0.983384</td>\n",
              "      <td>0.230779</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.114988</td>\n",
              "      <td>0.966767</td>\n",
              "      <td>0.230254</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.024169</td>\n",
              "      <td>0.989426</td>\n",
              "      <td>0.233132</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.060366</td>\n",
              "      <td>0.980363</td>\n",
              "      <td>0.322351</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.113783</td>\n",
              "      <td>0.963746</td>\n",
              "      <td>0.239930</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.161236</td>\n",
              "      <td>0.960725</td>\n",
              "      <td>0.297949</td>\n",
              "      <td>0.946154</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.061308</td>\n",
              "      <td>0.978852</td>\n",
              "      <td>0.296149</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.046505</td>\n",
              "      <td>0.981873</td>\n",
              "      <td>0.336731</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.079525</td>\n",
              "      <td>0.977341</td>\n",
              "      <td>0.253320</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.675317</td>\n",
              "      <td>0.897281</td>\n",
              "      <td>0.359347</td>\n",
              "      <td>0.934615</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.065810</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.298689</td>\n",
              "      <td>0.934615</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.044743</td>\n",
              "      <td>0.980363</td>\n",
              "      <td>0.355267</td>\n",
              "      <td>0.930769</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.075863</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.372953</td>\n",
              "      <td>0.926923</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.092157</td>\n",
              "      <td>0.972810</td>\n",
              "      <td>0.351210</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.208487</td>\n",
              "      <td>0.945619</td>\n",
              "      <td>0.477387</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.095614</td>\n",
              "      <td>0.972810</td>\n",
              "      <td>0.497110</td>\n",
              "      <td>0.919231</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.724213</td>\n",
              "      <td>0.888218</td>\n",
              "      <td>0.443783</td>\n",
              "      <td>0.919231</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.414903</td>\n",
              "      <td>0.921450</td>\n",
              "      <td>0.434332</td>\n",
              "      <td>0.915385</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.143981</td>\n",
              "      <td>0.968278</td>\n",
              "      <td>0.612305</td>\n",
              "      <td>0.911538</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.554561</td>\n",
              "      <td>0.907855</td>\n",
              "      <td>0.657011</td>\n",
              "      <td>0.907692</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.145163</td>\n",
              "      <td>0.965257</td>\n",
              "      <td>0.556029</td>\n",
              "      <td>0.896154</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.823690</td>\n",
              "      <td>0.512085</td>\n",
              "      <td>0.545515</td>\n",
              "      <td>0.830769</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.141156</td>\n",
              "      <td>0.805136</td>\n",
              "      <td>1.363776</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy  epoch\n",
              "43  0.032924  0.984894  0.194026      0.969231     43\n",
              "40  0.026082  0.986405  0.189445      0.965385     40\n",
              "26  0.032761  0.989426  0.223894      0.965385     26\n",
              "29  0.074030  0.977341  0.245334      0.965385     29\n",
              "39  0.056392  0.978852  0.194843      0.965385     39\n",
              "41  0.031350  0.992447  0.182093      0.961538     41\n",
              "27  0.102205  0.969788  0.289355      0.961538     27\n",
              "38  0.026559  0.993958  0.223965      0.961538     38\n",
              "25  0.080565  0.972810  0.220768      0.961538     25\n",
              "42  0.054952  0.984894  0.240449      0.961538     42\n",
              "45  0.017254  0.992447  0.232073      0.961538     45\n",
              "48  0.047723  0.983384  0.225987      0.961538     48\n",
              "18  0.052740  0.986405  0.209485      0.957692     18\n",
              "44  0.021797  0.989426  0.197914      0.957692     44\n",
              "34  0.058871  0.984894  0.196375      0.957692     34\n",
              "31  0.088797  0.972810  0.249901      0.957692     31\n",
              "46  0.030177  0.992447  0.250291      0.957692     46\n",
              "22  0.185825  0.953172  0.227504      0.957692     22\n",
              "49  0.033016  0.992447  0.205108      0.957692     49\n",
              "17  0.059586  0.975831  0.214666      0.957692     17\n",
              "8   0.223734  0.930514  0.273262      0.957692      8\n",
              "16  0.058761  0.975831  0.223541      0.957692     16\n",
              "19  0.075357  0.974320  0.212189      0.953846     19\n",
              "6   0.365798  0.925982  0.288595      0.953846      6\n",
              "20  0.090975  0.971299  0.283292      0.953846     20\n",
              "11  0.170186  0.956193  0.356104      0.953846     11\n",
              "47  0.047311  0.984894  0.206819      0.953846     47\n",
              "15  0.043524  0.983384  0.230779      0.950000     15\n",
              "13  0.114988  0.966767  0.230254      0.950000     13\n",
              "35  0.024169  0.989426  0.233132      0.950000     35\n",
              "37  0.060366  0.980363  0.322351      0.950000     37\n",
              "14  0.113783  0.963746  0.239930      0.950000     14\n",
              "9   0.161236  0.960725  0.297949      0.946154      9\n",
              "28  0.061308  0.978852  0.296149      0.942308     28\n",
              "30  0.046505  0.981873  0.336731      0.942308     30\n",
              "23  0.079525  0.977341  0.253320      0.942308     23\n",
              "3   0.675317  0.897281  0.359347      0.934615      3\n",
              "33  0.065810  0.974320  0.298689      0.934615     33\n",
              "36  0.044743  0.980363  0.355267      0.930769     36\n",
              "12  0.075863  0.974320  0.372953      0.926923     12\n",
              "32  0.092157  0.972810  0.351210      0.923077     32\n",
              "7   0.208487  0.945619  0.477387      0.923077      7\n",
              "24  0.095614  0.972810  0.497110      0.919231     24\n",
              "2   0.724213  0.888218  0.443783      0.919231      2\n",
              "5   0.414903  0.921450  0.434332      0.915385      5\n",
              "10  0.143981  0.968278  0.612305      0.911538     10\n",
              "4   0.554561  0.907855  0.657011      0.907692      4\n",
              "21  0.145163  0.965257  0.556029      0.896154     21\n",
              "0   4.823690  0.512085  0.545515      0.830769      0\n",
              "1   1.141156  0.805136  1.363776      0.826923      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUaY7T5WHwbh"
      },
      "source": [
        "**Kita ingin mencari loss yang terendah, loss ini terhadap val_lossnya**\n",
        "\n",
        "Nilai val_accuracy tertinggi pada model berada pada epoch 43 yaitu sebesar 0.969231 akan tetapi kita harus tinjau juga berdasarkan val_lossnya. Berdasarkan grafik epoch terhadap loss pada arsitektur CNN dengan vgg19 dan image augmentation, terlihat bahwa garis loss nya menurun drastis pada epoch 3 hingga epoch 15 dan sudah stabil hingga epoch 50 dan val_loss nya juga cenderung stabil dengan epoch 50 walaupun diawal sempat terjadi peningkatan. Terlihat adanya perbedaan jarak antara loss dan val_lossnya dengan 50 epoch yang kecil yang berarti model yang kita buat ini bagus. Nilai val_loss terendah diperoleh saat epochnya sekitar 17, dimana diperoleh val_loss: 0.182093 dan val_accuracy: 0.961538, sedikit lebih kecil dibanding val_accuracy tertingginya"
      ]
    }
  ]
}