{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning MNIST.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib7nDPtIP0CX"
      },
      "source": [
        "## **MNIST Detection**\n",
        "\n",
        "**Benedictus Bayu Pramudhito**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5badx-5OMVFo"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ5nvfOAMJLF",
        "outputId": "8f78c80d-6edb-4caa-eb53-0faed450393e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(\"Train\", X_train.shape, y_train.shape)\n",
        "print(\"Test\", X_test.shape, y_test.shape)\n",
        "\n",
        "plt.imshow(X_train[50], cmap=plt.get_cmap('gray'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Train (60000, 28, 28) (60000,)\n",
            "Test (10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcaa2d9ef28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0k6T3gJZ-tC",
        "outputId": "232b42b5-a62b-464c-c5fe-a9d73dbbc851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO3QQwwXNXd3"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUglBLFINSd0"
      },
      "source": [
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDJyzaP9hE6_",
        "outputId": "2a84e428-5be5-430f-ed8e-40be1acb43bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(X_train.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO2_g0KDaDvY",
        "outputId": "d8b0a160-e141-41b9-b15a-14795cb532f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]]],\n",
              "\n",
              "\n",
              "       [[[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]]],\n",
              "\n",
              "\n",
              "       [[[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]]],\n",
              "\n",
              "\n",
              "       [[[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]]],\n",
              "\n",
              "\n",
              "       [[[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePwMvhdjPctF",
        "outputId": "ba53b7a1-16aa-48cf-dccc-04721302c741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "print(y_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyGLG2SuP5vX"
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwP6J7TpVOwX",
        "outputId": "50f7b621-4fe0-4bfd-f29f-9b2ddf052648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w2hBAChj4t7"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUNSzpZOlzr6"
      },
      "source": [
        "## Multilayer Perceptron (Neural Network)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EoE3U5ej1Nk",
        "outputId": "4608edd2-f44b-4236-8811-f22cd1d2e7e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "base_model = Sequential()\n",
        "\n",
        "base_model.add(Flatten(input_shape=(28, 28, 1)))\n",
        "base_model.add(Dense(128, activation='relu', kernel_initializer='he_uniform')) # Activation relu dipakai, ini salah satu function yang paling banyak dipakai\n",
        "base_model.add(Dense(10, activation='softmax')) # Activation softmax dipakai untuk classification, nilai 10 karena terdapat 10 class (0-9)\n",
        "\n",
        "opt = SGD(lr=0.01, momentum=0.9) # Optimizer (Stochastic Gradient Descent), untuk mencari minima dari grafik fungsi loss\n",
        "\n",
        "base_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) # Loss Function\n",
        "\n",
        "base_model.summary()\n",
        "\n",
        "history = base_model.fit(X_train, y_train, batch_size=32, validation_data=(X_test, y_test), epochs=100)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2993 - accuracy: 0.9141 - val_loss: 0.1634 - val_accuracy: 0.9547\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1423 - accuracy: 0.9585 - val_loss: 0.1184 - val_accuracy: 0.9655\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1035 - accuracy: 0.9701 - val_loss: 0.0992 - val_accuracy: 0.9716\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0813 - accuracy: 0.9757 - val_loss: 0.0893 - val_accuracy: 0.9741\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0661 - accuracy: 0.9806 - val_loss: 0.0809 - val_accuracy: 0.9749\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0565 - accuracy: 0.9834 - val_loss: 0.0784 - val_accuracy: 0.9757\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0472 - accuracy: 0.9860 - val_loss: 0.0773 - val_accuracy: 0.9767\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0412 - accuracy: 0.9883 - val_loss: 0.0753 - val_accuracy: 0.9766\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0354 - accuracy: 0.9905 - val_loss: 0.0703 - val_accuracy: 0.9788\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0311 - accuracy: 0.9914 - val_loss: 0.0719 - val_accuracy: 0.9775\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0268 - accuracy: 0.9934 - val_loss: 0.0750 - val_accuracy: 0.9778\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0234 - accuracy: 0.9943 - val_loss: 0.0741 - val_accuracy: 0.9770\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0211 - accuracy: 0.9945 - val_loss: 0.0722 - val_accuracy: 0.9786\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0178 - accuracy: 0.9963 - val_loss: 0.0713 - val_accuracy: 0.9792\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0157 - accuracy: 0.9972 - val_loss: 0.0769 - val_accuracy: 0.9773\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0137 - accuracy: 0.9976 - val_loss: 0.0724 - val_accuracy: 0.9777\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0121 - accuracy: 0.9979 - val_loss: 0.0713 - val_accuracy: 0.9792\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0107 - accuracy: 0.9983 - val_loss: 0.0726 - val_accuracy: 0.9798\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0095 - accuracy: 0.9988 - val_loss: 0.0771 - val_accuracy: 0.9786\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 0.0729 - val_accuracy: 0.9796\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0072 - accuracy: 0.9994 - val_loss: 0.0727 - val_accuracy: 0.9796\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - accuracy: 0.9995 - val_loss: 0.0737 - val_accuracy: 0.9798\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0059 - accuracy: 0.9996 - val_loss: 0.0745 - val_accuracy: 0.9790\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0053 - accuracy: 0.9997 - val_loss: 0.0748 - val_accuracy: 0.9795\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0048 - accuracy: 0.9998 - val_loss: 0.0754 - val_accuracy: 0.9795\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0045 - accuracy: 0.9998 - val_loss: 0.0752 - val_accuracy: 0.9794\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0758 - val_accuracy: 0.9793\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0038 - accuracy: 0.9999 - val_loss: 0.0784 - val_accuracy: 0.9783\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0036 - accuracy: 0.9999 - val_loss: 0.0775 - val_accuracy: 0.9797\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.0785 - val_accuracy: 0.9787\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 0.9801\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 0.9800\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9797\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0796 - val_accuracy: 0.9793\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9795\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0797 - val_accuracy: 0.9790\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9789\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 0.9801\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0805 - val_accuracy: 0.9790\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0815 - val_accuracy: 0.9795\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0811 - val_accuracy: 0.9791\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0813 - val_accuracy: 0.9794\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 0.9795\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0825 - val_accuracy: 0.9797\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9792\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 0.9798\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 0.9794\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0832 - val_accuracy: 0.9794\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9793\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0836 - val_accuracy: 0.9794\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0836 - val_accuracy: 0.9795\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 0.9793\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9792\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0847 - val_accuracy: 0.9789\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0847 - val_accuracy: 0.9793\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9788\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9792\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9787\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9794\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 0.9794\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 9.8448e-04 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9798\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 9.6327e-04 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9794\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 9.4172e-04 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 0.9794\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 9.1966e-04 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 0.9791\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 8.9637e-04 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9792\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 8.7732e-04 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9789\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 8.6397e-04 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9795\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 8.4176e-04 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9797\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 8.2430e-04 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9796\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 8.1004e-04 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9794\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 7.9284e-04 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9794\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 7.7819e-04 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9794\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 7.6086e-04 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9791\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 7.4703e-04 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9792\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 7.3319e-04 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9792\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 7.2177e-04 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9793\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 7.0849e-04 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9795\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 6.9554e-04 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9792\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 6.8133e-04 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9798\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 6.7213e-04 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9792\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 6.5881e-04 - accuracy: 1.0000 - val_loss: 0.0895 - val_accuracy: 0.9793\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 6.4806e-04 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 0.9796\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 6.3902e-04 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9792\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 6.2666e-04 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9794\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 6.1859e-04 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9798\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 6.0912e-04 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9796\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 5.9761e-04 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 0.9795\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 5.9001e-04 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9793\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 5.8144e-04 - accuracy: 1.0000 - val_loss: 0.0912 - val_accuracy: 0.9795\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 5.7050e-04 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 0.9796\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 5.6333e-04 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9794\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 5.5622e-04 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 0.9796\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 5.4706e-04 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9796\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 5.3975e-04 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9794\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 5.3162e-04 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9797\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 5.2321e-04 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9794\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 5.1656e-04 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9793\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 5.0980e-04 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9796\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 5.0289e-04 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9795\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 4.9672e-04 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGJbXzb7SjC7"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3z2b1JuTSom",
        "outputId": "64c95613-6176-48d1-ef9c-e86e1c502add",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "history_dataframe = pd.DataFrame(history.history)\n",
        "history_dataframe['epoch'] = history.epoch\n",
        "history_dataframe"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.299281</td>\n",
              "      <td>0.914133</td>\n",
              "      <td>0.163369</td>\n",
              "      <td>0.9547</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.142258</td>\n",
              "      <td>0.958517</td>\n",
              "      <td>0.118388</td>\n",
              "      <td>0.9655</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.103486</td>\n",
              "      <td>0.970083</td>\n",
              "      <td>0.099151</td>\n",
              "      <td>0.9716</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.081314</td>\n",
              "      <td>0.975650</td>\n",
              "      <td>0.089279</td>\n",
              "      <td>0.9741</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.066053</td>\n",
              "      <td>0.980567</td>\n",
              "      <td>0.080943</td>\n",
              "      <td>0.9749</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.000523</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.092029</td>\n",
              "      <td>0.9794</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.000517</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.092072</td>\n",
              "      <td>0.9793</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.000510</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.092047</td>\n",
              "      <td>0.9796</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.000503</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.092245</td>\n",
              "      <td>0.9795</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.000497</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.092695</td>\n",
              "      <td>0.9794</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy  epoch\n",
              "0   0.299281  0.914133  0.163369        0.9547      0\n",
              "1   0.142258  0.958517  0.118388        0.9655      1\n",
              "2   0.103486  0.970083  0.099151        0.9716      2\n",
              "3   0.081314  0.975650  0.089279        0.9741      3\n",
              "4   0.066053  0.980567  0.080943        0.9749      4\n",
              "..       ...       ...       ...           ...    ...\n",
              "95  0.000523  1.000000  0.092029        0.9794     95\n",
              "96  0.000517  1.000000  0.092072        0.9793     96\n",
              "97  0.000510  1.000000  0.092047        0.9796     97\n",
              "98  0.000503  1.000000  0.092245        0.9795     98\n",
              "99  0.000497  1.000000  0.092695        0.9794     99\n",
              "\n",
              "[100 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk5lH4rrSp22",
        "outputId": "d269657e-4f5d-48b3-93d7-025ab43a6298",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_loss(history) # epoch vs loss graph"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhfzqJPGUT3R"
      },
      "source": [
        "**Kita ingin mencari loss yang terendah, loss ini terhadap val_lossnya**\n",
        "\n",
        "Berdasarkan grafik epoch terhadap loss pada model multilayer perceptron, terlihat bahwa garis lossnya memang sudah mencapai titik terendahnya dengan 100 epoch, tetapi grafik val_loss nya cenderung mengalami peningkatan. Oleh karena itu, nilai val_loss terendah diperoleh saat epochnya sekitar 20-21, tepat sebelum val_loss nya mengalami peningkatan dimana saat epoch 21 diperoleh val_loss: 0.0727 dan val_accuracy: 0.9796"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFfSnLO-ka9u"
      },
      "source": [
        "#loss, accuracy = base_model.evaluate(X_test,  y_test, verbose=2)\n",
        "\n",
        "#print(\"Test accuracy:\", accuracy)\n",
        "#print(\"Test loss:\", loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D20aS2TSl1gm"
      },
      "source": [
        "## Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjwhNq6DVVz5",
        "outputId": "8cba507a-1fb1-40c4-b73a-c7f0821b7581",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Adapted from: https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1))) # Convolution, 32 filters, masing-masing dengan kernel 3x3\n",
        "\n",
        "model.add(MaxPooling2D((2, 2))) # Pooling\n",
        "\n",
        "model.add(Flatten()) # Flatten hasil output\n",
        "\n",
        "# Fully connected layer\n",
        "model.add(Dense(100, activation='relu', kernel_initializer='he_uniform')) # Activation relu dipakai, ini salah satu function yang paling banyak dipakai\n",
        "model.add(Dense(10, activation='softmax')) # Activation softmax dipakai untuk classification, nilai 10 karena terdapat 10 class (0-9)\n",
        "\n",
        "opt = SGD(lr=0.01, momentum=0.9) # Optimizer (Stochastic Gradient Descent), untuk mencari minima dari grafik fungsi loss\n",
        "\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) # Loss Function\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history_cnn = model.fit(X_train, y_train, batch_size=32, validation_data=(X_test, y_test), epochs=100)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 5408)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               540900    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 542,230\n",
            "Trainable params: 542,230\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1694 - accuracy: 0.9473 - val_loss: 0.0678 - val_accuracy: 0.9787\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0582 - accuracy: 0.9823 - val_loss: 0.0463 - val_accuracy: 0.9850\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0379 - accuracy: 0.9883 - val_loss: 0.0521 - val_accuracy: 0.9834\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0264 - accuracy: 0.9920 - val_loss: 0.0456 - val_accuracy: 0.9860\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0184 - accuracy: 0.9948 - val_loss: 0.0459 - val_accuracy: 0.9848\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 0.0390 - val_accuracy: 0.9879\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.0407 - val_accuracy: 0.9864\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.0400 - val_accuracy: 0.9885\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.0405 - val_accuracy: 0.9883\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.0424 - val_accuracy: 0.9879\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0415 - val_accuracy: 0.9885\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0421 - val_accuracy: 0.9884\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0404 - val_accuracy: 0.9890\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 8.0603e-04 - accuracy: 0.9999 - val_loss: 0.0413 - val_accuracy: 0.9888\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 6.1213e-04 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9884\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.7800e-04 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9885\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.2120e-04 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9883\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.8140e-04 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9882\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.2821e-04 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9884\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.9853e-04 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9885\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.7805e-04 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9882\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.5214e-04 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9884\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3714e-04 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9886\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2161e-04 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9887\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.0802e-04 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9884\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.9619e-04 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9885\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.8628e-04 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9886\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.7554e-04 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9883\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6742e-04 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9886\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.5858e-04 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9886\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.5096e-04 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9885\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.4368e-04 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9886\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.3787e-04 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9883\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.3260e-04 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9886\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.2774e-04 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9887\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.2273e-04 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9884\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.1768e-04 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9886\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.1377e-04 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9884\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.1033e-04 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.9885\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.0649e-04 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9885\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.0252e-04 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9885\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 9.9648e-05 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9884\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 9.6027e-05 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9885\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 9.3816e-05 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9886\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 9.0992e-05 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9885\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 8.8500e-05 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9887\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 8.6079e-05 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9884\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 8.4008e-05 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9887\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 8.1494e-05 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9883\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 7.9453e-05 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9885\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 7.7540e-05 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9886\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 7.5450e-05 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9884\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 7.3626e-05 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9884\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 7.2004e-05 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9885\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 7.0248e-05 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9886\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 6.8637e-05 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9885\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 6.6908e-05 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9885\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 6.5474e-05 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9885\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 6.4478e-05 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9886\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 6.2736e-05 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9884\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 6.1590e-05 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9885\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 6.0040e-05 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9885\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 5.9122e-05 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9886\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 5.7976e-05 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9885\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 5.6982e-05 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9885\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 5.5714e-05 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9886\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 5.4663e-05 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9884\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 5.3619e-05 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9885\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 5.2843e-05 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9884\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 5.1847e-05 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9887\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 5.0967e-05 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9884\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.9954e-05 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9886\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.9288e-05 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9885\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.8278e-05 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9885\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.7674e-05 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9886\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.6818e-05 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9887\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.6068e-05 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9884\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.5282e-05 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9886\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.4628e-05 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 0.9886\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.3980e-05 - accuracy: 1.0000 - val_loss: 0.0539 - val_accuracy: 0.9886\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.3223e-05 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 0.9884\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.2543e-05 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 0.9883\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.1929e-05 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 0.9885\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.1376e-05 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 0.9885\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.0585e-05 - accuracy: 1.0000 - val_loss: 0.0544 - val_accuracy: 0.9885\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.0166e-05 - accuracy: 1.0000 - val_loss: 0.0544 - val_accuracy: 0.9886\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.9571e-05 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 0.9885\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.9010e-05 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 0.9885\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.8494e-05 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 0.9885\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.7976e-05 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 0.9884\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.7465e-05 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 0.9884\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.7022e-05 - accuracy: 1.0000 - val_loss: 0.0549 - val_accuracy: 0.9884\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.6488e-05 - accuracy: 1.0000 - val_loss: 0.0549 - val_accuracy: 0.9884\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.6048e-05 - accuracy: 1.0000 - val_loss: 0.0550 - val_accuracy: 0.9885\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.5497e-05 - accuracy: 1.0000 - val_loss: 0.0550 - val_accuracy: 0.9884\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.5115e-05 - accuracy: 1.0000 - val_loss: 0.0550 - val_accuracy: 0.9885\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.4619e-05 - accuracy: 1.0000 - val_loss: 0.0552 - val_accuracy: 0.9884\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.4201e-05 - accuracy: 1.0000 - val_loss: 0.0552 - val_accuracy: 0.9884\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.3772e-05 - accuracy: 1.0000 - val_loss: 0.0552 - val_accuracy: 0.9884\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.3348e-05 - accuracy: 1.0000 - val_loss: 0.0553 - val_accuracy: 0.9884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDXIubauXE1V"
      },
      "source": [
        "#loss, accuracy = model.evaluate(X_test,  y_test, verbose=2)\n",
        "\n",
        "#print(\"Test accuracy:\", accuracy)\n",
        "#print(\"Test loss:\", loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSoWHoZQThaI",
        "outputId": "8840c906-d5b6-4422-973c-4c38073786da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "plot_loss(history_cnn)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxSmY3R7lT6E"
      },
      "source": [
        "**Kita ingin mencari loss yang terendah, loss ini terhadap val_lossnya**\n",
        "\n",
        "Berdasarkan grafik epoch terhadap loss pada model CNN single layer, terlihat bahwa garis lossnya memang sudah mencapai titik terendahnya dengan 100 epoch, tetapi grafik val_loss nya cenderung mengalami peningkatan setelah sekitar 15 epoch. Oleh karena itu, nilai val_loss terendah diperoleh saat epochnya sekitar 15-16, tepat sebelum val_loss nya mengalami peningkatan dimana saat epoch 15 diperoleh val_loss: 0.0414 dan val_accuracy: 0.9884"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-94dNfhKk5C-"
      },
      "source": [
        "**Deep Learning with Deeper Layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D84fYHvOk_aX"
      },
      "source": [
        "model = Sequential([Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)),\n",
        "                   MaxPooling2D((2,2)),\n",
        "                   Conv2D(64, (3,3), activation='relu', kernel_initializer='he_uniform'),\n",
        "                   MaxPooling2D((2,2)),\n",
        "                   Flatten(),\n",
        "                   Dense(100, activation='relu', kernel_initializer='he_uniform'),\n",
        "                   Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUvn5uDfk_Pu"
      },
      "source": [
        "model.compile(optimizer=SGD(lr=0.01, momentum=0.9), \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cepwlT1ZlL9V",
        "outputId": "58e75e0c-51dd-4217-cac5-3f4af4a66427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()\n",
        "\n",
        "history_cnn_1 = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=32,\n",
        "    validation_data = (X_test, y_test),\n",
        "    epochs=100\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 100)               160100    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 179,926\n",
            "Trainable params: 179,926\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1268 - accuracy: 0.9606 - val_loss: 0.0647 - val_accuracy: 0.9795\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0432 - accuracy: 0.9863 - val_loss: 0.0384 - val_accuracy: 0.9871\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0291 - accuracy: 0.9908 - val_loss: 0.0368 - val_accuracy: 0.9889\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.0293 - val_accuracy: 0.9903\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.0425 - val_accuracy: 0.9858\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.0297 - val_accuracy: 0.9912\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.0292 - val_accuracy: 0.9913\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0353 - val_accuracy: 0.9899\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0356 - val_accuracy: 0.9908\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0345 - val_accuracy: 0.9905\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0325 - val_accuracy: 0.9911\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0323 - val_accuracy: 0.9922\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 6.3189e-04 - accuracy: 0.9999 - val_loss: 0.0332 - val_accuracy: 0.9927\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 3.8087e-04 - accuracy: 1.0000 - val_loss: 0.0332 - val_accuracy: 0.9925\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.4817e-04 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 0.9925\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6580e-04 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 0.9924\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.5750e-04 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 0.9926\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.3036e-04 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 0.9923\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.0724e-04 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 0.9921\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 9.5820e-05 - accuracy: 1.0000 - val_loss: 0.0361 - val_accuracy: 0.9926\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 8.6163e-05 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9922\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 7.9659e-05 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9922\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 7.4249e-05 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9922\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 6.9219e-05 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9922\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 6.5068e-05 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9922\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 6.1500e-05 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9922\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 5.7235e-05 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9924\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 5.4489e-05 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9922\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 5.1620e-05 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9922\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.8627e-05 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9922\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.6873e-05 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9921\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.5024e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9922\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.2947e-05 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9922\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.1326e-05 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9922\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.9667e-05 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9922\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.7992e-05 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9922\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.6731e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9922\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.5403e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9923\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.4521e-05 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9922\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.2956e-05 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9922\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.1638e-05 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9922\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.1243e-05 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9922\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.0116e-05 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9922\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.9170e-05 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9921\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.8353e-05 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9923\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.7611e-05 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9921\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.6862e-05 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9921\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.6092e-05 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9923\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.5357e-05 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9922\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.4875e-05 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9922\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3994e-05 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9921\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3554e-05 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9923\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2951e-05 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9922\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2434e-05 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9923\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.1786e-05 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9923\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.1422e-05 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9922\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.0964e-05 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9922\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.0577e-05 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9921\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.0039e-05 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9921\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.9592e-05 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9922\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.9227e-05 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9921\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.8876e-05 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9922\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.8516e-05 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9921\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.8115e-05 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9921\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.7782e-05 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9921\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.7409e-05 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9922\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.7211e-05 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9921\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6805e-05 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9922\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6563e-05 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9922\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6247e-05 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9921\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.5933e-05 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9922\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.5690e-05 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9921\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.5429e-05 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9921\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5173e-05 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9921\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.4894e-05 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9922\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.4664e-05 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9921\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.4456e-05 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9921\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.4207e-05 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9921\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.3970e-05 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9922\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.3794e-05 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9921\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.3605e-05 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9922\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.3363e-05 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9921\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.3187e-05 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 0.9922\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.2989e-05 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 0.9921\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.2797e-05 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9921\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.2643e-05 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 0.9921\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.2445e-05 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9922\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.2239e-05 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9921\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.2114e-05 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9921\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.1944e-05 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9921\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.1781e-05 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9921\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.1578e-05 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9921\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.1476e-05 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9921\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.1322e-05 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9921\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.1183e-05 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9921\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.1046e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9921\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.0900e-05 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9922\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.0755e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9921\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.0628e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9922\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.0484e-05 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCR-G79olPQ8",
        "outputId": "d38af71d-8384-4575-a523-bd47bdca9d4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "history_df_cnn1 = pd.DataFrame(history_cnn_1.history)\n",
        "history_df_cnn1['epoch'] = history_cnn_1.epoch\n",
        "history_df_cnn1"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.126752</td>\n",
              "      <td>0.960600</td>\n",
              "      <td>0.064664</td>\n",
              "      <td>0.9795</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.043158</td>\n",
              "      <td>0.986283</td>\n",
              "      <td>0.038402</td>\n",
              "      <td>0.9871</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.029112</td>\n",
              "      <td>0.990850</td>\n",
              "      <td>0.036785</td>\n",
              "      <td>0.9889</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.021772</td>\n",
              "      <td>0.993167</td>\n",
              "      <td>0.029294</td>\n",
              "      <td>0.9903</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.015635</td>\n",
              "      <td>0.995167</td>\n",
              "      <td>0.042512</td>\n",
              "      <td>0.9858</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.000011</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.045767</td>\n",
              "      <td>0.9921</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.000011</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.045746</td>\n",
              "      <td>0.9922</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.000011</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.045817</td>\n",
              "      <td>0.9921</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.000011</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.045834</td>\n",
              "      <td>0.9922</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.000010</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.045984</td>\n",
              "      <td>0.9921</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy  epoch\n",
              "0   0.126752  0.960600  0.064664        0.9795      0\n",
              "1   0.043158  0.986283  0.038402        0.9871      1\n",
              "2   0.029112  0.990850  0.036785        0.9889      2\n",
              "3   0.021772  0.993167  0.029294        0.9903      3\n",
              "4   0.015635  0.995167  0.042512        0.9858      4\n",
              "..       ...       ...       ...           ...    ...\n",
              "95  0.000011  1.000000  0.045767        0.9921     95\n",
              "96  0.000011  1.000000  0.045746        0.9922     96\n",
              "97  0.000011  1.000000  0.045817        0.9921     97\n",
              "98  0.000011  1.000000  0.045834        0.9922     98\n",
              "99  0.000010  1.000000  0.045984        0.9921     99\n",
              "\n",
              "[100 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-KzDYn5lPHc",
        "outputId": "adce8a51-9cb0-49f4-bb58-5fe831dc7a92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_loss(history_cnn_1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW5HSRkqoKe3"
      },
      "source": [
        "**Kita ingin mencari loss yang terendah, loss ini terhadap val_lossnya**\n",
        "\n",
        "Berdasarkan grafik epoch terhadap loss pada model CNN dengan deeper layer, terlihat bahwa garis lossnya memang sudah mencapai titik terendahnya dengan 100 epoch, tetapi grafik val_loss nya cenderung mengalami peningkatan setelah sekitar 15 epoch. Oleh karena itu, nilai val_loss terendah diperoleh saat epochnya sekitar 15-16, tepat sebelum val_loss nya mengalami peningkatan dimana saat epoch 15 diperoleh val_loss: 0.0334 dan val_accuracy: 0.9925"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAjHe__yVO-n"
      },
      "source": [
        "Nilai akurasi pada model CNN single layer sebesar 0.9884 dan pada model CNN dengan deeper layer nilainya sedikit lebih besar yakni 0.9925. Hal ini bisa disebabkan karena layer yang digunakan lebih dalam sehingga feature yang diambil pun bisa lebih banyak. Walaupun layer yang lebih dalam belum tentu menghasilkan model yang lebih baik, akan tetapi untuk dataset MNIST ini penggunaan layer yang lebih dalam mampu meningkatkan performa dari model"
      ]
    }
  ]
}