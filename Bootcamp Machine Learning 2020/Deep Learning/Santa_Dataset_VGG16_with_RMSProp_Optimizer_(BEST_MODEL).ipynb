{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Santa Dataset VGG16 with RMSProp Optimizer (BEST MODEL).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL7Jp8TxSrqi"
      },
      "source": [
        "## **Santa Dataset VGG16 with RMSProp Optimizer**\n",
        "\n",
        "**Benedictus Bayu Pramudhito**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nne7TrwrJ020",
        "outputId": "fce0a039-6bec-4445-8c22-bd9466a2b01a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR37W7tFchKF"
      },
      "source": [
        "zip_path = '/content/drive/My\\ Drive/santa-dataset.zip'\n",
        "\n",
        "!cp {zip_path} /content/\n",
        "\n",
        "!cd /content/\n",
        "\n",
        "!unzip -q /content/santa-dataset.zip -d /content\n",
        "\n",
        "!rm /content/santa-dataset.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FwE2WEKlEKQ"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vdl88-zjxM4R"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keMDICRGrhNs"
      },
      "source": [
        "# Baseline CNN model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nov8K3vg-hie"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0O7kh6rmJj9",
        "outputId": "b8dd650b-92db-4e07-8ec8-958a228673ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "opt = SGD(lr=0.001, momentum=0.9)\n",
        "\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 200, 200, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 100, 100, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 100, 100, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 50, 50, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 25, 25, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 80000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               10240128  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 10,333,505\n",
            "Trainable params: 10,333,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeGSbxxk29SO",
        "outputId": "b37c628f-d6d1-42f0-b3ba-e842115c0543",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "dataset_dir = '/content/'\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "train_iterator = datagen.flow_from_directory(os.path.join(dataset_dir, 'train'), class_mode='binary', batch_size=128, target_size=(200, 200))\n",
        "test_iterator = datagen.flow_from_directory(os.path.join(dataset_dir, 'test'), class_mode='binary', batch_size=128, target_size=(200, 200))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 662 images belonging to 2 classes.\n",
            "Found 260 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uk8mTSp_oJe"
      },
      "source": [
        "**Training with Baseline CNN Layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znPhLUV4ma06",
        "outputId": "de760f9d-9820-4c60-82b1-155322fac022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_base_model = model.fit_generator(train_iterator, steps_per_epoch=len(train_iterator), validation_data=test_iterator, validation_steps=len(test_iterator), epochs=75)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-9-97d030b73ef6>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/75\n",
            "6/6 [==============================] - 58s 10s/step - loss: 0.7556 - accuracy: 0.5619 - val_loss: 0.9726 - val_accuracy: 0.5346\n",
            "Epoch 2/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.7086 - accuracy: 0.6360 - val_loss: 0.7464 - val_accuracy: 0.5000\n",
            "Epoch 3/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.6396 - accuracy: 0.6088 - val_loss: 0.6043 - val_accuracy: 0.6885\n",
            "Epoch 4/75\n",
            "6/6 [==============================] - 57s 9s/step - loss: 0.5360 - accuracy: 0.7085 - val_loss: 0.5039 - val_accuracy: 0.7654\n",
            "Epoch 5/75\n",
            "6/6 [==============================] - 58s 10s/step - loss: 0.4315 - accuracy: 0.8021 - val_loss: 0.5141 - val_accuracy: 0.7385\n",
            "Epoch 6/75\n",
            "6/6 [==============================] - 57s 9s/step - loss: 0.3648 - accuracy: 0.8625 - val_loss: 0.4240 - val_accuracy: 0.8308\n",
            "Epoch 7/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.3060 - accuracy: 0.9048 - val_loss: 0.3607 - val_accuracy: 0.9038\n",
            "Epoch 8/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.2653 - accuracy: 0.9290 - val_loss: 0.3559 - val_accuracy: 0.9000\n",
            "Epoch 9/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.2455 - accuracy: 0.9169 - val_loss: 0.3417 - val_accuracy: 0.9154\n",
            "Epoch 10/75\n",
            "6/6 [==============================] - 57s 10s/step - loss: 0.2288 - accuracy: 0.9245 - val_loss: 0.3195 - val_accuracy: 0.9231\n",
            "Epoch 11/75\n",
            "6/6 [==============================] - 65s 11s/step - loss: 0.2108 - accuracy: 0.9335 - val_loss: 0.3077 - val_accuracy: 0.9115\n",
            "Epoch 12/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.2061 - accuracy: 0.9305 - val_loss: 0.3326 - val_accuracy: 0.8885\n",
            "Epoch 13/75\n",
            "6/6 [==============================] - 57s 10s/step - loss: 0.2630 - accuracy: 0.8822 - val_loss: 0.3395 - val_accuracy: 0.8808\n",
            "Epoch 14/75\n",
            "6/6 [==============================] - 68s 11s/step - loss: 0.1797 - accuracy: 0.9456 - val_loss: 0.3224 - val_accuracy: 0.8885\n",
            "Epoch 15/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.1768 - accuracy: 0.9426 - val_loss: 0.2794 - val_accuracy: 0.9269\n",
            "Epoch 16/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.1663 - accuracy: 0.9396 - val_loss: 0.2893 - val_accuracy: 0.9231\n",
            "Epoch 17/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.1367 - accuracy: 0.9592 - val_loss: 0.2803 - val_accuracy: 0.9231\n",
            "Epoch 18/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.1249 - accuracy: 0.9653 - val_loss: 0.2786 - val_accuracy: 0.9231\n",
            "Epoch 19/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.1348 - accuracy: 0.9562 - val_loss: 0.2915 - val_accuracy: 0.9077\n",
            "Epoch 20/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.1442 - accuracy: 0.9502 - val_loss: 0.2957 - val_accuracy: 0.9077\n",
            "Epoch 21/75\n",
            "6/6 [==============================] - 54s 9s/step - loss: 0.1313 - accuracy: 0.9547 - val_loss: 0.2666 - val_accuracy: 0.9231\n",
            "Epoch 22/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.1196 - accuracy: 0.9562 - val_loss: 0.2599 - val_accuracy: 0.9192\n",
            "Epoch 23/75\n",
            "6/6 [==============================] - 58s 10s/step - loss: 0.1105 - accuracy: 0.9622 - val_loss: 0.2654 - val_accuracy: 0.9192\n",
            "Epoch 24/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0974 - accuracy: 0.9698 - val_loss: 0.2720 - val_accuracy: 0.9231\n",
            "Epoch 25/75\n",
            "6/6 [==============================] - 57s 10s/step - loss: 0.0977 - accuracy: 0.9713 - val_loss: 0.2679 - val_accuracy: 0.9192\n",
            "Epoch 26/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0953 - accuracy: 0.9698 - val_loss: 0.2604 - val_accuracy: 0.9231\n",
            "Epoch 27/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0837 - accuracy: 0.9804 - val_loss: 0.2605 - val_accuracy: 0.9231\n",
            "Epoch 28/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0945 - accuracy: 0.9713 - val_loss: 0.2642 - val_accuracy: 0.9115\n",
            "Epoch 29/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0934 - accuracy: 0.9683 - val_loss: 0.2670 - val_accuracy: 0.9231\n",
            "Epoch 30/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0806 - accuracy: 0.9773 - val_loss: 0.3241 - val_accuracy: 0.9038\n",
            "Epoch 31/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0786 - accuracy: 0.9713 - val_loss: 0.3125 - val_accuracy: 0.9115\n",
            "Epoch 32/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0707 - accuracy: 0.9743 - val_loss: 0.3083 - val_accuracy: 0.9115\n",
            "Epoch 33/75\n",
            "6/6 [==============================] - 54s 9s/step - loss: 0.0612 - accuracy: 0.9879 - val_loss: 0.2864 - val_accuracy: 0.9115\n",
            "Epoch 34/75\n",
            "6/6 [==============================] - 65s 11s/step - loss: 0.0549 - accuracy: 0.9894 - val_loss: 0.2653 - val_accuracy: 0.9231\n",
            "Epoch 35/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0511 - accuracy: 0.9924 - val_loss: 0.2680 - val_accuracy: 0.9231\n",
            "Epoch 36/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0454 - accuracy: 0.9909 - val_loss: 0.2662 - val_accuracy: 0.9269\n",
            "Epoch 37/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0457 - accuracy: 0.9909 - val_loss: 0.2670 - val_accuracy: 0.9154\n",
            "Epoch 38/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0421 - accuracy: 0.9940 - val_loss: 0.2684 - val_accuracy: 0.9231\n",
            "Epoch 39/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0407 - accuracy: 0.9940 - val_loss: 0.2748 - val_accuracy: 0.9192\n",
            "Epoch 40/75\n",
            "6/6 [==============================] - 67s 11s/step - loss: 0.0407 - accuracy: 0.9955 - val_loss: 0.2793 - val_accuracy: 0.9192\n",
            "Epoch 41/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0345 - accuracy: 0.9985 - val_loss: 0.2709 - val_accuracy: 0.9308\n",
            "Epoch 42/75\n",
            "6/6 [==============================] - 66s 11s/step - loss: 0.0341 - accuracy: 0.9970 - val_loss: 0.2729 - val_accuracy: 0.9192\n",
            "Epoch 43/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.2874 - val_accuracy: 0.9077\n",
            "Epoch 44/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0305 - accuracy: 0.9985 - val_loss: 0.3162 - val_accuracy: 0.9077\n",
            "Epoch 45/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0328 - accuracy: 0.9970 - val_loss: 0.2861 - val_accuracy: 0.9077\n",
            "Epoch 46/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0285 - accuracy: 0.9970 - val_loss: 0.2759 - val_accuracy: 0.9231\n",
            "Epoch 47/75\n",
            "6/6 [==============================] - 66s 11s/step - loss: 0.0266 - accuracy: 0.9985 - val_loss: 0.2832 - val_accuracy: 0.9154\n",
            "Epoch 48/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.2962 - val_accuracy: 0.9077\n",
            "Epoch 49/75\n",
            "6/6 [==============================] - 57s 9s/step - loss: 0.0241 - accuracy: 0.9985 - val_loss: 0.2958 - val_accuracy: 0.9077\n",
            "Epoch 50/75\n",
            "6/6 [==============================] - 66s 11s/step - loss: 0.0263 - accuracy: 0.9985 - val_loss: 0.3092 - val_accuracy: 0.9077\n",
            "Epoch 51/75\n",
            "6/6 [==============================] - 57s 10s/step - loss: 0.0322 - accuracy: 0.9985 - val_loss: 0.3360 - val_accuracy: 0.9077\n",
            "Epoch 52/75\n",
            "6/6 [==============================] - 57s 9s/step - loss: 0.0338 - accuracy: 0.9955 - val_loss: 0.3785 - val_accuracy: 0.9000\n",
            "Epoch 53/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0314 - accuracy: 0.9955 - val_loss: 0.3889 - val_accuracy: 0.8962\n",
            "Epoch 54/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0332 - accuracy: 0.9924 - val_loss: 0.3116 - val_accuracy: 0.9115\n",
            "Epoch 55/75\n",
            "6/6 [==============================] - 65s 11s/step - loss: 0.0294 - accuracy: 0.9985 - val_loss: 0.2834 - val_accuracy: 0.9269\n",
            "Epoch 56/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 0.9308\n",
            "Epoch 57/75\n",
            "6/6 [==============================] - 66s 11s/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9308\n",
            "Epoch 58/75\n",
            "6/6 [==============================] - 67s 11s/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.3161 - val_accuracy: 0.9115\n",
            "Epoch 59/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.3128 - val_accuracy: 0.9077\n",
            "Epoch 60/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.3032 - val_accuracy: 0.9192\n",
            "Epoch 61/75\n",
            "6/6 [==============================] - 54s 9s/step - loss: 0.0224 - accuracy: 0.9985 - val_loss: 0.3008 - val_accuracy: 0.9346\n",
            "Epoch 62/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.9192\n",
            "Epoch 63/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 0.9231\n",
            "Epoch 64/75\n",
            "6/6 [==============================] - 54s 9s/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.9192\n",
            "Epoch 65/75\n",
            "6/6 [==============================] - 56s 9s/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.3043 - val_accuracy: 0.9231\n",
            "Epoch 66/75\n",
            "6/6 [==============================] - 65s 11s/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.3104 - val_accuracy: 0.9192\n",
            "Epoch 67/75\n",
            "6/6 [==============================] - 57s 10s/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.3118 - val_accuracy: 0.9192\n",
            "Epoch 68/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.9192\n",
            "Epoch 69/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9077\n",
            "Epoch 70/75\n",
            "6/6 [==============================] - 65s 11s/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.3087 - val_accuracy: 0.9308\n",
            "Epoch 71/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.3124 - val_accuracy: 0.9231\n",
            "Epoch 72/75\n",
            "6/6 [==============================] - 65s 11s/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.3453 - val_accuracy: 0.9038\n",
            "Epoch 73/75\n",
            "6/6 [==============================] - 55s 9s/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.3109 - val_accuracy: 0.9231\n",
            "Epoch 74/75\n",
            "6/6 [==============================] - 54s 9s/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.3206 - val_accuracy: 0.9192\n",
            "Epoch 75/75\n",
            "6/6 [==============================] - 54s 9s/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.3228 - val_accuracy: 0.9192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaPbEQ2RxSDa",
        "outputId": "bf717f0e-dd35-4dfb-c8a0-db1f6a71f048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_loss(history_base_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDiFRYEgB01W"
      },
      "source": [
        "### **Fine Tuning Method**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD1dQz6WnmIz"
      },
      "source": [
        "**Image Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EApcJT87lUQq",
        "outputId": "8058c12e-8bf6-4186-e8d1-a4dceede6b1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "dataset_dir = '/content/'\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "\n",
        "train_augmented_iteration = train_datagen.flow_from_directory(os.path.join(dataset_dir, 'train'), class_mode='binary', batch_size=128, target_size=(224, 224))\n",
        "test_augmented_iteration = test_datagen.flow_from_directory(os.path.join(dataset_dir, 'test'), class_mode='binary', batch_size=128, target_size=(224, 224))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 662 images belonging to 2 classes.\n",
            "Found 260 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxRasE8c_ldC"
      },
      "source": [
        "**Fine Tuning with RMSProp Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YfzbpROnaOx"
      },
      "source": [
        "from tensorflow.keras.applications import vgg16\n",
        "from tensorflow.keras.layers import Dropout"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fue5L5AT_z5-",
        "outputId": "505ad911-45bb-4d42-9fd5-7620251eb3f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "vgg_conv = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in vgg_conv.layers[:]:\n",
        "  layer.trainable = False\n",
        "\n",
        "fine_tuned_model = Sequential()\n",
        "\n",
        "fine_tuned_model.add(vgg_conv)\n",
        "\n",
        "fine_tuned_model.add(Flatten())\n",
        "fine_tuned_model.add(Dense(1024, activation='relu'))\n",
        "fine_tuned_model.add(Dropout(0.5))\n",
        "fine_tuned_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "fine_tuned_model.summary()\n",
        "\n",
        "opt = RMSprop(learning_rate=0.0001, momentum=0.9)\n",
        "\n",
        "fine_tuned_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 1025      \n",
            "=================================================================\n",
            "Total params: 40,406,849\n",
            "Trainable params: 25,692,161\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKYLHYsTA33h",
        "outputId": "9e046d84-1eec-439d-dd8f-a68517c477dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_model = fine_tuned_model.fit_generator(train_augmented_iteration, steps_per_epoch=len(train_augmented_iteration), validation_data=test_augmented_iteration, validation_steps=len(test_augmented_iteration), epochs=50)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "6/6 [==============================] - 24s 4s/step - loss: 1.1515 - accuracy: 0.7145 - val_loss: 0.2460 - val_accuracy: 0.9231\n",
            "Epoch 2/50\n",
            "6/6 [==============================] - 20s 3s/step - loss: 0.2580 - accuracy: 0.9184 - val_loss: 0.2839 - val_accuracy: 0.9115\n",
            "Epoch 3/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.3281 - accuracy: 0.9079 - val_loss: 0.1821 - val_accuracy: 0.9577\n",
            "Epoch 4/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.1717 - accuracy: 0.9592 - val_loss: 0.2307 - val_accuracy: 0.9423\n",
            "Epoch 5/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.1454 - accuracy: 0.9517 - val_loss: 0.2341 - val_accuracy: 0.9423\n",
            "Epoch 6/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.1285 - accuracy: 0.9562 - val_loss: 0.2155 - val_accuracy: 0.9538\n",
            "Epoch 7/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0810 - accuracy: 0.9773 - val_loss: 0.2009 - val_accuracy: 0.9654\n",
            "Epoch 8/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.1069 - accuracy: 0.9743 - val_loss: 0.2062 - val_accuracy: 0.9654\n",
            "Epoch 9/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0711 - accuracy: 0.9743 - val_loss: 0.2046 - val_accuracy: 0.9500\n",
            "Epoch 10/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0538 - accuracy: 0.9789 - val_loss: 0.1593 - val_accuracy: 0.9654\n",
            "Epoch 11/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.0469 - accuracy: 0.9804 - val_loss: 0.2187 - val_accuracy: 0.9385\n",
            "Epoch 12/50\n",
            "6/6 [==============================] - 17s 3s/step - loss: 0.0350 - accuracy: 0.9894 - val_loss: 0.1750 - val_accuracy: 0.9692\n",
            "Epoch 13/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0876 - accuracy: 0.9743 - val_loss: 0.1941 - val_accuracy: 0.9692\n",
            "Epoch 14/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0599 - accuracy: 0.9743 - val_loss: 0.2476 - val_accuracy: 0.9423\n",
            "Epoch 15/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0293 - accuracy: 0.9879 - val_loss: 0.2066 - val_accuracy: 0.9615\n",
            "Epoch 16/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0244 - accuracy: 0.9909 - val_loss: 0.1940 - val_accuracy: 0.9577\n",
            "Epoch 17/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0280 - accuracy: 0.9940 - val_loss: 0.2202 - val_accuracy: 0.9538\n",
            "Epoch 18/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0369 - accuracy: 0.9879 - val_loss: 0.1411 - val_accuracy: 0.9731\n",
            "Epoch 19/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0367 - accuracy: 0.9819 - val_loss: 0.1457 - val_accuracy: 0.9692\n",
            "Epoch 20/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0808 - accuracy: 0.9789 - val_loss: 0.2326 - val_accuracy: 0.9500\n",
            "Epoch 21/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0422 - accuracy: 0.9879 - val_loss: 0.1555 - val_accuracy: 0.9731\n",
            "Epoch 22/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0398 - accuracy: 0.9894 - val_loss: 0.1675 - val_accuracy: 0.9654\n",
            "Epoch 23/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.0172 - accuracy: 0.9940 - val_loss: 0.1694 - val_accuracy: 0.9654\n",
            "Epoch 24/50\n",
            "6/6 [==============================] - 21s 4s/step - loss: 0.0202 - accuracy: 0.9909 - val_loss: 0.1488 - val_accuracy: 0.9731\n",
            "Epoch 25/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.0382 - accuracy: 0.9864 - val_loss: 0.1893 - val_accuracy: 0.9692\n",
            "Epoch 26/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.0234 - accuracy: 0.9940 - val_loss: 0.2517 - val_accuracy: 0.9538\n",
            "Epoch 27/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0552 - accuracy: 0.9804 - val_loss: 0.1720 - val_accuracy: 0.9692\n",
            "Epoch 28/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0331 - accuracy: 0.9849 - val_loss: 0.1681 - val_accuracy: 0.9731\n",
            "Epoch 29/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0365 - accuracy: 0.9864 - val_loss: 0.1899 - val_accuracy: 0.9769\n",
            "Epoch 30/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0203 - accuracy: 0.9879 - val_loss: 0.2212 - val_accuracy: 0.9654\n",
            "Epoch 31/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0360 - accuracy: 0.9879 - val_loss: 0.2038 - val_accuracy: 0.9692\n",
            "Epoch 32/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0411 - accuracy: 0.9864 - val_loss: 0.2186 - val_accuracy: 0.9731\n",
            "Epoch 33/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0346 - accuracy: 0.9909 - val_loss: 0.2582 - val_accuracy: 0.9538\n",
            "Epoch 34/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0316 - accuracy: 0.9849 - val_loss: 0.1826 - val_accuracy: 0.9731\n",
            "Epoch 35/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0369 - accuracy: 0.9879 - val_loss: 0.1842 - val_accuracy: 0.9692\n",
            "Epoch 36/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0704 - accuracy: 0.9849 - val_loss: 0.3724 - val_accuracy: 0.9346\n",
            "Epoch 37/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.1357 - accuracy: 0.9517 - val_loss: 0.4369 - val_accuracy: 0.9231\n",
            "Epoch 38/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.1028 - accuracy: 0.9713 - val_loss: 0.6321 - val_accuracy: 0.9038\n",
            "Epoch 39/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0781 - accuracy: 0.9743 - val_loss: 0.3175 - val_accuracy: 0.9500\n",
            "Epoch 40/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0184 - accuracy: 0.9955 - val_loss: 0.2789 - val_accuracy: 0.9654\n",
            "Epoch 41/50\n",
            "6/6 [==============================] - 20s 3s/step - loss: 0.0258 - accuracy: 0.9909 - val_loss: 0.2583 - val_accuracy: 0.9654\n",
            "Epoch 42/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0566 - accuracy: 0.9864 - val_loss: 0.4038 - val_accuracy: 0.9308\n",
            "Epoch 43/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.0275 - accuracy: 0.9909 - val_loss: 0.2493 - val_accuracy: 0.9731\n",
            "Epoch 44/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0082 - accuracy: 0.9955 - val_loss: 0.2541 - val_accuracy: 0.9692\n",
            "Epoch 45/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0206 - accuracy: 0.9970 - val_loss: 0.2965 - val_accuracy: 0.9577\n",
            "Epoch 46/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.0122 - accuracy: 0.9970 - val_loss: 0.2348 - val_accuracy: 0.9692\n",
            "Epoch 47/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.0071 - accuracy: 0.9970 - val_loss: 0.2670 - val_accuracy: 0.9615\n",
            "Epoch 48/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0028 - accuracy: 0.9985 - val_loss: 0.2464 - val_accuracy: 0.9731\n",
            "Epoch 49/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0232 - accuracy: 0.9955 - val_loss: 0.2962 - val_accuracy: 0.9538\n",
            "Epoch 50/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.0122 - accuracy: 0.9955 - val_loss: 0.2417 - val_accuracy: 0.9731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7e4zB4hDcwm",
        "outputId": "f375c46d-72a3-48a8-c0f1-8ea679e8a5b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plot_loss(history_model)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnadRSelOtML"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "history_dataframe = pd.DataFrame(history_model.history)\n",
        "history_dataframe['epoch'] = history_model.epoch"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heflxEZgD3T3",
        "outputId": "7cbe2601-25d9-4102-a4ff-5f881bdf2733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.036891</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.141145</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.036678</td>\n",
              "      <td>0.981873</td>\n",
              "      <td>0.145738</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.020238</td>\n",
              "      <td>0.990937</td>\n",
              "      <td>0.148840</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.042236</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.155499</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.053793</td>\n",
              "      <td>0.978852</td>\n",
              "      <td>0.159293</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.039815</td>\n",
              "      <td>0.989426</td>\n",
              "      <td>0.167536</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.033119</td>\n",
              "      <td>0.984894</td>\n",
              "      <td>0.168054</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.017203</td>\n",
              "      <td>0.993958</td>\n",
              "      <td>0.169443</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.055166</td>\n",
              "      <td>0.980363</td>\n",
              "      <td>0.172033</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.034990</td>\n",
              "      <td>0.989426</td>\n",
              "      <td>0.175037</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.328145</td>\n",
              "      <td>0.907855</td>\n",
              "      <td>0.182070</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.031564</td>\n",
              "      <td>0.984894</td>\n",
              "      <td>0.182563</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.036917</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.184233</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.038220</td>\n",
              "      <td>0.986405</td>\n",
              "      <td>0.189299</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.036508</td>\n",
              "      <td>0.986405</td>\n",
              "      <td>0.189898</td>\n",
              "      <td>0.976923</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.024403</td>\n",
              "      <td>0.990937</td>\n",
              "      <td>0.193965</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.087646</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.194083</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.080980</td>\n",
              "      <td>0.977341</td>\n",
              "      <td>0.200884</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.035983</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.203840</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.071147</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.204627</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.106919</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.206196</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.029287</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.206646</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.128486</td>\n",
              "      <td>0.956193</td>\n",
              "      <td>0.215512</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.986405</td>\n",
              "      <td>0.218613</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.046927</td>\n",
              "      <td>0.980363</td>\n",
              "      <td>0.218742</td>\n",
              "      <td>0.938462</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.027984</td>\n",
              "      <td>0.993958</td>\n",
              "      <td>0.220170</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.020287</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.221205</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.171666</td>\n",
              "      <td>0.959215</td>\n",
              "      <td>0.230689</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.080776</td>\n",
              "      <td>0.978852</td>\n",
              "      <td>0.232648</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.145379</td>\n",
              "      <td>0.951662</td>\n",
              "      <td>0.234050</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.012207</td>\n",
              "      <td>0.996979</td>\n",
              "      <td>0.234758</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.012204</td>\n",
              "      <td>0.995468</td>\n",
              "      <td>0.241711</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.151487</td>\n",
              "      <td>0.714502</td>\n",
              "      <td>0.246014</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.002768</td>\n",
              "      <td>0.998489</td>\n",
              "      <td>0.246404</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.059893</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.247594</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.027452</td>\n",
              "      <td>0.990937</td>\n",
              "      <td>0.249323</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.023356</td>\n",
              "      <td>0.993958</td>\n",
              "      <td>0.251703</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.008224</td>\n",
              "      <td>0.995468</td>\n",
              "      <td>0.254138</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.034606</td>\n",
              "      <td>0.990937</td>\n",
              "      <td>0.258239</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.025836</td>\n",
              "      <td>0.990937</td>\n",
              "      <td>0.258280</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.007107</td>\n",
              "      <td>0.996979</td>\n",
              "      <td>0.266969</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.018388</td>\n",
              "      <td>0.995468</td>\n",
              "      <td>0.278945</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.258043</td>\n",
              "      <td>0.918429</td>\n",
              "      <td>0.283871</td>\n",
              "      <td>0.911538</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.023193</td>\n",
              "      <td>0.995468</td>\n",
              "      <td>0.296193</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.020559</td>\n",
              "      <td>0.996979</td>\n",
              "      <td>0.296503</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.078068</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.317547</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.070379</td>\n",
              "      <td>0.984894</td>\n",
              "      <td>0.372404</td>\n",
              "      <td>0.934615</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.056602</td>\n",
              "      <td>0.986405</td>\n",
              "      <td>0.403830</td>\n",
              "      <td>0.930769</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.135743</td>\n",
              "      <td>0.951662</td>\n",
              "      <td>0.436899</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.102783</td>\n",
              "      <td>0.971299</td>\n",
              "      <td>0.632065</td>\n",
              "      <td>0.903846</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy  epoch\n",
              "17  0.036891  0.987915  0.141145      0.973077     17\n",
              "18  0.036678  0.981873  0.145738      0.969231     18\n",
              "23  0.020238  0.990937  0.148840      0.973077     23\n",
              "20  0.042236  0.987915  0.155499      0.973077     20\n",
              "9   0.053793  0.978852  0.159293      0.965385      9\n",
              "21  0.039815  0.989426  0.167536      0.965385     21\n",
              "27  0.033119  0.984894  0.168054      0.973077     27\n",
              "22  0.017203  0.993958  0.169443      0.965385     22\n",
              "26  0.055166  0.980363  0.172033      0.969231     26\n",
              "11  0.034990  0.989426  0.175037      0.969231     11\n",
              "2   0.328145  0.907855  0.182070      0.957692      2\n",
              "33  0.031564  0.984894  0.182563      0.973077     33\n",
              "34  0.036917  0.987915  0.184233      0.969231     34\n",
              "24  0.038220  0.986405  0.189299      0.969231     24\n",
              "28  0.036508  0.986405  0.189898      0.976923     28\n",
              "15  0.024403  0.990937  0.193965      0.957692     15\n",
              "12  0.087646  0.974320  0.194083      0.969231     12\n",
              "6   0.080980  0.977341  0.200884      0.965385      6\n",
              "30  0.035983  0.987915  0.203840      0.969231     30\n",
              "8   0.071147  0.974320  0.204627      0.950000      8\n",
              "7   0.106919  0.974320  0.206196      0.965385      7\n",
              "14  0.029287  0.987915  0.206646      0.961538     14\n",
              "5   0.128486  0.956193  0.215512      0.953846      5\n",
              "31  0.041111  0.986405  0.218613      0.973077     31\n",
              "10  0.046927  0.980363  0.218742      0.938462     10\n",
              "16  0.027984  0.993958  0.220170      0.953846     16\n",
              "29  0.020287  0.987915  0.221205      0.965385     29\n",
              "3   0.171666  0.959215  0.230689      0.942308      3\n",
              "19  0.080776  0.978852  0.232648      0.950000     19\n",
              "4   0.145379  0.951662  0.234050      0.942308      4\n",
              "45  0.012207  0.996979  0.234758      0.969231     45\n",
              "49  0.012204  0.995468  0.241711      0.973077     49\n",
              "0   1.151487  0.714502  0.246014      0.923077      0\n",
              "47  0.002768  0.998489  0.246404      0.973077     47\n",
              "13  0.059893  0.974320  0.247594      0.942308     13\n",
              "42  0.027452  0.990937  0.249323      0.973077     42\n",
              "25  0.023356  0.993958  0.251703      0.953846     25\n",
              "43  0.008224  0.995468  0.254138      0.969231     43\n",
              "32  0.034606  0.990937  0.258239      0.953846     32\n",
              "40  0.025836  0.990937  0.258280      0.965385     40\n",
              "46  0.007107  0.996979  0.266969      0.961538     46\n",
              "39  0.018388  0.995468  0.278945      0.965385     39\n",
              "1   0.258043  0.918429  0.283871      0.911538      1\n",
              "48  0.023193  0.995468  0.296193      0.953846     48\n",
              "44  0.020559  0.996979  0.296503      0.957692     44\n",
              "38  0.078068  0.974320  0.317547      0.950000     38\n",
              "35  0.070379  0.984894  0.372404      0.934615     35\n",
              "41  0.056602  0.986405  0.403830      0.930769     41\n",
              "36  0.135743  0.951662  0.436899      0.923077     36\n",
              "37  0.102783  0.971299  0.632065      0.903846     37"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQZDsf_dP_EG",
        "outputId": "6bdeb7fe-11e4-4568-b8f5-96eb38ff57ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_dataframe.sort_values(by='val_accuracy', ascending=False)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.036508</td>\n",
              "      <td>0.986405</td>\n",
              "      <td>0.189898</td>\n",
              "      <td>0.976923</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.012204</td>\n",
              "      <td>0.995468</td>\n",
              "      <td>0.241711</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.031564</td>\n",
              "      <td>0.984894</td>\n",
              "      <td>0.182563</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.986405</td>\n",
              "      <td>0.218613</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.033119</td>\n",
              "      <td>0.984894</td>\n",
              "      <td>0.168054</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.020238</td>\n",
              "      <td>0.990937</td>\n",
              "      <td>0.148840</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.042236</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.155499</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.036891</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.141145</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.027452</td>\n",
              "      <td>0.990937</td>\n",
              "      <td>0.249323</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.002768</td>\n",
              "      <td>0.998489</td>\n",
              "      <td>0.246404</td>\n",
              "      <td>0.973077</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.036917</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.184233</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.034990</td>\n",
              "      <td>0.989426</td>\n",
              "      <td>0.175037</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.087646</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.194083</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.008224</td>\n",
              "      <td>0.995468</td>\n",
              "      <td>0.254138</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.035983</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.203840</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.012207</td>\n",
              "      <td>0.996979</td>\n",
              "      <td>0.234758</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.036678</td>\n",
              "      <td>0.981873</td>\n",
              "      <td>0.145738</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.055166</td>\n",
              "      <td>0.980363</td>\n",
              "      <td>0.172033</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.038220</td>\n",
              "      <td>0.986405</td>\n",
              "      <td>0.189299</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.017203</td>\n",
              "      <td>0.993958</td>\n",
              "      <td>0.169443</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.020287</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.221205</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.018388</td>\n",
              "      <td>0.995468</td>\n",
              "      <td>0.278945</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.053793</td>\n",
              "      <td>0.978852</td>\n",
              "      <td>0.159293</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.080980</td>\n",
              "      <td>0.977341</td>\n",
              "      <td>0.200884</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.025836</td>\n",
              "      <td>0.990937</td>\n",
              "      <td>0.258280</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.106919</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.206196</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.039815</td>\n",
              "      <td>0.989426</td>\n",
              "      <td>0.167536</td>\n",
              "      <td>0.965385</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.007107</td>\n",
              "      <td>0.996979</td>\n",
              "      <td>0.266969</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.029287</td>\n",
              "      <td>0.987915</td>\n",
              "      <td>0.206646</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.020559</td>\n",
              "      <td>0.996979</td>\n",
              "      <td>0.296503</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.024403</td>\n",
              "      <td>0.990937</td>\n",
              "      <td>0.193965</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.328145</td>\n",
              "      <td>0.907855</td>\n",
              "      <td>0.182070</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.023193</td>\n",
              "      <td>0.995468</td>\n",
              "      <td>0.296193</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.023356</td>\n",
              "      <td>0.993958</td>\n",
              "      <td>0.251703</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.034606</td>\n",
              "      <td>0.990937</td>\n",
              "      <td>0.258239</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.027984</td>\n",
              "      <td>0.993958</td>\n",
              "      <td>0.220170</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.128486</td>\n",
              "      <td>0.956193</td>\n",
              "      <td>0.215512</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.078068</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.317547</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.080776</td>\n",
              "      <td>0.978852</td>\n",
              "      <td>0.232648</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.071147</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.204627</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.059893</td>\n",
              "      <td>0.974320</td>\n",
              "      <td>0.247594</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.145379</td>\n",
              "      <td>0.951662</td>\n",
              "      <td>0.234050</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.171666</td>\n",
              "      <td>0.959215</td>\n",
              "      <td>0.230689</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.046927</td>\n",
              "      <td>0.980363</td>\n",
              "      <td>0.218742</td>\n",
              "      <td>0.938462</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.070379</td>\n",
              "      <td>0.984894</td>\n",
              "      <td>0.372404</td>\n",
              "      <td>0.934615</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.056602</td>\n",
              "      <td>0.986405</td>\n",
              "      <td>0.403830</td>\n",
              "      <td>0.930769</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.135743</td>\n",
              "      <td>0.951662</td>\n",
              "      <td>0.436899</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.151487</td>\n",
              "      <td>0.714502</td>\n",
              "      <td>0.246014</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.258043</td>\n",
              "      <td>0.918429</td>\n",
              "      <td>0.283871</td>\n",
              "      <td>0.911538</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.102783</td>\n",
              "      <td>0.971299</td>\n",
              "      <td>0.632065</td>\n",
              "      <td>0.903846</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy  epoch\n",
              "28  0.036508  0.986405  0.189898      0.976923     28\n",
              "49  0.012204  0.995468  0.241711      0.973077     49\n",
              "33  0.031564  0.984894  0.182563      0.973077     33\n",
              "31  0.041111  0.986405  0.218613      0.973077     31\n",
              "27  0.033119  0.984894  0.168054      0.973077     27\n",
              "23  0.020238  0.990937  0.148840      0.973077     23\n",
              "20  0.042236  0.987915  0.155499      0.973077     20\n",
              "17  0.036891  0.987915  0.141145      0.973077     17\n",
              "42  0.027452  0.990937  0.249323      0.973077     42\n",
              "47  0.002768  0.998489  0.246404      0.973077     47\n",
              "34  0.036917  0.987915  0.184233      0.969231     34\n",
              "11  0.034990  0.989426  0.175037      0.969231     11\n",
              "12  0.087646  0.974320  0.194083      0.969231     12\n",
              "43  0.008224  0.995468  0.254138      0.969231     43\n",
              "30  0.035983  0.987915  0.203840      0.969231     30\n",
              "45  0.012207  0.996979  0.234758      0.969231     45\n",
              "18  0.036678  0.981873  0.145738      0.969231     18\n",
              "26  0.055166  0.980363  0.172033      0.969231     26\n",
              "24  0.038220  0.986405  0.189299      0.969231     24\n",
              "22  0.017203  0.993958  0.169443      0.965385     22\n",
              "29  0.020287  0.987915  0.221205      0.965385     29\n",
              "39  0.018388  0.995468  0.278945      0.965385     39\n",
              "9   0.053793  0.978852  0.159293      0.965385      9\n",
              "6   0.080980  0.977341  0.200884      0.965385      6\n",
              "40  0.025836  0.990937  0.258280      0.965385     40\n",
              "7   0.106919  0.974320  0.206196      0.965385      7\n",
              "21  0.039815  0.989426  0.167536      0.965385     21\n",
              "46  0.007107  0.996979  0.266969      0.961538     46\n",
              "14  0.029287  0.987915  0.206646      0.961538     14\n",
              "44  0.020559  0.996979  0.296503      0.957692     44\n",
              "15  0.024403  0.990937  0.193965      0.957692     15\n",
              "2   0.328145  0.907855  0.182070      0.957692      2\n",
              "48  0.023193  0.995468  0.296193      0.953846     48\n",
              "25  0.023356  0.993958  0.251703      0.953846     25\n",
              "32  0.034606  0.990937  0.258239      0.953846     32\n",
              "16  0.027984  0.993958  0.220170      0.953846     16\n",
              "5   0.128486  0.956193  0.215512      0.953846      5\n",
              "38  0.078068  0.974320  0.317547      0.950000     38\n",
              "19  0.080776  0.978852  0.232648      0.950000     19\n",
              "8   0.071147  0.974320  0.204627      0.950000      8\n",
              "13  0.059893  0.974320  0.247594      0.942308     13\n",
              "4   0.145379  0.951662  0.234050      0.942308      4\n",
              "3   0.171666  0.959215  0.230689      0.942308      3\n",
              "10  0.046927  0.980363  0.218742      0.938462     10\n",
              "35  0.070379  0.984894  0.372404      0.934615     35\n",
              "41  0.056602  0.986405  0.403830      0.930769     41\n",
              "36  0.135743  0.951662  0.436899      0.923077     36\n",
              "0   1.151487  0.714502  0.246014      0.923077      0\n",
              "1   0.258043  0.918429  0.283871      0.911538      1\n",
              "37  0.102783  0.971299  0.632065      0.903846     37"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHzrFCooJTEw"
      },
      "source": [
        "**Kita ingin mencari loss yang terendah, loss ini terhadap val_lossnya**\n",
        "\n",
        "Nilai val_accuracy tertinggi pada model berada pada epoch 28 yaitu sebesar 0.976923 akan tetapi kita harus tinjau juga berdasarkan val_lossnya. Berdasarkan grafik epoch terhadap loss pada arsitektur CNN dengan vgg16 dan image augmentation, terlihat bahwa garis loss dan val_loss nya cenderung stabil dengan epoch 50 namun terjadi peningkatan pada epoch 34 hingga mulai turun kembali pada epoch 36. Terlihat adanya perbedaan jarak antara loss dan val_lossnya dengan 50 epoch yang tidak begitu besar yang berarti model yang kita buat ini cukup bagus. Nilai val_loss terendah diperoleh saat epochnya sekitar 17, dimana diperoleh val_loss: 0.141145 dan val_accuracy: 0.973077, sedikit lebih kecil dibanding val_accuracy tertingginya"
      ]
    }
  ]
}