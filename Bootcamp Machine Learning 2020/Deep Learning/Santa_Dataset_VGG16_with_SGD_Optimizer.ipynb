{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Santa Dataset VGG16 with SGD Optimizer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiN1cmfXR-QO"
      },
      "source": [
        "## **Santa Dataset with VGG16 & SGD Optimizer**\n",
        "\n",
        "**Benedictus Bayu Pramudhito**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFwNJKHWKBty",
        "outputId": "29026068-f38a-4005-ad95-d887fb4bf683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pebVB50qKICW"
      },
      "source": [
        "zip_path = '/content/drive/My\\ Drive/santa-dataset.zip'\n",
        "\n",
        "!cp {zip_path} /content/\n",
        "\n",
        "!cd /content/\n",
        "\n",
        "!unzip -q /content/santa-dataset.zip -d /content\n",
        "\n",
        "!rm /content/santa-dataset.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl7k7kbTKPMf"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVHIfI1AKprj"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy5ZGHJKKRhs"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6_lf8yRKRus",
        "outputId": "6ff6fcbe-67b4-4876-d526-ac24d8f7bd15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "dataset_dir = '/content/'\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "\n",
        "train_augmented_iteration = train_datagen.flow_from_directory(os.path.join(dataset_dir, 'train'), class_mode='binary', batch_size=128, target_size=(224, 224))\n",
        "test_augmented_iteration = test_datagen.flow_from_directory(os.path.join(dataset_dir, 'test'), class_mode='binary', batch_size=128, target_size=(224, 224))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 662 images belonging to 2 classes.\n",
            "Found 260 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI1ErhA4KRcb"
      },
      "source": [
        "from tensorflow.keras.applications import vgg16\n",
        "from tensorflow.keras.layers import Dropout"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAKqLXDCKbUz",
        "outputId": "45906e57-9895-47a7-e563-4d8e117cee18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "vgg_conv = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in vgg_conv.layers[:]:\n",
        "  layer.trainable = False\n",
        "\n",
        "fine_tuned_model = Sequential()\n",
        "\n",
        "fine_tuned_model.add(vgg_conv)\n",
        "\n",
        "fine_tuned_model.add(Flatten())\n",
        "fine_tuned_model.add(Dense(1024, activation='relu'))\n",
        "fine_tuned_model.add(Dropout(0.5))\n",
        "fine_tuned_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "fine_tuned_model.summary()\n",
        "\n",
        "opt = SGD(learning_rate=0.0001, momentum=0.9)\n",
        "\n",
        "fine_tuned_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 1025      \n",
            "=================================================================\n",
            "Total params: 40,406,849\n",
            "Trainable params: 25,692,161\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWi3TgqEKd30",
        "outputId": "a4538143-2cec-4daa-d6c2-72f85948ceac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_model = fine_tuned_model.fit_generator(train_augmented_iteration, steps_per_epoch=len(train_augmented_iteration), validation_data=test_augmented_iteration, validation_steps=len(test_augmented_iteration), epochs=50)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-10-e259ca58586a>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/50\n",
            "6/6 [==============================] - 24s 4s/step - loss: 0.7598 - accuracy: 0.5106 - val_loss: 0.7064 - val_accuracy: 0.4731\n",
            "Epoch 2/50\n",
            "6/6 [==============================] - 20s 3s/step - loss: 0.7647 - accuracy: 0.5045 - val_loss: 0.6442 - val_accuracy: 0.6423\n",
            "Epoch 3/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.6950 - accuracy: 0.5891 - val_loss: 0.5893 - val_accuracy: 0.7423\n",
            "Epoch 4/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.6210 - accuracy: 0.6450 - val_loss: 0.5320 - val_accuracy: 0.8308\n",
            "Epoch 5/50\n",
            "6/6 [==============================] - 22s 4s/step - loss: 0.5768 - accuracy: 0.7009 - val_loss: 0.4874 - val_accuracy: 0.8692\n",
            "Epoch 6/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.4852 - accuracy: 0.7900 - val_loss: 0.4503 - val_accuracy: 0.9077\n",
            "Epoch 7/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.4749 - accuracy: 0.8097 - val_loss: 0.4204 - val_accuracy: 0.9077\n",
            "Epoch 8/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.4447 - accuracy: 0.8172 - val_loss: 0.3974 - val_accuracy: 0.9038\n",
            "Epoch 9/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.4273 - accuracy: 0.8323 - val_loss: 0.3766 - val_accuracy: 0.9231\n",
            "Epoch 10/50\n",
            "6/6 [==============================] - 21s 4s/step - loss: 0.4049 - accuracy: 0.8399 - val_loss: 0.3616 - val_accuracy: 0.9231\n",
            "Epoch 11/50\n",
            "6/6 [==============================] - 21s 4s/step - loss: 0.3801 - accuracy: 0.8716 - val_loss: 0.3472 - val_accuracy: 0.9154\n",
            "Epoch 12/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.3902 - accuracy: 0.8489 - val_loss: 0.3318 - val_accuracy: 0.9269\n",
            "Epoch 13/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.3674 - accuracy: 0.8761 - val_loss: 0.3198 - val_accuracy: 0.9231\n",
            "Epoch 14/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.3478 - accuracy: 0.8837 - val_loss: 0.3112 - val_accuracy: 0.9231\n",
            "Epoch 15/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.3470 - accuracy: 0.8761 - val_loss: 0.3049 - val_accuracy: 0.9231\n",
            "Epoch 16/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.3136 - accuracy: 0.8988 - val_loss: 0.2914 - val_accuracy: 0.9346\n",
            "Epoch 17/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.3179 - accuracy: 0.9018 - val_loss: 0.2859 - val_accuracy: 0.9269\n",
            "Epoch 18/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.3013 - accuracy: 0.8958 - val_loss: 0.2787 - val_accuracy: 0.9231\n",
            "Epoch 19/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.3079 - accuracy: 0.9033 - val_loss: 0.2694 - val_accuracy: 0.9385\n",
            "Epoch 20/50\n",
            "6/6 [==============================] - 21s 3s/step - loss: 0.3020 - accuracy: 0.9094 - val_loss: 0.2671 - val_accuracy: 0.9346\n",
            "Epoch 21/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.2811 - accuracy: 0.9109 - val_loss: 0.2581 - val_accuracy: 0.9269\n",
            "Epoch 22/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.2879 - accuracy: 0.8973 - val_loss: 0.2530 - val_accuracy: 0.9308\n",
            "Epoch 23/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.2749 - accuracy: 0.9215 - val_loss: 0.2493 - val_accuracy: 0.9462\n",
            "Epoch 24/50\n",
            "6/6 [==============================] - 21s 3s/step - loss: 0.2757 - accuracy: 0.9139 - val_loss: 0.2460 - val_accuracy: 0.9500\n",
            "Epoch 25/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.2599 - accuracy: 0.9245 - val_loss: 0.2400 - val_accuracy: 0.9385\n",
            "Epoch 26/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.2563 - accuracy: 0.9215 - val_loss: 0.2362 - val_accuracy: 0.9385\n",
            "Epoch 27/50\n",
            "6/6 [==============================] - 21s 3s/step - loss: 0.2526 - accuracy: 0.9199 - val_loss: 0.2338 - val_accuracy: 0.9500\n",
            "Epoch 28/50\n",
            "6/6 [==============================] - 17s 3s/step - loss: 0.2470 - accuracy: 0.9245 - val_loss: 0.2330 - val_accuracy: 0.9500\n",
            "Epoch 29/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.2510 - accuracy: 0.9245 - val_loss: 0.2267 - val_accuracy: 0.9385\n",
            "Epoch 30/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.2273 - accuracy: 0.9366 - val_loss: 0.2240 - val_accuracy: 0.9423\n",
            "Epoch 31/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.2404 - accuracy: 0.9154 - val_loss: 0.2243 - val_accuracy: 0.9500\n",
            "Epoch 32/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.2228 - accuracy: 0.9305 - val_loss: 0.2229 - val_accuracy: 0.9500\n",
            "Epoch 33/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.2362 - accuracy: 0.9245 - val_loss: 0.2165 - val_accuracy: 0.9423\n",
            "Epoch 34/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.2397 - accuracy: 0.9215 - val_loss: 0.2142 - val_accuracy: 0.9462\n",
            "Epoch 35/50\n",
            "6/6 [==============================] - 17s 3s/step - loss: 0.2310 - accuracy: 0.9215 - val_loss: 0.2128 - val_accuracy: 0.9423\n",
            "Epoch 36/50\n",
            "6/6 [==============================] - 17s 3s/step - loss: 0.2223 - accuracy: 0.9335 - val_loss: 0.2118 - val_accuracy: 0.9462\n",
            "Epoch 37/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.2209 - accuracy: 0.9305 - val_loss: 0.2077 - val_accuracy: 0.9462\n",
            "Epoch 38/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.2298 - accuracy: 0.9124 - val_loss: 0.2061 - val_accuracy: 0.9500\n",
            "Epoch 39/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.2193 - accuracy: 0.9230 - val_loss: 0.2067 - val_accuracy: 0.9500\n",
            "Epoch 40/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.2125 - accuracy: 0.9366 - val_loss: 0.2023 - val_accuracy: 0.9462\n",
            "Epoch 41/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.2119 - accuracy: 0.9275 - val_loss: 0.1996 - val_accuracy: 0.9462\n",
            "Epoch 42/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.2022 - accuracy: 0.9381 - val_loss: 0.1976 - val_accuracy: 0.9500\n",
            "Epoch 43/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.2067 - accuracy: 0.9320 - val_loss: 0.1968 - val_accuracy: 0.9462\n",
            "Epoch 44/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.2169 - accuracy: 0.9245 - val_loss: 0.1991 - val_accuracy: 0.9500\n",
            "Epoch 45/50\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.2111 - accuracy: 0.9215 - val_loss: 0.1926 - val_accuracy: 0.9500\n",
            "Epoch 46/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.2012 - accuracy: 0.9350 - val_loss: 0.1921 - val_accuracy: 0.9500\n",
            "Epoch 47/50\n",
            "6/6 [==============================] - 21s 4s/step - loss: 0.1922 - accuracy: 0.9441 - val_loss: 0.1902 - val_accuracy: 0.9500\n",
            "Epoch 48/50\n",
            "6/6 [==============================] - 21s 4s/step - loss: 0.2003 - accuracy: 0.9260 - val_loss: 0.1903 - val_accuracy: 0.9500\n",
            "Epoch 49/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.1975 - accuracy: 0.9350 - val_loss: 0.1885 - val_accuracy: 0.9500\n",
            "Epoch 50/50\n",
            "6/6 [==============================] - 18s 3s/step - loss: 0.1879 - accuracy: 0.9350 - val_loss: 0.1882 - val_accuracy: 0.9500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmY4lI_JKsfy",
        "outputId": "6554ad79-d019-4141-d612-8ab698595051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_loss(history_model)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-kCiZRxQtSc"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "history_dataframe = pd.DataFrame(history_model.history)\n",
        "history_dataframe['epoch'] = history_model.epoch"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx5a0Yj4Q752",
        "outputId": "93416458-b324-41f2-f62b-a9a6d2a0ae79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.187866</td>\n",
              "      <td>0.935045</td>\n",
              "      <td>0.188225</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.197519</td>\n",
              "      <td>0.935045</td>\n",
              "      <td>0.188489</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.192174</td>\n",
              "      <td>0.944109</td>\n",
              "      <td>0.190231</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.200321</td>\n",
              "      <td>0.925982</td>\n",
              "      <td>0.190323</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.201180</td>\n",
              "      <td>0.935045</td>\n",
              "      <td>0.192122</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.211145</td>\n",
              "      <td>0.921450</td>\n",
              "      <td>0.192596</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.206710</td>\n",
              "      <td>0.932024</td>\n",
              "      <td>0.196840</td>\n",
              "      <td>0.946154</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.202241</td>\n",
              "      <td>0.938066</td>\n",
              "      <td>0.197572</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.216868</td>\n",
              "      <td>0.924471</td>\n",
              "      <td>0.199137</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.211906</td>\n",
              "      <td>0.927492</td>\n",
              "      <td>0.199638</td>\n",
              "      <td>0.946154</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.212535</td>\n",
              "      <td>0.936556</td>\n",
              "      <td>0.202299</td>\n",
              "      <td>0.946154</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.229842</td>\n",
              "      <td>0.912387</td>\n",
              "      <td>0.206060</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.219350</td>\n",
              "      <td>0.922961</td>\n",
              "      <td>0.206666</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.220863</td>\n",
              "      <td>0.930514</td>\n",
              "      <td>0.207721</td>\n",
              "      <td>0.946154</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.222286</td>\n",
              "      <td>0.933535</td>\n",
              "      <td>0.211805</td>\n",
              "      <td>0.946154</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.231021</td>\n",
              "      <td>0.921450</td>\n",
              "      <td>0.212781</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.239707</td>\n",
              "      <td>0.921450</td>\n",
              "      <td>0.214226</td>\n",
              "      <td>0.946154</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.236227</td>\n",
              "      <td>0.924471</td>\n",
              "      <td>0.216478</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.222800</td>\n",
              "      <td>0.930514</td>\n",
              "      <td>0.222851</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.227257</td>\n",
              "      <td>0.936556</td>\n",
              "      <td>0.223998</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.240422</td>\n",
              "      <td>0.915408</td>\n",
              "      <td>0.224257</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.250984</td>\n",
              "      <td>0.924471</td>\n",
              "      <td>0.226732</td>\n",
              "      <td>0.938462</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.247033</td>\n",
              "      <td>0.924471</td>\n",
              "      <td>0.233042</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.252552</td>\n",
              "      <td>0.919940</td>\n",
              "      <td>0.233793</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.256334</td>\n",
              "      <td>0.921450</td>\n",
              "      <td>0.236203</td>\n",
              "      <td>0.938462</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.259945</td>\n",
              "      <td>0.924471</td>\n",
              "      <td>0.239986</td>\n",
              "      <td>0.938462</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.275746</td>\n",
              "      <td>0.913897</td>\n",
              "      <td>0.245969</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.274938</td>\n",
              "      <td>0.921450</td>\n",
              "      <td>0.249330</td>\n",
              "      <td>0.946154</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.287859</td>\n",
              "      <td>0.897281</td>\n",
              "      <td>0.253011</td>\n",
              "      <td>0.930769</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.281135</td>\n",
              "      <td>0.910876</td>\n",
              "      <td>0.258147</td>\n",
              "      <td>0.926923</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.302014</td>\n",
              "      <td>0.909366</td>\n",
              "      <td>0.267074</td>\n",
              "      <td>0.934615</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.307870</td>\n",
              "      <td>0.903323</td>\n",
              "      <td>0.269408</td>\n",
              "      <td>0.938462</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.301317</td>\n",
              "      <td>0.895770</td>\n",
              "      <td>0.278741</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.317898</td>\n",
              "      <td>0.901813</td>\n",
              "      <td>0.285866</td>\n",
              "      <td>0.926923</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.313642</td>\n",
              "      <td>0.898792</td>\n",
              "      <td>0.291379</td>\n",
              "      <td>0.934615</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.347027</td>\n",
              "      <td>0.876133</td>\n",
              "      <td>0.304868</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.347778</td>\n",
              "      <td>0.883686</td>\n",
              "      <td>0.311199</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.367420</td>\n",
              "      <td>0.876133</td>\n",
              "      <td>0.319781</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.390223</td>\n",
              "      <td>0.848943</td>\n",
              "      <td>0.331753</td>\n",
              "      <td>0.926923</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.380077</td>\n",
              "      <td>0.871601</td>\n",
              "      <td>0.347184</td>\n",
              "      <td>0.915385</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.404930</td>\n",
              "      <td>0.839879</td>\n",
              "      <td>0.361646</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.427273</td>\n",
              "      <td>0.832326</td>\n",
              "      <td>0.376609</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.444697</td>\n",
              "      <td>0.817221</td>\n",
              "      <td>0.397388</td>\n",
              "      <td>0.903846</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.474868</td>\n",
              "      <td>0.809668</td>\n",
              "      <td>0.420430</td>\n",
              "      <td>0.907692</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.485157</td>\n",
              "      <td>0.790030</td>\n",
              "      <td>0.450311</td>\n",
              "      <td>0.907692</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.576770</td>\n",
              "      <td>0.700906</td>\n",
              "      <td>0.487432</td>\n",
              "      <td>0.869231</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.620985</td>\n",
              "      <td>0.645015</td>\n",
              "      <td>0.531990</td>\n",
              "      <td>0.830769</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.695035</td>\n",
              "      <td>0.589124</td>\n",
              "      <td>0.589346</td>\n",
              "      <td>0.742308</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.764695</td>\n",
              "      <td>0.504532</td>\n",
              "      <td>0.644155</td>\n",
              "      <td>0.642308</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.759792</td>\n",
              "      <td>0.510574</td>\n",
              "      <td>0.706405</td>\n",
              "      <td>0.473077</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy  epoch\n",
              "49  0.187866  0.935045  0.188225      0.950000     49\n",
              "48  0.197519  0.935045  0.188489      0.950000     48\n",
              "46  0.192174  0.944109  0.190231      0.950000     46\n",
              "47  0.200321  0.925982  0.190323      0.950000     47\n",
              "45  0.201180  0.935045  0.192122      0.950000     45\n",
              "44  0.211145  0.921450  0.192596      0.950000     44\n",
              "42  0.206710  0.932024  0.196840      0.946154     42\n",
              "41  0.202241  0.938066  0.197572      0.950000     41\n",
              "43  0.216868  0.924471  0.199137      0.950000     43\n",
              "40  0.211906  0.927492  0.199638      0.946154     40\n",
              "39  0.212535  0.936556  0.202299      0.946154     39\n",
              "37  0.229842  0.912387  0.206060      0.950000     37\n",
              "38  0.219350  0.922961  0.206666      0.950000     38\n",
              "36  0.220863  0.930514  0.207721      0.946154     36\n",
              "35  0.222286  0.933535  0.211805      0.946154     35\n",
              "34  0.231021  0.921450  0.212781      0.942308     34\n",
              "33  0.239707  0.921450  0.214226      0.946154     33\n",
              "32  0.236227  0.924471  0.216478      0.942308     32\n",
              "31  0.222800  0.930514  0.222851      0.950000     31\n",
              "29  0.227257  0.936556  0.223998      0.942308     29\n",
              "30  0.240422  0.915408  0.224257      0.950000     30\n",
              "28  0.250984  0.924471  0.226732      0.938462     28\n",
              "27  0.247033  0.924471  0.233042      0.950000     27\n",
              "26  0.252552  0.919940  0.233793      0.950000     26\n",
              "25  0.256334  0.921450  0.236203      0.938462     25\n",
              "24  0.259945  0.924471  0.239986      0.938462     24\n",
              "23  0.275746  0.913897  0.245969      0.950000     23\n",
              "22  0.274938  0.921450  0.249330      0.946154     22\n",
              "21  0.287859  0.897281  0.253011      0.930769     21\n",
              "20  0.281135  0.910876  0.258147      0.926923     20\n",
              "19  0.302014  0.909366  0.267074      0.934615     19\n",
              "18  0.307870  0.903323  0.269408      0.938462     18\n",
              "17  0.301317  0.895770  0.278741      0.923077     17\n",
              "16  0.317898  0.901813  0.285866      0.926923     16\n",
              "15  0.313642  0.898792  0.291379      0.934615     15\n",
              "14  0.347027  0.876133  0.304868      0.923077     14\n",
              "13  0.347778  0.883686  0.311199      0.923077     13\n",
              "12  0.367420  0.876133  0.319781      0.923077     12\n",
              "11  0.390223  0.848943  0.331753      0.926923     11\n",
              "10  0.380077  0.871601  0.347184      0.915385     10\n",
              "9   0.404930  0.839879  0.361646      0.923077      9\n",
              "8   0.427273  0.832326  0.376609      0.923077      8\n",
              "7   0.444697  0.817221  0.397388      0.903846      7\n",
              "6   0.474868  0.809668  0.420430      0.907692      6\n",
              "5   0.485157  0.790030  0.450311      0.907692      5\n",
              "4   0.576770  0.700906  0.487432      0.869231      4\n",
              "3   0.620985  0.645015  0.531990      0.830769      3\n",
              "2   0.695035  0.589124  0.589346      0.742308      2\n",
              "1   0.764695  0.504532  0.644155      0.642308      1\n",
              "0   0.759792  0.510574  0.706405      0.473077      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFJkodwARBSD",
        "outputId": "6d0fea6a-1839-423b-ed24-f5a1937c0bf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_dataframe.sort_values(by='val_accuracy', ascending=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.187866</td>\n",
              "      <td>0.935045</td>\n",
              "      <td>0.188225</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.202241</td>\n",
              "      <td>0.938066</td>\n",
              "      <td>0.197572</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.275746</td>\n",
              "      <td>0.913897</td>\n",
              "      <td>0.245969</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.240422</td>\n",
              "      <td>0.915408</td>\n",
              "      <td>0.224257</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.222800</td>\n",
              "      <td>0.930514</td>\n",
              "      <td>0.222851</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.252552</td>\n",
              "      <td>0.919940</td>\n",
              "      <td>0.233793</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.219350</td>\n",
              "      <td>0.922961</td>\n",
              "      <td>0.206666</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.229842</td>\n",
              "      <td>0.912387</td>\n",
              "      <td>0.206060</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.247033</td>\n",
              "      <td>0.924471</td>\n",
              "      <td>0.233042</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.216868</td>\n",
              "      <td>0.924471</td>\n",
              "      <td>0.199137</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.197519</td>\n",
              "      <td>0.935045</td>\n",
              "      <td>0.188489</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.211145</td>\n",
              "      <td>0.921450</td>\n",
              "      <td>0.192596</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.201180</td>\n",
              "      <td>0.935045</td>\n",
              "      <td>0.192122</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.200321</td>\n",
              "      <td>0.925982</td>\n",
              "      <td>0.190323</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.192174</td>\n",
              "      <td>0.944109</td>\n",
              "      <td>0.190231</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.274938</td>\n",
              "      <td>0.921450</td>\n",
              "      <td>0.249330</td>\n",
              "      <td>0.946154</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.206710</td>\n",
              "      <td>0.932024</td>\n",
              "      <td>0.196840</td>\n",
              "      <td>0.946154</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.222286</td>\n",
              "      <td>0.933535</td>\n",
              "      <td>0.211805</td>\n",
              "      <td>0.946154</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.220863</td>\n",
              "      <td>0.930514</td>\n",
              "      <td>0.207721</td>\n",
              "      <td>0.946154</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.212535</td>\n",
              "      <td>0.936556</td>\n",
              "      <td>0.202299</td>\n",
              "      <td>0.946154</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.211906</td>\n",
              "      <td>0.927492</td>\n",
              "      <td>0.199638</td>\n",
              "      <td>0.946154</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.239707</td>\n",
              "      <td>0.921450</td>\n",
              "      <td>0.214226</td>\n",
              "      <td>0.946154</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.231021</td>\n",
              "      <td>0.921450</td>\n",
              "      <td>0.212781</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.236227</td>\n",
              "      <td>0.924471</td>\n",
              "      <td>0.216478</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.227257</td>\n",
              "      <td>0.936556</td>\n",
              "      <td>0.223998</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.250984</td>\n",
              "      <td>0.924471</td>\n",
              "      <td>0.226732</td>\n",
              "      <td>0.938462</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.256334</td>\n",
              "      <td>0.921450</td>\n",
              "      <td>0.236203</td>\n",
              "      <td>0.938462</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.259945</td>\n",
              "      <td>0.924471</td>\n",
              "      <td>0.239986</td>\n",
              "      <td>0.938462</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.307870</td>\n",
              "      <td>0.903323</td>\n",
              "      <td>0.269408</td>\n",
              "      <td>0.938462</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.302014</td>\n",
              "      <td>0.909366</td>\n",
              "      <td>0.267074</td>\n",
              "      <td>0.934615</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.313642</td>\n",
              "      <td>0.898792</td>\n",
              "      <td>0.291379</td>\n",
              "      <td>0.934615</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.287859</td>\n",
              "      <td>0.897281</td>\n",
              "      <td>0.253011</td>\n",
              "      <td>0.930769</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.281135</td>\n",
              "      <td>0.910876</td>\n",
              "      <td>0.258147</td>\n",
              "      <td>0.926923</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.317898</td>\n",
              "      <td>0.901813</td>\n",
              "      <td>0.285866</td>\n",
              "      <td>0.926923</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.390223</td>\n",
              "      <td>0.848943</td>\n",
              "      <td>0.331753</td>\n",
              "      <td>0.926923</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.367420</td>\n",
              "      <td>0.876133</td>\n",
              "      <td>0.319781</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.427273</td>\n",
              "      <td>0.832326</td>\n",
              "      <td>0.376609</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.404930</td>\n",
              "      <td>0.839879</td>\n",
              "      <td>0.361646</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.347778</td>\n",
              "      <td>0.883686</td>\n",
              "      <td>0.311199</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.347027</td>\n",
              "      <td>0.876133</td>\n",
              "      <td>0.304868</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.301317</td>\n",
              "      <td>0.895770</td>\n",
              "      <td>0.278741</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.380077</td>\n",
              "      <td>0.871601</td>\n",
              "      <td>0.347184</td>\n",
              "      <td>0.915385</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.474868</td>\n",
              "      <td>0.809668</td>\n",
              "      <td>0.420430</td>\n",
              "      <td>0.907692</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.485157</td>\n",
              "      <td>0.790030</td>\n",
              "      <td>0.450311</td>\n",
              "      <td>0.907692</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.444697</td>\n",
              "      <td>0.817221</td>\n",
              "      <td>0.397388</td>\n",
              "      <td>0.903846</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.576770</td>\n",
              "      <td>0.700906</td>\n",
              "      <td>0.487432</td>\n",
              "      <td>0.869231</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.620985</td>\n",
              "      <td>0.645015</td>\n",
              "      <td>0.531990</td>\n",
              "      <td>0.830769</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.695035</td>\n",
              "      <td>0.589124</td>\n",
              "      <td>0.589346</td>\n",
              "      <td>0.742308</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.764695</td>\n",
              "      <td>0.504532</td>\n",
              "      <td>0.644155</td>\n",
              "      <td>0.642308</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.759792</td>\n",
              "      <td>0.510574</td>\n",
              "      <td>0.706405</td>\n",
              "      <td>0.473077</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy  epoch\n",
              "49  0.187866  0.935045  0.188225      0.950000     49\n",
              "41  0.202241  0.938066  0.197572      0.950000     41\n",
              "23  0.275746  0.913897  0.245969      0.950000     23\n",
              "30  0.240422  0.915408  0.224257      0.950000     30\n",
              "31  0.222800  0.930514  0.222851      0.950000     31\n",
              "26  0.252552  0.919940  0.233793      0.950000     26\n",
              "38  0.219350  0.922961  0.206666      0.950000     38\n",
              "37  0.229842  0.912387  0.206060      0.950000     37\n",
              "27  0.247033  0.924471  0.233042      0.950000     27\n",
              "43  0.216868  0.924471  0.199137      0.950000     43\n",
              "48  0.197519  0.935045  0.188489      0.950000     48\n",
              "44  0.211145  0.921450  0.192596      0.950000     44\n",
              "45  0.201180  0.935045  0.192122      0.950000     45\n",
              "47  0.200321  0.925982  0.190323      0.950000     47\n",
              "46  0.192174  0.944109  0.190231      0.950000     46\n",
              "22  0.274938  0.921450  0.249330      0.946154     22\n",
              "42  0.206710  0.932024  0.196840      0.946154     42\n",
              "35  0.222286  0.933535  0.211805      0.946154     35\n",
              "36  0.220863  0.930514  0.207721      0.946154     36\n",
              "39  0.212535  0.936556  0.202299      0.946154     39\n",
              "40  0.211906  0.927492  0.199638      0.946154     40\n",
              "33  0.239707  0.921450  0.214226      0.946154     33\n",
              "34  0.231021  0.921450  0.212781      0.942308     34\n",
              "32  0.236227  0.924471  0.216478      0.942308     32\n",
              "29  0.227257  0.936556  0.223998      0.942308     29\n",
              "28  0.250984  0.924471  0.226732      0.938462     28\n",
              "25  0.256334  0.921450  0.236203      0.938462     25\n",
              "24  0.259945  0.924471  0.239986      0.938462     24\n",
              "18  0.307870  0.903323  0.269408      0.938462     18\n",
              "19  0.302014  0.909366  0.267074      0.934615     19\n",
              "15  0.313642  0.898792  0.291379      0.934615     15\n",
              "21  0.287859  0.897281  0.253011      0.930769     21\n",
              "20  0.281135  0.910876  0.258147      0.926923     20\n",
              "16  0.317898  0.901813  0.285866      0.926923     16\n",
              "11  0.390223  0.848943  0.331753      0.926923     11\n",
              "12  0.367420  0.876133  0.319781      0.923077     12\n",
              "8   0.427273  0.832326  0.376609      0.923077      8\n",
              "9   0.404930  0.839879  0.361646      0.923077      9\n",
              "13  0.347778  0.883686  0.311199      0.923077     13\n",
              "14  0.347027  0.876133  0.304868      0.923077     14\n",
              "17  0.301317  0.895770  0.278741      0.923077     17\n",
              "10  0.380077  0.871601  0.347184      0.915385     10\n",
              "6   0.474868  0.809668  0.420430      0.907692      6\n",
              "5   0.485157  0.790030  0.450311      0.907692      5\n",
              "7   0.444697  0.817221  0.397388      0.903846      7\n",
              "4   0.576770  0.700906  0.487432      0.869231      4\n",
              "3   0.620985  0.645015  0.531990      0.830769      3\n",
              "2   0.695035  0.589124  0.589346      0.742308      2\n",
              "1   0.764695  0.504532  0.644155      0.642308      1\n",
              "0   0.759792  0.510574  0.706405      0.473077      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJUGDSK6RWVD"
      },
      "source": [
        "**Kita ingin mencari loss yang terendah, loss ini terhadap val_lossnya**\n",
        "\n",
        "Nilai val_accuracy tertinggi pada model berada pada epoch 46 hingga 50 yaitu sebesar 0.95 akan tetapi kita harus tinjau juga berdasarkan val_lossnya. Berdasarkan grafik epoch terhadap loss pada arsitektur CNN dengan vgg16 dan image augmentation dengan optimizer SGD, terlihat bahwa garis loss dan val_loss nya terus menurun dengan 50 epoch. Terlihat adanya perbedaan jarak antara loss dan val_lossnya dengan 50 epoch yang kecil yang berarti model yang kita buat ini bagus. Nilai val_loss terendah diperoleh saat epochnya sekitar 50, dimana diperoleh val_loss: 0.1882 dan val_accuracy: 0.95"
      ]
    }
  ]
}