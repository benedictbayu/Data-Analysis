{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Learning_Fashion_MNIST_100 epochs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQnmXni6KLEe"
      },
      "source": [
        "## **Fashion MNIST Image Classification**\n",
        "\n",
        "**Benedictus Bayu Pramudhito**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iaj5E1KVZGVc"
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSNDaG1XZlv5",
        "outputId": "c63e6d96-ad9a-4db2-9c3a-fc911a9e6fb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "print('Train', X_train.shape, y_train.shape)\n",
        "print('Test', X_test.shape, y_test.shape)\n",
        "\n",
        "plt.imshow(X_train[50], cmap=plt.get_cmap('gray'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "Train (60000, 28, 28) (60000,)\n",
            "Test (10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f68c8856c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD9GBbHnaGJd",
        "outputId": "9a167614-e832-41f4-d7b4-27b2454e398e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEC0iZ-5zbbM"
      },
      "source": [
        "**Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuXz3KVvzY8p"
      },
      "source": [
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7to8BPhKzusL",
        "outputId": "8d275871-5311-4557-ad2a-749fc883d30e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTGUL8WGzxns",
        "outputId": "7dbc9f67-0654-4ab7-bad0-735ed273df2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]]],\n",
              "\n",
              "\n",
              "       [[[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]]],\n",
              "\n",
              "\n",
              "       [[[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]]],\n",
              "\n",
              "\n",
              "       [[[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]]],\n",
              "\n",
              "\n",
              "       [[[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]],\n",
              "\n",
              "        [[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         ...,\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QUIvzohz1V1"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Zz3c3zaKo3R",
        "outputId": "402be830-23cb-44b1-925b-b2d77e24e643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 0 0 ... 3 0 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvP5oNtZz7bc",
        "outputId": "deb770ac-807a-4720-91a2-fe6d98fa4588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "print(y_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 1.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2aHgm3R0CDM"
      },
      "source": [
        "#casting features\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOwabIZ-0iJB",
        "outputId": "ed40507e-227f-4d98-e873-e58372405622",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykF2DX9O0jKN"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGz8fBZf1kAw"
      },
      "source": [
        "**Multilayer Perceptron (Neural Network)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVs_ltY61jNR",
        "outputId": "0f95de63-87b3-46e1-e769-25c984d565e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "base_model = Sequential()\n",
        "\n",
        "base_model.add(Flatten(input_shape=(28, 28, 1)))\n",
        "base_model.add(Dense(128, activation='relu', kernel_initializer='he_uniform')) #Nilai 128 karena akan memakai 128 neuron\n",
        "base_model.add(Dense(10, activation='softmax')) #Nilai 10 karena ada 10 label\n",
        "\n",
        "opt = SGD(lr=0.01, momentum=0.9) #Optimizer Stochastic Gradient Descent, untuk mencari minima dari grafik fungsi loss\n",
        "\n",
        "base_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) #Loss function\n",
        "base_model.summary()\n",
        "\n",
        "history = base_model.fit(X_train, y_train, batch_size=32, validation_data=(X_test, y_test), epochs=100)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "   1/1875 [..............................] - ETA: 0s - loss: 2.3619 - accuracy: 0.2812WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0044s). Check your callbacks.\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5342 - accuracy: 0.8127 - val_loss: 0.4583 - val_accuracy: 0.8342\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3952 - accuracy: 0.8575 - val_loss: 0.3928 - val_accuracy: 0.8618\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3577 - accuracy: 0.8703 - val_loss: 0.3926 - val_accuracy: 0.8567\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3346 - accuracy: 0.8778 - val_loss: 0.3814 - val_accuracy: 0.8611\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3166 - accuracy: 0.8848 - val_loss: 0.3673 - val_accuracy: 0.8707\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3042 - accuracy: 0.8886 - val_loss: 0.3683 - val_accuracy: 0.8690\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2917 - accuracy: 0.8916 - val_loss: 0.3700 - val_accuracy: 0.8684\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2834 - accuracy: 0.8967 - val_loss: 0.3506 - val_accuracy: 0.8758\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2730 - accuracy: 0.8984 - val_loss: 0.3535 - val_accuracy: 0.8750\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2655 - accuracy: 0.9017 - val_loss: 0.3757 - val_accuracy: 0.8679\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2586 - accuracy: 0.9032 - val_loss: 0.3541 - val_accuracy: 0.8760\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2506 - accuracy: 0.9070 - val_loss: 0.3462 - val_accuracy: 0.8783\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2449 - accuracy: 0.9087 - val_loss: 0.3458 - val_accuracy: 0.8755\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2381 - accuracy: 0.9114 - val_loss: 0.3484 - val_accuracy: 0.8782\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2335 - accuracy: 0.9139 - val_loss: 0.3502 - val_accuracy: 0.8819\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2278 - accuracy: 0.9152 - val_loss: 0.3357 - val_accuracy: 0.8860\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2258 - accuracy: 0.9158 - val_loss: 0.3523 - val_accuracy: 0.8795\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2179 - accuracy: 0.9190 - val_loss: 0.3302 - val_accuracy: 0.8836\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2152 - accuracy: 0.9189 - val_loss: 0.3424 - val_accuracy: 0.8865\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2088 - accuracy: 0.9213 - val_loss: 0.3378 - val_accuracy: 0.8823\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2045 - accuracy: 0.9237 - val_loss: 0.3347 - val_accuracy: 0.8898\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2021 - accuracy: 0.9244 - val_loss: 0.3417 - val_accuracy: 0.8838\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1966 - accuracy: 0.9265 - val_loss: 0.3391 - val_accuracy: 0.8845\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1922 - accuracy: 0.9294 - val_loss: 0.3353 - val_accuracy: 0.8891\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1894 - accuracy: 0.9298 - val_loss: 0.3466 - val_accuracy: 0.8856\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1869 - accuracy: 0.9302 - val_loss: 0.3461 - val_accuracy: 0.8881\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1801 - accuracy: 0.9327 - val_loss: 0.3605 - val_accuracy: 0.8833\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1792 - accuracy: 0.9334 - val_loss: 0.3527 - val_accuracy: 0.8842\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1738 - accuracy: 0.9351 - val_loss: 0.3543 - val_accuracy: 0.8852\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1723 - accuracy: 0.9363 - val_loss: 0.3679 - val_accuracy: 0.8859\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1699 - accuracy: 0.9375 - val_loss: 0.3549 - val_accuracy: 0.8844\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1668 - accuracy: 0.9377 - val_loss: 0.3745 - val_accuracy: 0.8790\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1638 - accuracy: 0.9391 - val_loss: 0.3669 - val_accuracy: 0.8844\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1598 - accuracy: 0.9408 - val_loss: 0.3556 - val_accuracy: 0.8850\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1594 - accuracy: 0.9411 - val_loss: 0.3732 - val_accuracy: 0.8839\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1562 - accuracy: 0.9412 - val_loss: 0.3740 - val_accuracy: 0.8860\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1520 - accuracy: 0.9430 - val_loss: 0.3789 - val_accuracy: 0.8859\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1499 - accuracy: 0.9433 - val_loss: 0.3537 - val_accuracy: 0.8889\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1475 - accuracy: 0.9458 - val_loss: 0.3669 - val_accuracy: 0.8853\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1473 - accuracy: 0.9452 - val_loss: 0.3795 - val_accuracy: 0.8862\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1447 - accuracy: 0.9465 - val_loss: 0.3809 - val_accuracy: 0.8850\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1395 - accuracy: 0.9474 - val_loss: 0.3968 - val_accuracy: 0.8831\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1407 - accuracy: 0.9478 - val_loss: 0.3963 - val_accuracy: 0.8871\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1381 - accuracy: 0.9482 - val_loss: 0.3922 - val_accuracy: 0.8814\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1346 - accuracy: 0.9503 - val_loss: 0.3802 - val_accuracy: 0.8839\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1314 - accuracy: 0.9514 - val_loss: 0.4056 - val_accuracy: 0.8861\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1305 - accuracy: 0.9510 - val_loss: 0.4050 - val_accuracy: 0.8866\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1270 - accuracy: 0.9523 - val_loss: 0.4049 - val_accuracy: 0.8840\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1275 - accuracy: 0.9525 - val_loss: 0.4198 - val_accuracy: 0.8804\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1239 - accuracy: 0.9548 - val_loss: 0.4542 - val_accuracy: 0.8782\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1230 - accuracy: 0.9544 - val_loss: 0.4107 - val_accuracy: 0.8847\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1202 - accuracy: 0.9558 - val_loss: 0.4204 - val_accuracy: 0.8841\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1190 - accuracy: 0.9560 - val_loss: 0.4408 - val_accuracy: 0.8823\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1186 - accuracy: 0.9566 - val_loss: 0.4304 - val_accuracy: 0.8838\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1145 - accuracy: 0.9576 - val_loss: 0.4369 - val_accuracy: 0.8824\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1128 - accuracy: 0.9586 - val_loss: 0.4428 - val_accuracy: 0.8820\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1151 - accuracy: 0.9575 - val_loss: 0.4151 - val_accuracy: 0.8868\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1099 - accuracy: 0.9593 - val_loss: 0.4252 - val_accuracy: 0.8886\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1124 - accuracy: 0.9580 - val_loss: 0.4750 - val_accuracy: 0.8815\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1082 - accuracy: 0.9586 - val_loss: 0.4261 - val_accuracy: 0.8881\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1081 - accuracy: 0.9605 - val_loss: 0.4396 - val_accuracy: 0.8833\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1046 - accuracy: 0.9609 - val_loss: 0.4685 - val_accuracy: 0.8807\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1029 - accuracy: 0.9617 - val_loss: 0.4720 - val_accuracy: 0.8799\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1026 - accuracy: 0.9620 - val_loss: 0.4424 - val_accuracy: 0.8859\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0988 - accuracy: 0.9639 - val_loss: 0.4547 - val_accuracy: 0.8876\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0996 - accuracy: 0.9632 - val_loss: 0.4864 - val_accuracy: 0.8812\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0954 - accuracy: 0.9646 - val_loss: 0.4730 - val_accuracy: 0.8831\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0961 - accuracy: 0.9650 - val_loss: 0.4561 - val_accuracy: 0.8850\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0933 - accuracy: 0.9658 - val_loss: 0.4651 - val_accuracy: 0.8808\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0955 - accuracy: 0.9649 - val_loss: 0.4773 - val_accuracy: 0.8822\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0933 - accuracy: 0.9658 - val_loss: 0.4804 - val_accuracy: 0.8838\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0903 - accuracy: 0.9671 - val_loss: 0.4848 - val_accuracy: 0.8833\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0904 - accuracy: 0.9665 - val_loss: 0.4790 - val_accuracy: 0.8830\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0859 - accuracy: 0.9690 - val_loss: 0.4886 - val_accuracy: 0.8828\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0876 - accuracy: 0.9674 - val_loss: 0.4860 - val_accuracy: 0.8835\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0881 - accuracy: 0.9680 - val_loss: 0.4960 - val_accuracy: 0.8832\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0879 - accuracy: 0.9682 - val_loss: 0.5018 - val_accuracy: 0.8817\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0846 - accuracy: 0.9686 - val_loss: 0.5010 - val_accuracy: 0.8837\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0842 - accuracy: 0.9684 - val_loss: 0.4855 - val_accuracy: 0.8847\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0809 - accuracy: 0.9701 - val_loss: 0.4972 - val_accuracy: 0.8849\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0808 - accuracy: 0.9704 - val_loss: 0.4978 - val_accuracy: 0.8839\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0810 - accuracy: 0.9706 - val_loss: 0.5029 - val_accuracy: 0.8807\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0789 - accuracy: 0.9710 - val_loss: 0.5058 - val_accuracy: 0.8811\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0804 - accuracy: 0.9705 - val_loss: 0.5130 - val_accuracy: 0.8836\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0759 - accuracy: 0.9722 - val_loss: 0.5255 - val_accuracy: 0.8856\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0759 - accuracy: 0.9726 - val_loss: 0.5333 - val_accuracy: 0.8823\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0757 - accuracy: 0.9717 - val_loss: 0.5121 - val_accuracy: 0.8848\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0738 - accuracy: 0.9729 - val_loss: 0.5544 - val_accuracy: 0.8840\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0712 - accuracy: 0.9741 - val_loss: 0.5361 - val_accuracy: 0.8837\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0726 - accuracy: 0.9737 - val_loss: 0.5467 - val_accuracy: 0.8854\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0699 - accuracy: 0.9746 - val_loss: 0.5343 - val_accuracy: 0.8821\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0687 - accuracy: 0.9747 - val_loss: 0.5617 - val_accuracy: 0.8829\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0721 - accuracy: 0.9733 - val_loss: 0.5653 - val_accuracy: 0.8797\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0672 - accuracy: 0.9757 - val_loss: 0.5396 - val_accuracy: 0.8860\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0710 - accuracy: 0.9734 - val_loss: 0.5890 - val_accuracy: 0.8812\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0678 - accuracy: 0.9756 - val_loss: 0.5519 - val_accuracy: 0.8861\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0660 - accuracy: 0.9764 - val_loss: 0.5404 - val_accuracy: 0.8849\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0640 - accuracy: 0.9763 - val_loss: 0.5998 - val_accuracy: 0.8795\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0660 - accuracy: 0.9757 - val_loss: 0.5549 - val_accuracy: 0.8832\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0652 - accuracy: 0.9762 - val_loss: 0.6115 - val_accuracy: 0.8792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vVC3hGi6bUW"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX0trJah75Ns",
        "outputId": "b7aff992-6f81-4607-ff9c-a423f6b87140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "history_df = pd.DataFrame(history.history)\n",
        "history_df['epoch'] = history.epoch\n",
        "history_df"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.534192</td>\n",
              "      <td>0.812683</td>\n",
              "      <td>0.458269</td>\n",
              "      <td>0.8342</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.395208</td>\n",
              "      <td>0.857517</td>\n",
              "      <td>0.392773</td>\n",
              "      <td>0.8618</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.357730</td>\n",
              "      <td>0.870317</td>\n",
              "      <td>0.392650</td>\n",
              "      <td>0.8567</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.334607</td>\n",
              "      <td>0.877817</td>\n",
              "      <td>0.381364</td>\n",
              "      <td>0.8611</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.316621</td>\n",
              "      <td>0.884750</td>\n",
              "      <td>0.367271</td>\n",
              "      <td>0.8707</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.067756</td>\n",
              "      <td>0.975567</td>\n",
              "      <td>0.551906</td>\n",
              "      <td>0.8861</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.065975</td>\n",
              "      <td>0.976400</td>\n",
              "      <td>0.540431</td>\n",
              "      <td>0.8849</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.064012</td>\n",
              "      <td>0.976283</td>\n",
              "      <td>0.599824</td>\n",
              "      <td>0.8795</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.065969</td>\n",
              "      <td>0.975683</td>\n",
              "      <td>0.554895</td>\n",
              "      <td>0.8832</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.065188</td>\n",
              "      <td>0.976200</td>\n",
              "      <td>0.611478</td>\n",
              "      <td>0.8792</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy  epoch\n",
              "0   0.534192  0.812683  0.458269        0.8342      0\n",
              "1   0.395208  0.857517  0.392773        0.8618      1\n",
              "2   0.357730  0.870317  0.392650        0.8567      2\n",
              "3   0.334607  0.877817  0.381364        0.8611      3\n",
              "4   0.316621  0.884750  0.367271        0.8707      4\n",
              "..       ...       ...       ...           ...    ...\n",
              "95  0.067756  0.975567  0.551906        0.8861     95\n",
              "96  0.065975  0.976400  0.540431        0.8849     96\n",
              "97  0.064012  0.976283  0.599824        0.8795     97\n",
              "98  0.065969  0.975683  0.554895        0.8832     98\n",
              "99  0.065188  0.976200  0.611478        0.8792     99\n",
              "\n",
              "[100 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6o8H0OV8Mq7",
        "outputId": "1aae888b-7b36-4dcc-f3ec-eb36cd78ae6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_loss(history) #epoch vs loss graph"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Czu4Pg5e8Z-Y"
      },
      "source": [
        "**Kita ingin mencari loss yang terendah, loss ini terhadap val_lossnya**\n",
        "\n",
        "Berdasarkan grafik epoch terhadap loss pada model multilayer perceptron, terlihat bahwa garis lossnya terus mengalami penurunan dengan 100 epoch, tetapi grafik val_loss nya cenderung mengalami peningkatan setelah sekitar 18 epoch. Oleh karena itu, nilai val_loss terendah diperoleh saat epochnya sekitar 18-19, tepat sebelum val_loss nya mengalami peningkatan dimana saat epoch 18 diperoleh val_loss: 0.3302 dan val_accuracy: 0.8836"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ioyToNp8p_j"
      },
      "source": [
        "#loss, accuracy = base_model.evaluate(X_test, y_test, verbose=2)\n",
        "\n",
        "#print('Test Accuracy:', round(accuracy, 3))\n",
        "#print('Test Loss:', round(loss, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf85Cg6X9C81"
      },
      "source": [
        "**Convolutional Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OPhiK1A817X",
        "outputId": "6ab152ba-d287-4508-d73a-dab63b33431b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1))) #Convolution dengan 32 filter, masing-masing dengan kernel 3x3\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Flatten())\n",
        "\n",
        "#Fully connected layer\n",
        "model.add(Dense(100, activation='relu', kernel_initializer='he_uniform')) #Memakai 100 neuron\n",
        "model.add(Dense(10, activation='softmax')) #Terdapat 10 label pada dataset\n",
        "\n",
        "opt = SGD(lr=0.01, momentum=0.9) #optimizer Stochastic Gradient Descent\n",
        "\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "history_cnn = model.fit(X_train, y_train, batch_size=32, validation_data=(X_test, y_test), epochs=100)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 5408)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               540900    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 542,230\n",
            "Trainable params: 542,230\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4289 - accuracy: 0.8451 - val_loss: 0.3479 - val_accuracy: 0.8757\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2919 - accuracy: 0.8925 - val_loss: 0.3211 - val_accuracy: 0.8819\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2465 - accuracy: 0.9097 - val_loss: 0.2928 - val_accuracy: 0.8940\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2183 - accuracy: 0.9184 - val_loss: 0.2905 - val_accuracy: 0.8965\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1962 - accuracy: 0.9273 - val_loss: 0.2651 - val_accuracy: 0.9079\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1780 - accuracy: 0.9331 - val_loss: 0.2894 - val_accuracy: 0.8979\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1603 - accuracy: 0.9411 - val_loss: 0.2723 - val_accuracy: 0.9117\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1467 - accuracy: 0.9469 - val_loss: 0.2944 - val_accuracy: 0.9020\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1305 - accuracy: 0.9530 - val_loss: 0.2852 - val_accuracy: 0.9027\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1172 - accuracy: 0.9565 - val_loss: 0.2902 - val_accuracy: 0.9037\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1083 - accuracy: 0.9600 - val_loss: 0.2979 - val_accuracy: 0.9062\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0940 - accuracy: 0.9662 - val_loss: 0.3067 - val_accuracy: 0.9082\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0864 - accuracy: 0.9686 - val_loss: 0.3015 - val_accuracy: 0.9117\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0763 - accuracy: 0.9722 - val_loss: 0.3175 - val_accuracy: 0.9111\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0681 - accuracy: 0.9761 - val_loss: 0.3290 - val_accuracy: 0.9065\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0655 - accuracy: 0.9758 - val_loss: 0.3463 - val_accuracy: 0.9084\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0550 - accuracy: 0.9800 - val_loss: 0.3702 - val_accuracy: 0.9077\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0464 - accuracy: 0.9843 - val_loss: 0.4006 - val_accuracy: 0.9043\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0426 - accuracy: 0.9855 - val_loss: 0.3865 - val_accuracy: 0.9069\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0387 - accuracy: 0.9867 - val_loss: 0.4330 - val_accuracy: 0.9040\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0354 - accuracy: 0.9877 - val_loss: 0.4265 - val_accuracy: 0.9086\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0310 - accuracy: 0.9891 - val_loss: 0.4558 - val_accuracy: 0.9019\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0266 - accuracy: 0.9910 - val_loss: 0.4392 - val_accuracy: 0.9062\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0236 - accuracy: 0.9922 - val_loss: 0.4726 - val_accuracy: 0.9041\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0232 - accuracy: 0.9923 - val_loss: 0.4718 - val_accuracy: 0.9103\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.4825 - val_accuracy: 0.9101\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.5113 - val_accuracy: 0.9109\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0124 - accuracy: 0.9962 - val_loss: 0.4997 - val_accuracy: 0.9093\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0163 - accuracy: 0.9950 - val_loss: 0.5315 - val_accuracy: 0.9104\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.5346 - val_accuracy: 0.9095\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.5514 - val_accuracy: 0.9078\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 0.5745 - val_accuracy: 0.9086\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.5807 - val_accuracy: 0.9068\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.5653 - val_accuracy: 0.9129\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.5736 - val_accuracy: 0.9134\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.5859 - val_accuracy: 0.9120\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 8.1896e-04 - accuracy: 1.0000 - val_loss: 0.5894 - val_accuracy: 0.9129\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 6.1818e-04 - accuracy: 1.0000 - val_loss: 0.5943 - val_accuracy: 0.9142\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 5.4469e-04 - accuracy: 1.0000 - val_loss: 0.6014 - val_accuracy: 0.9138\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 4.9260e-04 - accuracy: 1.0000 - val_loss: 0.6100 - val_accuracy: 0.9139\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 4.6180e-04 - accuracy: 1.0000 - val_loss: 0.6132 - val_accuracy: 0.9135\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 4.2199e-04 - accuracy: 1.0000 - val_loss: 0.6185 - val_accuracy: 0.9137\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 3.9673e-04 - accuracy: 1.0000 - val_loss: 0.6181 - val_accuracy: 0.9137\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 3.7075e-04 - accuracy: 1.0000 - val_loss: 0.6216 - val_accuracy: 0.9134\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 3.5371e-04 - accuracy: 1.0000 - val_loss: 0.6273 - val_accuracy: 0.9129\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 3.3666e-04 - accuracy: 1.0000 - val_loss: 0.6309 - val_accuracy: 0.9133\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 3.1942e-04 - accuracy: 1.0000 - val_loss: 0.6334 - val_accuracy: 0.9138\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 3.0549e-04 - accuracy: 1.0000 - val_loss: 0.6357 - val_accuracy: 0.9133\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.9242e-04 - accuracy: 1.0000 - val_loss: 0.6391 - val_accuracy: 0.9135\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.8059e-04 - accuracy: 1.0000 - val_loss: 0.6418 - val_accuracy: 0.9126\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.6852e-04 - accuracy: 1.0000 - val_loss: 0.6463 - val_accuracy: 0.9135\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.5909e-04 - accuracy: 1.0000 - val_loss: 0.6475 - val_accuracy: 0.9130\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.4955e-04 - accuracy: 1.0000 - val_loss: 0.6498 - val_accuracy: 0.9131\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.4164e-04 - accuracy: 1.0000 - val_loss: 0.6532 - val_accuracy: 0.9130\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.3212e-04 - accuracy: 1.0000 - val_loss: 0.6560 - val_accuracy: 0.9134\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.2465e-04 - accuracy: 1.0000 - val_loss: 0.6572 - val_accuracy: 0.9130\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.1825e-04 - accuracy: 1.0000 - val_loss: 0.6601 - val_accuracy: 0.9132\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.1265e-04 - accuracy: 1.0000 - val_loss: 0.6606 - val_accuracy: 0.9124\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.0451e-04 - accuracy: 1.0000 - val_loss: 0.6639 - val_accuracy: 0.9133\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.9924e-04 - accuracy: 1.0000 - val_loss: 0.6654 - val_accuracy: 0.9128\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.9286e-04 - accuracy: 1.0000 - val_loss: 0.6672 - val_accuracy: 0.9132\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.8833e-04 - accuracy: 1.0000 - val_loss: 0.6702 - val_accuracy: 0.9129\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.8284e-04 - accuracy: 1.0000 - val_loss: 0.6723 - val_accuracy: 0.9135\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.7811e-04 - accuracy: 1.0000 - val_loss: 0.6733 - val_accuracy: 0.9133\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.7407e-04 - accuracy: 1.0000 - val_loss: 0.6747 - val_accuracy: 0.9123\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.6959e-04 - accuracy: 1.0000 - val_loss: 0.6769 - val_accuracy: 0.9123\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.6645e-04 - accuracy: 1.0000 - val_loss: 0.6779 - val_accuracy: 0.9129\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.6158e-04 - accuracy: 1.0000 - val_loss: 0.6804 - val_accuracy: 0.9127\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.5821e-04 - accuracy: 1.0000 - val_loss: 0.6810 - val_accuracy: 0.9125\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.5440e-04 - accuracy: 1.0000 - val_loss: 0.6835 - val_accuracy: 0.9132\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.5133e-04 - accuracy: 1.0000 - val_loss: 0.6839 - val_accuracy: 0.9124\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4767e-04 - accuracy: 1.0000 - val_loss: 0.6877 - val_accuracy: 0.9127\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4510e-04 - accuracy: 1.0000 - val_loss: 0.6886 - val_accuracy: 0.9126\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4200e-04 - accuracy: 1.0000 - val_loss: 0.6886 - val_accuracy: 0.9127\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.3905e-04 - accuracy: 1.0000 - val_loss: 0.6909 - val_accuracy: 0.9127\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.3612e-04 - accuracy: 1.0000 - val_loss: 0.6921 - val_accuracy: 0.9123\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.3329e-04 - accuracy: 1.0000 - val_loss: 0.6952 - val_accuracy: 0.9125\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.3088e-04 - accuracy: 1.0000 - val_loss: 0.6969 - val_accuracy: 0.9129\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.2856e-04 - accuracy: 1.0000 - val_loss: 0.6961 - val_accuracy: 0.9125\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.2617e-04 - accuracy: 1.0000 - val_loss: 0.6985 - val_accuracy: 0.9122\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.2348e-04 - accuracy: 1.0000 - val_loss: 0.6995 - val_accuracy: 0.9125\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.2127e-04 - accuracy: 1.0000 - val_loss: 0.7006 - val_accuracy: 0.9121\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.1981e-04 - accuracy: 1.0000 - val_loss: 0.7018 - val_accuracy: 0.9122\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.1749e-04 - accuracy: 1.0000 - val_loss: 0.7037 - val_accuracy: 0.9123\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.1513e-04 - accuracy: 1.0000 - val_loss: 0.7059 - val_accuracy: 0.9122\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.1362e-04 - accuracy: 1.0000 - val_loss: 0.7053 - val_accuracy: 0.9121\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.1147e-04 - accuracy: 1.0000 - val_loss: 0.7068 - val_accuracy: 0.9128\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.1007e-04 - accuracy: 1.0000 - val_loss: 0.7078 - val_accuracy: 0.9120\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.0781e-04 - accuracy: 1.0000 - val_loss: 0.7098 - val_accuracy: 0.9121\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.0650e-04 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.9122\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.0439e-04 - accuracy: 1.0000 - val_loss: 0.7121 - val_accuracy: 0.9121\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.0313e-04 - accuracy: 1.0000 - val_loss: 0.7131 - val_accuracy: 0.9119\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.0160e-04 - accuracy: 1.0000 - val_loss: 0.7149 - val_accuracy: 0.9125\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 9.9795e-05 - accuracy: 1.0000 - val_loss: 0.7148 - val_accuracy: 0.9117\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 9.8478e-05 - accuracy: 1.0000 - val_loss: 0.7158 - val_accuracy: 0.9117\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 9.7133e-05 - accuracy: 1.0000 - val_loss: 0.7177 - val_accuracy: 0.9120\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 9.5714e-05 - accuracy: 1.0000 - val_loss: 0.7186 - val_accuracy: 0.9116\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 9.4486e-05 - accuracy: 1.0000 - val_loss: 0.7196 - val_accuracy: 0.9121\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 9.3020e-05 - accuracy: 1.0000 - val_loss: 0.7204 - val_accuracy: 0.9122\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 9.1548e-05 - accuracy: 1.0000 - val_loss: 0.7210 - val_accuracy: 0.9122\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHDzhgQw_OXt",
        "outputId": "5a73038b-033f-4eb2-b3ff-9a160591aca3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "history_df_cnn = pd.DataFrame(history_cnn.history)\n",
        "history_df_cnn['epoch'] = history_cnn.epoch\n",
        "history_df_cnn"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.428864</td>\n",
              "      <td>0.845133</td>\n",
              "      <td>0.347906</td>\n",
              "      <td>0.8757</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.291934</td>\n",
              "      <td>0.892517</td>\n",
              "      <td>0.321149</td>\n",
              "      <td>0.8819</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.246528</td>\n",
              "      <td>0.909650</td>\n",
              "      <td>0.292845</td>\n",
              "      <td>0.8940</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.218327</td>\n",
              "      <td>0.918400</td>\n",
              "      <td>0.290489</td>\n",
              "      <td>0.8965</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.196180</td>\n",
              "      <td>0.927350</td>\n",
              "      <td>0.265076</td>\n",
              "      <td>0.9079</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.000097</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.717655</td>\n",
              "      <td>0.9120</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.000096</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.718555</td>\n",
              "      <td>0.9116</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.000094</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.719564</td>\n",
              "      <td>0.9121</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.000093</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.720375</td>\n",
              "      <td>0.9122</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.000092</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.720967</td>\n",
              "      <td>0.9122</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy  epoch\n",
              "0   0.428864  0.845133  0.347906        0.8757      0\n",
              "1   0.291934  0.892517  0.321149        0.8819      1\n",
              "2   0.246528  0.909650  0.292845        0.8940      2\n",
              "3   0.218327  0.918400  0.290489        0.8965      3\n",
              "4   0.196180  0.927350  0.265076        0.9079      4\n",
              "..       ...       ...       ...           ...    ...\n",
              "95  0.000097  1.000000  0.717655        0.9120     95\n",
              "96  0.000096  1.000000  0.718555        0.9116     96\n",
              "97  0.000094  1.000000  0.719564        0.9121     97\n",
              "98  0.000093  1.000000  0.720375        0.9122     98\n",
              "99  0.000092  1.000000  0.720967        0.9122     99\n",
              "\n",
              "[100 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8tMEFryAGb8",
        "outputId": "549a2aff-e69d-4921-ab4f-9be8aeeedab0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_loss(history_cnn)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVtCtIUaGKkk"
      },
      "source": [
        "**Kita ingin mencari loss yang terendah, loss ini terhadap val_lossnya**\n",
        "\n",
        "Berdasarkan grafik epoch terhadap loss pada model multilayer perceptron, terlihat bahwa garis lossnya telah mencapai titik terendahnya dengan 100 epoch, tetapi grafik val_loss nya cenderung mengalami peningkatan setelah sekitar 5 epoch. Oleh karena itu, nilai val_loss terendah diperoleh saat epochnya sekitar 5-6, tepat sebelum val_loss nya mengalami peningkatan dimana saat epoch 5 diperoleh val_loss: 0.2651 dan val_accuracy: 0.9079"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_ZCyxkoHzrj"
      },
      "source": [
        "#loss, accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
        "\n",
        "#print('Test Accuracy:', round(accuracy, 3))\n",
        "#print('Test Loss:', round(loss, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-T2SEzdBgyw"
      },
      "source": [
        "**Convolutional Neural Network with Deeper Layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCd95ZOiAN1q"
      },
      "source": [
        "model = Sequential([Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)),\n",
        "                   MaxPooling2D((2,2)),\n",
        "                   Conv2D(64, (3,3), activation='relu', kernel_initializer='he_uniform'),\n",
        "                   MaxPooling2D((2,2)),\n",
        "                   Flatten(),\n",
        "                   Dense(100, activation='relu', kernel_initializer='he_uniform'),\n",
        "                   Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkNsG4slDMmL"
      },
      "source": [
        "model.compile(optimizer=SGD(lr=0.01, momentum=0.9), \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCUvbRv4Dx49",
        "outputId": "ca0145f1-8965-479f-d52a-4fb92184eeb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()\n",
        "\n",
        "history_cnn_1 = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=32,\n",
        "    validation_data = (X_test, y_test),\n",
        "    epochs=100\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 100)               160100    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 179,926\n",
            "Trainable params: 179,926\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4560 - accuracy: 0.8335 - val_loss: 0.3637 - val_accuracy: 0.8686\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3060 - accuracy: 0.8881 - val_loss: 0.3355 - val_accuracy: 0.8785\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2629 - accuracy: 0.9033 - val_loss: 0.2991 - val_accuracy: 0.8876\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2340 - accuracy: 0.9131 - val_loss: 0.2981 - val_accuracy: 0.8950\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2139 - accuracy: 0.9204 - val_loss: 0.2657 - val_accuracy: 0.9031\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1944 - accuracy: 0.9271 - val_loss: 0.2820 - val_accuracy: 0.9007\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1787 - accuracy: 0.9323 - val_loss: 0.2678 - val_accuracy: 0.9036\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1627 - accuracy: 0.9387 - val_loss: 0.2749 - val_accuracy: 0.9051\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1498 - accuracy: 0.9430 - val_loss: 0.2712 - val_accuracy: 0.9111\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1372 - accuracy: 0.9482 - val_loss: 0.2942 - val_accuracy: 0.9016\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1256 - accuracy: 0.9524 - val_loss: 0.3183 - val_accuracy: 0.8964\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1143 - accuracy: 0.9571 - val_loss: 0.2898 - val_accuracy: 0.9092\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1017 - accuracy: 0.9616 - val_loss: 0.3644 - val_accuracy: 0.8952\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0940 - accuracy: 0.9638 - val_loss: 0.3515 - val_accuracy: 0.8922\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0874 - accuracy: 0.9667 - val_loss: 0.3535 - val_accuracy: 0.9094\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0761 - accuracy: 0.9706 - val_loss: 0.3546 - val_accuracy: 0.9062\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0697 - accuracy: 0.9733 - val_loss: 0.3705 - val_accuracy: 0.9100\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0625 - accuracy: 0.9762 - val_loss: 0.3949 - val_accuracy: 0.9095\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0612 - accuracy: 0.9766 - val_loss: 0.3758 - val_accuracy: 0.9091\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0596 - accuracy: 0.9772 - val_loss: 0.4381 - val_accuracy: 0.9067\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0536 - accuracy: 0.9800 - val_loss: 0.4384 - val_accuracy: 0.9072\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0478 - accuracy: 0.9826 - val_loss: 0.4481 - val_accuracy: 0.9100\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0418 - accuracy: 0.9847 - val_loss: 0.4609 - val_accuracy: 0.9024\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0393 - accuracy: 0.9854 - val_loss: 0.4826 - val_accuracy: 0.9094\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0373 - accuracy: 0.9867 - val_loss: 0.4765 - val_accuracy: 0.9028\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0389 - accuracy: 0.9861 - val_loss: 0.4959 - val_accuracy: 0.9090\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0361 - accuracy: 0.9869 - val_loss: 0.5368 - val_accuracy: 0.9041\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0295 - accuracy: 0.9886 - val_loss: 0.5599 - val_accuracy: 0.9054\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0280 - accuracy: 0.9898 - val_loss: 0.6434 - val_accuracy: 0.9053\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0300 - accuracy: 0.9890 - val_loss: 0.5571 - val_accuracy: 0.9072\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0286 - accuracy: 0.9896 - val_loss: 0.6073 - val_accuracy: 0.9019\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0316 - accuracy: 0.9884 - val_loss: 0.6224 - val_accuracy: 0.9039\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0319 - accuracy: 0.9890 - val_loss: 0.6718 - val_accuracy: 0.9037\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0347 - accuracy: 0.9881 - val_loss: 0.6422 - val_accuracy: 0.9054\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0327 - accuracy: 0.9884 - val_loss: 0.5876 - val_accuracy: 0.9046\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0281 - accuracy: 0.9899 - val_loss: 0.6271 - val_accuracy: 0.9069\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0305 - accuracy: 0.9895 - val_loss: 0.6893 - val_accuracy: 0.8980\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0293 - accuracy: 0.9898 - val_loss: 0.6275 - val_accuracy: 0.9048\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0201 - accuracy: 0.9931 - val_loss: 0.6664 - val_accuracy: 0.9060\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0225 - accuracy: 0.9922 - val_loss: 0.6997 - val_accuracy: 0.9062\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0235 - accuracy: 0.9915 - val_loss: 0.7451 - val_accuracy: 0.9106\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.7082 - val_accuracy: 0.9121\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.7355 - val_accuracy: 0.9134\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.7483 - val_accuracy: 0.9149\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 4.7195e-04 - accuracy: 1.0000 - val_loss: 0.7625 - val_accuracy: 0.9143\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.0351e-04 - accuracy: 1.0000 - val_loss: 0.7779 - val_accuracy: 0.9162\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 1.5574e-04 - accuracy: 1.0000 - val_loss: 0.7898 - val_accuracy: 0.9165\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 1.3321e-04 - accuracy: 1.0000 - val_loss: 0.7974 - val_accuracy: 0.9161\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.1694e-04 - accuracy: 1.0000 - val_loss: 0.8051 - val_accuracy: 0.9167\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.0502e-04 - accuracy: 1.0000 - val_loss: 0.8108 - val_accuracy: 0.9160\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 9.5636e-05 - accuracy: 1.0000 - val_loss: 0.8155 - val_accuracy: 0.9159\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 8.8598e-05 - accuracy: 1.0000 - val_loss: 0.8212 - val_accuracy: 0.9157\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 8.2332e-05 - accuracy: 1.0000 - val_loss: 0.8245 - val_accuracy: 0.9160\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 7.7319e-05 - accuracy: 1.0000 - val_loss: 0.8305 - val_accuracy: 0.9156\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 7.2274e-05 - accuracy: 1.0000 - val_loss: 0.8338 - val_accuracy: 0.9162\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 6.8375e-05 - accuracy: 1.0000 - val_loss: 0.8380 - val_accuracy: 0.9162\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 6.4800e-05 - accuracy: 1.0000 - val_loss: 0.8419 - val_accuracy: 0.9164\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 6.1518e-05 - accuracy: 1.0000 - val_loss: 0.8453 - val_accuracy: 0.9163\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 5.8882e-05 - accuracy: 1.0000 - val_loss: 0.8479 - val_accuracy: 0.9164\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 5.6342e-05 - accuracy: 1.0000 - val_loss: 0.8506 - val_accuracy: 0.9164\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 5.4044e-05 - accuracy: 1.0000 - val_loss: 0.8538 - val_accuracy: 0.9167\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 5.2001e-05 - accuracy: 1.0000 - val_loss: 0.8560 - val_accuracy: 0.9168\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 4.9914e-05 - accuracy: 1.0000 - val_loss: 0.8589 - val_accuracy: 0.9169\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 4.8120e-05 - accuracy: 1.0000 - val_loss: 0.8617 - val_accuracy: 0.9168\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.6598e-05 - accuracy: 1.0000 - val_loss: 0.8639 - val_accuracy: 0.9168\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.5051e-05 - accuracy: 1.0000 - val_loss: 0.8667 - val_accuracy: 0.9169\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.3578e-05 - accuracy: 1.0000 - val_loss: 0.8681 - val_accuracy: 0.9168\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.2237e-05 - accuracy: 1.0000 - val_loss: 0.8708 - val_accuracy: 0.9168\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 4.1013e-05 - accuracy: 1.0000 - val_loss: 0.8721 - val_accuracy: 0.9170\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.9854e-05 - accuracy: 1.0000 - val_loss: 0.8742 - val_accuracy: 0.9170\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 3.8708e-05 - accuracy: 1.0000 - val_loss: 0.8765 - val_accuracy: 0.9168\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.7691e-05 - accuracy: 1.0000 - val_loss: 0.8786 - val_accuracy: 0.9168\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.6758e-05 - accuracy: 1.0000 - val_loss: 0.8799 - val_accuracy: 0.9169\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.5819e-05 - accuracy: 1.0000 - val_loss: 0.8818 - val_accuracy: 0.9168\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 3.4941e-05 - accuracy: 1.0000 - val_loss: 0.8834 - val_accuracy: 0.9171\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.4083e-05 - accuracy: 1.0000 - val_loss: 0.8850 - val_accuracy: 0.9171\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.3279e-05 - accuracy: 1.0000 - val_loss: 0.8864 - val_accuracy: 0.9170\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.2551e-05 - accuracy: 1.0000 - val_loss: 0.8882 - val_accuracy: 0.9171\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.1770e-05 - accuracy: 1.0000 - val_loss: 0.8898 - val_accuracy: 0.9172\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 3.1105e-05 - accuracy: 1.0000 - val_loss: 0.8915 - val_accuracy: 0.9171\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.0472e-05 - accuracy: 1.0000 - val_loss: 0.8931 - val_accuracy: 0.9169\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.9822e-05 - accuracy: 1.0000 - val_loss: 0.8944 - val_accuracy: 0.9171\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.9273e-05 - accuracy: 1.0000 - val_loss: 0.8961 - val_accuracy: 0.9169\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 2.8694e-05 - accuracy: 1.0000 - val_loss: 0.8973 - val_accuracy: 0.9172\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.8151e-05 - accuracy: 1.0000 - val_loss: 0.8986 - val_accuracy: 0.9168\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.7557e-05 - accuracy: 1.0000 - val_loss: 0.8993 - val_accuracy: 0.9175\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 2.7104e-05 - accuracy: 1.0000 - val_loss: 0.9011 - val_accuracy: 0.9170\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.6590e-05 - accuracy: 1.0000 - val_loss: 0.9024 - val_accuracy: 0.9168\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 2.6053e-05 - accuracy: 1.0000 - val_loss: 0.9042 - val_accuracy: 0.9169\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.5694e-05 - accuracy: 1.0000 - val_loss: 0.9045 - val_accuracy: 0.9170\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 2.5242e-05 - accuracy: 1.0000 - val_loss: 0.9062 - val_accuracy: 0.9166\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.4813e-05 - accuracy: 1.0000 - val_loss: 0.9069 - val_accuracy: 0.9171\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.4412e-05 - accuracy: 1.0000 - val_loss: 0.9080 - val_accuracy: 0.9170\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.4019e-05 - accuracy: 1.0000 - val_loss: 0.9089 - val_accuracy: 0.9172\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 2.3641e-05 - accuracy: 1.0000 - val_loss: 0.9107 - val_accuracy: 0.9168\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3239e-05 - accuracy: 1.0000 - val_loss: 0.9118 - val_accuracy: 0.9169\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2926e-05 - accuracy: 1.0000 - val_loss: 0.9123 - val_accuracy: 0.9171\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 2.2563e-05 - accuracy: 1.0000 - val_loss: 0.9134 - val_accuracy: 0.9171\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2224e-05 - accuracy: 1.0000 - val_loss: 0.9143 - val_accuracy: 0.9170\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.1889e-05 - accuracy: 1.0000 - val_loss: 0.9155 - val_accuracy: 0.9170\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Guhlg9cfEBfe",
        "outputId": "f70f4fd6-28c5-49b1-808e-07d919d6c4cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "history_df_cnn1 = pd.DataFrame(history_cnn_1.history)\n",
        "history_df_cnn1['epoch'] = history_cnn_1.epoch\n",
        "history_df_cnn1"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.455989</td>\n",
              "      <td>0.833467</td>\n",
              "      <td>0.363715</td>\n",
              "      <td>0.8686</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.305962</td>\n",
              "      <td>0.888050</td>\n",
              "      <td>0.335452</td>\n",
              "      <td>0.8785</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.262866</td>\n",
              "      <td>0.903300</td>\n",
              "      <td>0.299051</td>\n",
              "      <td>0.8876</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.233967</td>\n",
              "      <td>0.913117</td>\n",
              "      <td>0.298056</td>\n",
              "      <td>0.8950</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.213919</td>\n",
              "      <td>0.920400</td>\n",
              "      <td>0.265717</td>\n",
              "      <td>0.9031</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.000023</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.911845</td>\n",
              "      <td>0.9169</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.000023</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.912274</td>\n",
              "      <td>0.9171</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.000023</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.913438</td>\n",
              "      <td>0.9171</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.000022</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.914335</td>\n",
              "      <td>0.9170</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.000022</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.915541</td>\n",
              "      <td>0.9170</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy  epoch\n",
              "0   0.455989  0.833467  0.363715        0.8686      0\n",
              "1   0.305962  0.888050  0.335452        0.8785      1\n",
              "2   0.262866  0.903300  0.299051        0.8876      2\n",
              "3   0.233967  0.913117  0.298056        0.8950      3\n",
              "4   0.213919  0.920400  0.265717        0.9031      4\n",
              "..       ...       ...       ...           ...    ...\n",
              "95  0.000023  1.000000  0.911845        0.9169     95\n",
              "96  0.000023  1.000000  0.912274        0.9171     96\n",
              "97  0.000023  1.000000  0.913438        0.9171     97\n",
              "98  0.000022  1.000000  0.914335        0.9170     98\n",
              "99  0.000022  1.000000  0.915541        0.9170     99\n",
              "\n",
              "[100 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2chrU8JFz6G",
        "outputId": "17d3e422-568d-4d02-9c5d-165ec7b96b35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "  plot_loss(history_cnn_1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFN9DOkAJIUW"
      },
      "source": [
        "**Kita ingin mencari loss yang terendah, loss ini terhadap val_lossnya**\n",
        "\n",
        "Berdasarkan grafik epoch terhadap loss pada model multilayer perceptron, terlihat bahwa garis lossnya telah mencapai titik terendahnya dengan 100 epoch, tetapi grafik val_loss nya cenderung mengalami peningkatan setelah sekitar 10 epoch. Oleh karena itu, nilai val_loss terendah diperoleh saat epochnya sekitar 10-11, tepat sebelum val_loss nya mengalami peningkatan dimana saat epoch 10 diperoleh val_loss: 0.2942 dan val_accuracy: 0.9016"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBlvYE1RF8oO"
      },
      "source": [
        "#loss, accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
        "\n",
        "#print('Test Accuracy:', round(accuracy, 3))\n",
        "#print('Test Loss:', round(loss, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COEpjoa6Jg2-"
      },
      "source": [
        "Nilai akurasi pada model CNN single layer sebesar 0.9079 dan pada model CNN dengan deeper layer nilainya sedikit lebih rendah yakni 0.9016. Penambahan layer yang lebih dalam sebenarnya membuat model mampu mengambil feature dengan lebih banyak namun belum tentu menghasilkan model yang lebih baik. Seperti pada dataset MNIST dimana penambahan layer malah sedikit menurunkan performa dari model\n"
      ]
    }
  ]
}