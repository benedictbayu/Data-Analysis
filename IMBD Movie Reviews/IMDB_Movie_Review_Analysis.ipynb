{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB Movie Review Analysis",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuojjB1J4Prr",
        "colab_type": "text"
      },
      "source": [
        "### **IMDB Movie Reviews Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEDNVvraeOQG",
        "colab_type": "text"
      },
      "source": [
        "#### **Memakai Linear SVC dan Naive Bayes Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDO8GWGJ7RSb",
        "colab_type": "text"
      },
      "source": [
        "##### **Import Library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmPU3lxo1v8h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "outputId": "e4d8dc36-af74-4842-ab15-671d40b8f1d4"
      },
      "source": [
        "!pip install jcopml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jcopml in /usr/local/lib/python3.6/dist-packages (1.1.10)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from jcopml) (0.10.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from jcopml) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from jcopml) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from jcopml) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from jcopml) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from jcopml) (1.0.5)\n",
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.6/dist-packages (from jcopml) (0.7.4)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jcopml) (7.5.1)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from jcopml) (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->jcopml) (0.16.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jcopml) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jcopml) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jcopml) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jcopml) (1.2.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->jcopml) (2018.9)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize->jcopml) (20.4.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jcopml) (4.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jcopml) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jcopml) (5.0.7)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jcopml) (5.5.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jcopml) (4.10.1)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels->jcopml) (0.5.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->jcopml) (1.12.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyaml>=16.9->scikit-optimize->jcopml) (3.13)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets->jcopml) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets->jcopml) (4.4.2)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets->jcopml) (5.2.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->jcopml) (4.6.3)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->jcopml) (2.6.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jcopml) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jcopml) (49.1.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jcopml) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jcopml) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jcopml) (2.1.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jcopml) (0.8.1)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets->jcopml) (4.5.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets->jcopml) (5.3.5)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jcopml) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jcopml) (0.8.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jcopml) (2.11.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jcopml) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jcopml) (0.2.5)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->jcopml) (19.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jcopml) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jcopml) (0.6.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jcopml) (0.4.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jcopml) (1.4.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jcopml) (0.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jcopml) (3.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jcopml) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jcopml) (20.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jcopml) (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Wy0XXvn7XcR",
        "colab_type": "text"
      },
      "source": [
        "##### **Import Library and Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvfrPYDM2PdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFU3BjEa4hjY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bd67676e-c635-4c1e-892e-6b08f9d39754"
      },
      "source": [
        "imdb = pd.read_csv('IMDB Dataset.csv')\n",
        "imdb.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhUG_Jyj4utW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2dbfc26a-9ad6-43ee-d093-30466fcb2cfc"
      },
      "source": [
        "imdb.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUAfK9xj67SY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "e7dc9f4e-f0ee-4726-de06-51c0ed4f58ce"
      },
      "source": [
        "imdb.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     50000 non-null  object\n",
            " 1   sentiment  50000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 781.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvTVqxNS6-c-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "eb9a2482-042f-4213-c1f0-34405013f226"
      },
      "source": [
        "imdb['sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    25000\n",
              "positive    25000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBqDBxCx74qf",
        "colab_type": "text"
      },
      "source": [
        "Kita akan mengambil 1 sample dan melihat mengapa kita harus melakukan cleaning pada teks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ax_qKMKpAkAo",
        "colab_type": "text"
      },
      "source": [
        "### **Contoh review pada index 0**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5FEpO2D7Kau",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "bf49ab42-d466-4bc1-99fd-3f857b598cf5"
      },
      "source": [
        "review = imdb['review'][0]\n",
        "review"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fpE7XKD8znc",
        "colab_type": "text"
      },
      "source": [
        "Pada umumnya, NLP task meliputi teknik text cleaning sebagai berikut\n",
        "\n",
        "1. Menghilangkan konten HTML seperti '<br>'\n",
        "2. Menghilangkan tanda baca, karakter spesial seperti '/'\n",
        "3. Menghilangkan stopwords\n",
        "4. Stemming / Lemmatization\n",
        "5. Vectorization - encode nilai numerikal setelah dilakukan cleaning text\n",
        "6. Fit data ke dalam model machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1phHqQtR9Kuu",
        "colab_type": "text"
      },
      "source": [
        "#### **Menghilangkan konten HTML**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hafxwJJ8HjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nffi81tL9OUZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "719e4863-e2a7-4278-c620-113b02b11444"
      },
      "source": [
        "bsoup = BeautifulSoup(review, 'html.parser')\n",
        "review = bsoup.get_text()\n",
        "review"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuprMQC090Db",
        "colab_type": "text"
      },
      "source": [
        "Dapat terlihat bahwa konten HTML telah dihilangkan\n",
        "\n",
        "\n",
        "Berikutnya kita akan menghilangkan tulisan lower / upper case dengan regular expression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mOvPLwu9vny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g3kXIUW-NGq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "907f3d50-5594-4dfd-ccfe-8c79b47d060e"
      },
      "source": [
        "review = re.sub('\\[[^]]*\\]', ' ', review)\n",
        "review = re.sub('[^a-zA-Z]', ' ', review)\n",
        "review"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'One of the other reviewers has mentioned that after watching just   Oz episode you ll be hooked  They are right  as this is exactly what happened with me The first thing that struck me about Oz was its brutality and unflinching scenes of violence  which set in right from the word GO  Trust me  this is not a show for the faint hearted or timid  This show pulls no punches with regards to drugs  sex or violence  Its is hardcore  in the classic use of the word It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary  It focuses mainly on Emerald City  an experimental section of the prison where all the cells have glass fronts and face inwards  so privacy is not high on the agenda  Em City is home to many  Aryans  Muslims  gangstas  Latinos  Christians  Italians  Irish and more    so scuffles  death stares  dodgy dealings and shady agreements are never far away I would say the main appeal of the show is due to the fact that it goes where other shows wouldn t dare  Forget pretty pictures painted for mainstream audiences  forget charm  forget romance   OZ doesn t mess around  The first episode I ever saw struck me as so nasty it was surreal  I couldn t say I was ready for it  but as I watched more  I developed a taste for Oz  and got accustomed to the high levels of graphic violence  Not just violence  but injustice  crooked guards who ll be sold out for a nickel  inmates who ll kill on order and get away with it  well mannered  middle class inmates being turned into prison bitches due to their lack of street skills or prison experience  Watching Oz  you may become comfortable with what is uncomfortable viewing    thats if you can get in touch with your darker side '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvtUf09P-u65",
        "colab_type": "text"
      },
      "source": [
        "Berikutnya kita akan mengatur agar semua huruf menjadi lowercase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIdKJkwc-jBz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "3d49cd60-22c0-4365-9b48-7aace1fa0d53"
      },
      "source": [
        "review = review.lower()\n",
        "review"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'one of the other reviewers has mentioned that after watching just   oz episode you ll be hooked  they are right  as this is exactly what happened with me the first thing that struck me about oz was its brutality and unflinching scenes of violence  which set in right from the word go  trust me  this is not a show for the faint hearted or timid  this show pulls no punches with regards to drugs  sex or violence  its is hardcore  in the classic use of the word it is called oz as that is the nickname given to the oswald maximum security state penitentary  it focuses mainly on emerald city  an experimental section of the prison where all the cells have glass fronts and face inwards  so privacy is not high on the agenda  em city is home to many  aryans  muslims  gangstas  latinos  christians  italians  irish and more    so scuffles  death stares  dodgy dealings and shady agreements are never far away i would say the main appeal of the show is due to the fact that it goes where other shows wouldn t dare  forget pretty pictures painted for mainstream audiences  forget charm  forget romance   oz doesn t mess around  the first episode i ever saw struck me as so nasty it was surreal  i couldn t say i was ready for it  but as i watched more  i developed a taste for oz  and got accustomed to the high levels of graphic violence  not just violence  but injustice  crooked guards who ll be sold out for a nickel  inmates who ll kill on order and get away with it  well mannered  middle class inmates being turned into prison bitches due to their lack of street skills or prison experience  watching oz  you may become comfortable with what is uncomfortable viewing    thats if you can get in touch with your darker side '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mtwo_Wvb_clf",
        "colab_type": "text"
      },
      "source": [
        "Berikutnya kita akan menghilangkan Stopwords - proses menghilangkan Stopwords bekerja untuk setiap kata dalam teks sehingga kita harus split textnya"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EoQmeKI-5nf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "87a3d1cd-a8fa-4da9-c31f-cb96997eb1b6"
      },
      "source": [
        "review = review.split()\n",
        "review"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'other',\n",
              " 'reviewers',\n",
              " 'has',\n",
              " 'mentioned',\n",
              " 'that',\n",
              " 'after',\n",
              " 'watching',\n",
              " 'just',\n",
              " 'oz',\n",
              " 'episode',\n",
              " 'you',\n",
              " 'll',\n",
              " 'be',\n",
              " 'hooked',\n",
              " 'they',\n",
              " 'are',\n",
              " 'right',\n",
              " 'as',\n",
              " 'this',\n",
              " 'is',\n",
              " 'exactly',\n",
              " 'what',\n",
              " 'happened',\n",
              " 'with',\n",
              " 'me',\n",
              " 'the',\n",
              " 'first',\n",
              " 'thing',\n",
              " 'that',\n",
              " 'struck',\n",
              " 'me',\n",
              " 'about',\n",
              " 'oz',\n",
              " 'was',\n",
              " 'its',\n",
              " 'brutality',\n",
              " 'and',\n",
              " 'unflinching',\n",
              " 'scenes',\n",
              " 'of',\n",
              " 'violence',\n",
              " 'which',\n",
              " 'set',\n",
              " 'in',\n",
              " 'right',\n",
              " 'from',\n",
              " 'the',\n",
              " 'word',\n",
              " 'go',\n",
              " 'trust',\n",
              " 'me',\n",
              " 'this',\n",
              " 'is',\n",
              " 'not',\n",
              " 'a',\n",
              " 'show',\n",
              " 'for',\n",
              " 'the',\n",
              " 'faint',\n",
              " 'hearted',\n",
              " 'or',\n",
              " 'timid',\n",
              " 'this',\n",
              " 'show',\n",
              " 'pulls',\n",
              " 'no',\n",
              " 'punches',\n",
              " 'with',\n",
              " 'regards',\n",
              " 'to',\n",
              " 'drugs',\n",
              " 'sex',\n",
              " 'or',\n",
              " 'violence',\n",
              " 'its',\n",
              " 'is',\n",
              " 'hardcore',\n",
              " 'in',\n",
              " 'the',\n",
              " 'classic',\n",
              " 'use',\n",
              " 'of',\n",
              " 'the',\n",
              " 'word',\n",
              " 'it',\n",
              " 'is',\n",
              " 'called',\n",
              " 'oz',\n",
              " 'as',\n",
              " 'that',\n",
              " 'is',\n",
              " 'the',\n",
              " 'nickname',\n",
              " 'given',\n",
              " 'to',\n",
              " 'the',\n",
              " 'oswald',\n",
              " 'maximum',\n",
              " 'security',\n",
              " 'state',\n",
              " 'penitentary',\n",
              " 'it',\n",
              " 'focuses',\n",
              " 'mainly',\n",
              " 'on',\n",
              " 'emerald',\n",
              " 'city',\n",
              " 'an',\n",
              " 'experimental',\n",
              " 'section',\n",
              " 'of',\n",
              " 'the',\n",
              " 'prison',\n",
              " 'where',\n",
              " 'all',\n",
              " 'the',\n",
              " 'cells',\n",
              " 'have',\n",
              " 'glass',\n",
              " 'fronts',\n",
              " 'and',\n",
              " 'face',\n",
              " 'inwards',\n",
              " 'so',\n",
              " 'privacy',\n",
              " 'is',\n",
              " 'not',\n",
              " 'high',\n",
              " 'on',\n",
              " 'the',\n",
              " 'agenda',\n",
              " 'em',\n",
              " 'city',\n",
              " 'is',\n",
              " 'home',\n",
              " 'to',\n",
              " 'many',\n",
              " 'aryans',\n",
              " 'muslims',\n",
              " 'gangstas',\n",
              " 'latinos',\n",
              " 'christians',\n",
              " 'italians',\n",
              " 'irish',\n",
              " 'and',\n",
              " 'more',\n",
              " 'so',\n",
              " 'scuffles',\n",
              " 'death',\n",
              " 'stares',\n",
              " 'dodgy',\n",
              " 'dealings',\n",
              " 'and',\n",
              " 'shady',\n",
              " 'agreements',\n",
              " 'are',\n",
              " 'never',\n",
              " 'far',\n",
              " 'away',\n",
              " 'i',\n",
              " 'would',\n",
              " 'say',\n",
              " 'the',\n",
              " 'main',\n",
              " 'appeal',\n",
              " 'of',\n",
              " 'the',\n",
              " 'show',\n",
              " 'is',\n",
              " 'due',\n",
              " 'to',\n",
              " 'the',\n",
              " 'fact',\n",
              " 'that',\n",
              " 'it',\n",
              " 'goes',\n",
              " 'where',\n",
              " 'other',\n",
              " 'shows',\n",
              " 'wouldn',\n",
              " 't',\n",
              " 'dare',\n",
              " 'forget',\n",
              " 'pretty',\n",
              " 'pictures',\n",
              " 'painted',\n",
              " 'for',\n",
              " 'mainstream',\n",
              " 'audiences',\n",
              " 'forget',\n",
              " 'charm',\n",
              " 'forget',\n",
              " 'romance',\n",
              " 'oz',\n",
              " 'doesn',\n",
              " 't',\n",
              " 'mess',\n",
              " 'around',\n",
              " 'the',\n",
              " 'first',\n",
              " 'episode',\n",
              " 'i',\n",
              " 'ever',\n",
              " 'saw',\n",
              " 'struck',\n",
              " 'me',\n",
              " 'as',\n",
              " 'so',\n",
              " 'nasty',\n",
              " 'it',\n",
              " 'was',\n",
              " 'surreal',\n",
              " 'i',\n",
              " 'couldn',\n",
              " 't',\n",
              " 'say',\n",
              " 'i',\n",
              " 'was',\n",
              " 'ready',\n",
              " 'for',\n",
              " 'it',\n",
              " 'but',\n",
              " 'as',\n",
              " 'i',\n",
              " 'watched',\n",
              " 'more',\n",
              " 'i',\n",
              " 'developed',\n",
              " 'a',\n",
              " 'taste',\n",
              " 'for',\n",
              " 'oz',\n",
              " 'and',\n",
              " 'got',\n",
              " 'accustomed',\n",
              " 'to',\n",
              " 'the',\n",
              " 'high',\n",
              " 'levels',\n",
              " 'of',\n",
              " 'graphic',\n",
              " 'violence',\n",
              " 'not',\n",
              " 'just',\n",
              " 'violence',\n",
              " 'but',\n",
              " 'injustice',\n",
              " 'crooked',\n",
              " 'guards',\n",
              " 'who',\n",
              " 'll',\n",
              " 'be',\n",
              " 'sold',\n",
              " 'out',\n",
              " 'for',\n",
              " 'a',\n",
              " 'nickel',\n",
              " 'inmates',\n",
              " 'who',\n",
              " 'll',\n",
              " 'kill',\n",
              " 'on',\n",
              " 'order',\n",
              " 'and',\n",
              " 'get',\n",
              " 'away',\n",
              " 'with',\n",
              " 'it',\n",
              " 'well',\n",
              " 'mannered',\n",
              " 'middle',\n",
              " 'class',\n",
              " 'inmates',\n",
              " 'being',\n",
              " 'turned',\n",
              " 'into',\n",
              " 'prison',\n",
              " 'bitches',\n",
              " 'due',\n",
              " 'to',\n",
              " 'their',\n",
              " 'lack',\n",
              " 'of',\n",
              " 'street',\n",
              " 'skills',\n",
              " 'or',\n",
              " 'prison',\n",
              " 'experience',\n",
              " 'watching',\n",
              " 'oz',\n",
              " 'you',\n",
              " 'may',\n",
              " 'become',\n",
              " 'comfortable',\n",
              " 'with',\n",
              " 'what',\n",
              " 'is',\n",
              " 'uncomfortable',\n",
              " 'viewing',\n",
              " 'thats',\n",
              " 'if',\n",
              " 'you',\n",
              " 'can',\n",
              " 'get',\n",
              " 'in',\n",
              " 'touch',\n",
              " 'with',\n",
              " 'your',\n",
              " 'darker',\n",
              " 'side']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk8VE704_qns",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8b4af9a3-2322-4be9-b95b-ee93b58374db"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vTK-u12_3AJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c8de232-530e-491b-db5c-aec18d16f8e4"
      },
      "source": [
        "review = [word for word in review if not word in set(stopwords.words('english'))]\n",
        "review"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['one',\n",
              " 'reviewers',\n",
              " 'mentioned',\n",
              " 'watching',\n",
              " 'oz',\n",
              " 'episode',\n",
              " 'hooked',\n",
              " 'right',\n",
              " 'exactly',\n",
              " 'happened',\n",
              " 'first',\n",
              " 'thing',\n",
              " 'struck',\n",
              " 'oz',\n",
              " 'brutality',\n",
              " 'unflinching',\n",
              " 'scenes',\n",
              " 'violence',\n",
              " 'set',\n",
              " 'right',\n",
              " 'word',\n",
              " 'go',\n",
              " 'trust',\n",
              " 'show',\n",
              " 'faint',\n",
              " 'hearted',\n",
              " 'timid',\n",
              " 'show',\n",
              " 'pulls',\n",
              " 'punches',\n",
              " 'regards',\n",
              " 'drugs',\n",
              " 'sex',\n",
              " 'violence',\n",
              " 'hardcore',\n",
              " 'classic',\n",
              " 'use',\n",
              " 'word',\n",
              " 'called',\n",
              " 'oz',\n",
              " 'nickname',\n",
              " 'given',\n",
              " 'oswald',\n",
              " 'maximum',\n",
              " 'security',\n",
              " 'state',\n",
              " 'penitentary',\n",
              " 'focuses',\n",
              " 'mainly',\n",
              " 'emerald',\n",
              " 'city',\n",
              " 'experimental',\n",
              " 'section',\n",
              " 'prison',\n",
              " 'cells',\n",
              " 'glass',\n",
              " 'fronts',\n",
              " 'face',\n",
              " 'inwards',\n",
              " 'privacy',\n",
              " 'high',\n",
              " 'agenda',\n",
              " 'em',\n",
              " 'city',\n",
              " 'home',\n",
              " 'many',\n",
              " 'aryans',\n",
              " 'muslims',\n",
              " 'gangstas',\n",
              " 'latinos',\n",
              " 'christians',\n",
              " 'italians',\n",
              " 'irish',\n",
              " 'scuffles',\n",
              " 'death',\n",
              " 'stares',\n",
              " 'dodgy',\n",
              " 'dealings',\n",
              " 'shady',\n",
              " 'agreements',\n",
              " 'never',\n",
              " 'far',\n",
              " 'away',\n",
              " 'would',\n",
              " 'say',\n",
              " 'main',\n",
              " 'appeal',\n",
              " 'show',\n",
              " 'due',\n",
              " 'fact',\n",
              " 'goes',\n",
              " 'shows',\n",
              " 'dare',\n",
              " 'forget',\n",
              " 'pretty',\n",
              " 'pictures',\n",
              " 'painted',\n",
              " 'mainstream',\n",
              " 'audiences',\n",
              " 'forget',\n",
              " 'charm',\n",
              " 'forget',\n",
              " 'romance',\n",
              " 'oz',\n",
              " 'mess',\n",
              " 'around',\n",
              " 'first',\n",
              " 'episode',\n",
              " 'ever',\n",
              " 'saw',\n",
              " 'struck',\n",
              " 'nasty',\n",
              " 'surreal',\n",
              " 'say',\n",
              " 'ready',\n",
              " 'watched',\n",
              " 'developed',\n",
              " 'taste',\n",
              " 'oz',\n",
              " 'got',\n",
              " 'accustomed',\n",
              " 'high',\n",
              " 'levels',\n",
              " 'graphic',\n",
              " 'violence',\n",
              " 'violence',\n",
              " 'injustice',\n",
              " 'crooked',\n",
              " 'guards',\n",
              " 'sold',\n",
              " 'nickel',\n",
              " 'inmates',\n",
              " 'kill',\n",
              " 'order',\n",
              " 'get',\n",
              " 'away',\n",
              " 'well',\n",
              " 'mannered',\n",
              " 'middle',\n",
              " 'class',\n",
              " 'inmates',\n",
              " 'turned',\n",
              " 'prison',\n",
              " 'bitches',\n",
              " 'due',\n",
              " 'lack',\n",
              " 'street',\n",
              " 'skills',\n",
              " 'prison',\n",
              " 'experience',\n",
              " 'watching',\n",
              " 'oz',\n",
              " 'may',\n",
              " 'become',\n",
              " 'comfortable',\n",
              " 'uncomfortable',\n",
              " 'viewing',\n",
              " 'thats',\n",
              " 'get',\n",
              " 'touch',\n",
              " 'darker',\n",
              " 'side']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yfq8gftAevA",
        "colab_type": "text"
      },
      "source": [
        "Berikutnya kita akan melakukan Stemming / Lemmatization - kita akan lakukan keduanya dan lihat perbedaanya"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_8ESMK9AA3E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f8ab8fc-f4ce-4f00-9464-566654200994"
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "ps = PorterStemmer()\n",
        "review_stem = [ps.stem(word) for word in review]\n",
        "review_stem"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['one',\n",
              " 'review',\n",
              " 'mention',\n",
              " 'watch',\n",
              " 'oz',\n",
              " 'episod',\n",
              " 'hook',\n",
              " 'right',\n",
              " 'exactli',\n",
              " 'happen',\n",
              " 'first',\n",
              " 'thing',\n",
              " 'struck',\n",
              " 'oz',\n",
              " 'brutal',\n",
              " 'unflinch',\n",
              " 'scene',\n",
              " 'violenc',\n",
              " 'set',\n",
              " 'right',\n",
              " 'word',\n",
              " 'go',\n",
              " 'trust',\n",
              " 'show',\n",
              " 'faint',\n",
              " 'heart',\n",
              " 'timid',\n",
              " 'show',\n",
              " 'pull',\n",
              " 'punch',\n",
              " 'regard',\n",
              " 'drug',\n",
              " 'sex',\n",
              " 'violenc',\n",
              " 'hardcor',\n",
              " 'classic',\n",
              " 'use',\n",
              " 'word',\n",
              " 'call',\n",
              " 'oz',\n",
              " 'nicknam',\n",
              " 'given',\n",
              " 'oswald',\n",
              " 'maximum',\n",
              " 'secur',\n",
              " 'state',\n",
              " 'penitentari',\n",
              " 'focus',\n",
              " 'mainli',\n",
              " 'emerald',\n",
              " 'citi',\n",
              " 'experiment',\n",
              " 'section',\n",
              " 'prison',\n",
              " 'cell',\n",
              " 'glass',\n",
              " 'front',\n",
              " 'face',\n",
              " 'inward',\n",
              " 'privaci',\n",
              " 'high',\n",
              " 'agenda',\n",
              " 'em',\n",
              " 'citi',\n",
              " 'home',\n",
              " 'mani',\n",
              " 'aryan',\n",
              " 'muslim',\n",
              " 'gangsta',\n",
              " 'latino',\n",
              " 'christian',\n",
              " 'italian',\n",
              " 'irish',\n",
              " 'scuffl',\n",
              " 'death',\n",
              " 'stare',\n",
              " 'dodgi',\n",
              " 'deal',\n",
              " 'shadi',\n",
              " 'agreement',\n",
              " 'never',\n",
              " 'far',\n",
              " 'away',\n",
              " 'would',\n",
              " 'say',\n",
              " 'main',\n",
              " 'appeal',\n",
              " 'show',\n",
              " 'due',\n",
              " 'fact',\n",
              " 'goe',\n",
              " 'show',\n",
              " 'dare',\n",
              " 'forget',\n",
              " 'pretti',\n",
              " 'pictur',\n",
              " 'paint',\n",
              " 'mainstream',\n",
              " 'audienc',\n",
              " 'forget',\n",
              " 'charm',\n",
              " 'forget',\n",
              " 'romanc',\n",
              " 'oz',\n",
              " 'mess',\n",
              " 'around',\n",
              " 'first',\n",
              " 'episod',\n",
              " 'ever',\n",
              " 'saw',\n",
              " 'struck',\n",
              " 'nasti',\n",
              " 'surreal',\n",
              " 'say',\n",
              " 'readi',\n",
              " 'watch',\n",
              " 'develop',\n",
              " 'tast',\n",
              " 'oz',\n",
              " 'got',\n",
              " 'accustom',\n",
              " 'high',\n",
              " 'level',\n",
              " 'graphic',\n",
              " 'violenc',\n",
              " 'violenc',\n",
              " 'injustic',\n",
              " 'crook',\n",
              " 'guard',\n",
              " 'sold',\n",
              " 'nickel',\n",
              " 'inmat',\n",
              " 'kill',\n",
              " 'order',\n",
              " 'get',\n",
              " 'away',\n",
              " 'well',\n",
              " 'manner',\n",
              " 'middl',\n",
              " 'class',\n",
              " 'inmat',\n",
              " 'turn',\n",
              " 'prison',\n",
              " 'bitch',\n",
              " 'due',\n",
              " 'lack',\n",
              " 'street',\n",
              " 'skill',\n",
              " 'prison',\n",
              " 'experi',\n",
              " 'watch',\n",
              " 'oz',\n",
              " 'may',\n",
              " 'becom',\n",
              " 'comfort',\n",
              " 'uncomfort',\n",
              " 'view',\n",
              " 'that',\n",
              " 'get',\n",
              " 'touch',\n",
              " 'darker',\n",
              " 'side']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iny4nTJKBxAl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6cecc379-15db-468d-8ca8-2c2dfff9efa3"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mUTvU1SB4U2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ae9d3a79-cd6b-4315-a8c7-f113746d0686"
      },
      "source": [
        "lem = WordNetLemmatizer()\n",
        "review_lemma = [lem.lemmatize(word) for word in review]\n",
        "review_lemma"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['one',\n",
              " 'reviewer',\n",
              " 'mentioned',\n",
              " 'watching',\n",
              " 'oz',\n",
              " 'episode',\n",
              " 'hooked',\n",
              " 'right',\n",
              " 'exactly',\n",
              " 'happened',\n",
              " 'first',\n",
              " 'thing',\n",
              " 'struck',\n",
              " 'oz',\n",
              " 'brutality',\n",
              " 'unflinching',\n",
              " 'scene',\n",
              " 'violence',\n",
              " 'set',\n",
              " 'right',\n",
              " 'word',\n",
              " 'go',\n",
              " 'trust',\n",
              " 'show',\n",
              " 'faint',\n",
              " 'hearted',\n",
              " 'timid',\n",
              " 'show',\n",
              " 'pull',\n",
              " 'punch',\n",
              " 'regard',\n",
              " 'drug',\n",
              " 'sex',\n",
              " 'violence',\n",
              " 'hardcore',\n",
              " 'classic',\n",
              " 'use',\n",
              " 'word',\n",
              " 'called',\n",
              " 'oz',\n",
              " 'nickname',\n",
              " 'given',\n",
              " 'oswald',\n",
              " 'maximum',\n",
              " 'security',\n",
              " 'state',\n",
              " 'penitentary',\n",
              " 'focus',\n",
              " 'mainly',\n",
              " 'emerald',\n",
              " 'city',\n",
              " 'experimental',\n",
              " 'section',\n",
              " 'prison',\n",
              " 'cell',\n",
              " 'glass',\n",
              " 'front',\n",
              " 'face',\n",
              " 'inwards',\n",
              " 'privacy',\n",
              " 'high',\n",
              " 'agenda',\n",
              " 'em',\n",
              " 'city',\n",
              " 'home',\n",
              " 'many',\n",
              " 'aryan',\n",
              " 'muslim',\n",
              " 'gangsta',\n",
              " 'latino',\n",
              " 'christian',\n",
              " 'italian',\n",
              " 'irish',\n",
              " 'scuffle',\n",
              " 'death',\n",
              " 'stare',\n",
              " 'dodgy',\n",
              " 'dealing',\n",
              " 'shady',\n",
              " 'agreement',\n",
              " 'never',\n",
              " 'far',\n",
              " 'away',\n",
              " 'would',\n",
              " 'say',\n",
              " 'main',\n",
              " 'appeal',\n",
              " 'show',\n",
              " 'due',\n",
              " 'fact',\n",
              " 'go',\n",
              " 'show',\n",
              " 'dare',\n",
              " 'forget',\n",
              " 'pretty',\n",
              " 'picture',\n",
              " 'painted',\n",
              " 'mainstream',\n",
              " 'audience',\n",
              " 'forget',\n",
              " 'charm',\n",
              " 'forget',\n",
              " 'romance',\n",
              " 'oz',\n",
              " 'mess',\n",
              " 'around',\n",
              " 'first',\n",
              " 'episode',\n",
              " 'ever',\n",
              " 'saw',\n",
              " 'struck',\n",
              " 'nasty',\n",
              " 'surreal',\n",
              " 'say',\n",
              " 'ready',\n",
              " 'watched',\n",
              " 'developed',\n",
              " 'taste',\n",
              " 'oz',\n",
              " 'got',\n",
              " 'accustomed',\n",
              " 'high',\n",
              " 'level',\n",
              " 'graphic',\n",
              " 'violence',\n",
              " 'violence',\n",
              " 'injustice',\n",
              " 'crooked',\n",
              " 'guard',\n",
              " 'sold',\n",
              " 'nickel',\n",
              " 'inmate',\n",
              " 'kill',\n",
              " 'order',\n",
              " 'get',\n",
              " 'away',\n",
              " 'well',\n",
              " 'mannered',\n",
              " 'middle',\n",
              " 'class',\n",
              " 'inmate',\n",
              " 'turned',\n",
              " 'prison',\n",
              " 'bitch',\n",
              " 'due',\n",
              " 'lack',\n",
              " 'street',\n",
              " 'skill',\n",
              " 'prison',\n",
              " 'experience',\n",
              " 'watching',\n",
              " 'oz',\n",
              " 'may',\n",
              " 'become',\n",
              " 'comfortable',\n",
              " 'uncomfortable',\n",
              " 'viewing',\n",
              " 'thats',\n",
              " 'get',\n",
              " 'touch',\n",
              " 'darker',\n",
              " 'side']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1qoZvecDW5v",
        "colab_type": "text"
      },
      "source": [
        "Dapat kita lihat bahwa kata 'little' menjadi 'littl' setelah Stemming tetapi tetap menjadi 'little' setelah Lemmatization. Maka kita akan gunakan Lemmatization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4zFWDoiEMyL",
        "colab_type": "text"
      },
      "source": [
        "Menggabungkan kata kata yang telah di cleaned"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCAM1X3iCE5Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "b4736ee8-51b0-4205-d490-ee73293ff20c"
      },
      "source": [
        "review_cleaned = ' '.join(review)\n",
        "review_cleaned"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'one reviewers mentioned watching oz episode hooked right exactly happened first thing struck oz brutality unflinching scenes violence set right word go trust show faint hearted timid show pulls punches regards drugs sex violence hardcore classic use word called oz nickname given oswald maximum security state penitentary focuses mainly emerald city experimental section prison cells glass fronts face inwards privacy high agenda em city home many aryans muslims gangstas latinos christians italians irish scuffles death stares dodgy dealings shady agreements never far away would say main appeal show due fact goes shows dare forget pretty pictures painted mainstream audiences forget charm forget romance oz mess around first episode ever saw struck nasty surreal say ready watched developed taste oz got accustomed high levels graphic violence violence injustice crooked guards sold nickel inmates kill order get away well mannered middle class inmates turned prison bitches due lack street skills prison experience watching oz may become comfortable uncomfortable viewing thats get touch darker side'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53T0v_kZEzLe",
        "colab_type": "text"
      },
      "source": [
        "Langkah berikutnya kita akan membentuk format matematikal pada teks ini dan untuk melakukan itu kita akan membuat corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTYxj_8cEhxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = []\n",
        "corpus.append(review_cleaned)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgUsoiCeFNOH",
        "colab_type": "text"
      },
      "source": [
        "Berikutnya kita akan melakukan Vectorization. Ada 2 macam vectorization :\n",
        "\n",
        "1. Count Vectorizer (Bag of Words Model)\n",
        "2. TfIdf Vectorizer (Bag of Words Model)\n",
        "3. Keras Tokenizer (Embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuV2vidVFiNn",
        "colab_type": "text"
      },
      "source": [
        "###### **Count Vectorizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XISjDlb9FIXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkUC7ygmFlzT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "1318bb45-9f67-4fa1-d49c-536a5d0adb9e"
      },
      "source": [
        "cv = CountVectorizer()\n",
        "review_cv = cv.fit_transform(corpus)\n",
        "review_cv.toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3, 1, 1,\n",
              "        2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1,\n",
              "        1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3, 1,\n",
              "        1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 2,\n",
              "        1, 2, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSR8ZnciGXLo",
        "colab_type": "text"
      },
      "source": [
        "Dapat kita lihat bahwa data telah berubah menjadi numerikal dengan nilai 1, 2, 3s tergantung dari berapa kali mereka muncul dalam teks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7cjafqZGuXa",
        "colab_type": "text"
      },
      "source": [
        "Ada variasi lain dari Count Vectorizer dengan binary=True dan pada kasus itu, semua zero entry akan bernilai 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EElh_fJaFxuw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "212dcf8e-e5af-4a84-de7e-6e7bf2524f67"
      },
      "source": [
        "cv_bin = CountVectorizer(binary=True)\n",
        "review_cv_bin = cv_bin.fit_transform(corpus)\n",
        "review_cv_bin.toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKIPu9-wHavk",
        "colab_type": "text"
      },
      "source": [
        "Tidak ada no 2s dan 3s dalam vektor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STK6l-QFHz1i",
        "colab_type": "text"
      },
      "source": [
        "Berikutnya kita akan memakai TF-IDF (Text Frequency - Inverse Document Frequency) Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTnL-NksHym1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YjRC49oH8az",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "8c7fcba0-8123-44f4-e79f-b0b207fdba95"
      },
      "source": [
        "tfidf = TfidfVectorizer()\n",
        "review_tfidf = tfidf.fit_transform(corpus)\n",
        "review_tfidf.toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.06350006, 0.06350006, 0.06350006, 0.06350006, 0.06350006,\n",
              "        0.06350006, 0.06350006, 0.12700013, 0.06350006, 0.06350006,\n",
              "        0.06350006, 0.06350006, 0.06350006, 0.06350006, 0.06350006,\n",
              "        0.12700013, 0.06350006, 0.06350006, 0.06350006, 0.06350006,\n",
              "        0.06350006, 0.06350006, 0.06350006, 0.06350006, 0.06350006,\n",
              "        0.06350006, 0.06350006, 0.12700013, 0.06350006, 0.06350006,\n",
              "        0.12700013, 0.06350006, 0.06350006, 0.06350006, 0.06350006,\n",
              "        0.06350006, 0.06350006, 0.06350006, 0.06350006, 0.12700013,\n",
              "        0.06350006, 0.19050019, 0.06350006, 0.06350006, 0.12700013,\n",
              "        0.06350006, 0.06350006, 0.06350006, 0.06350006, 0.06350006,\n",
              "        0.06350006, 0.06350006, 0.06350006, 0.06350006, 0.06350006,\n",
              "        0.12700013, 0.06350006, 0.06350006, 0.06350006, 0.12700013,\n",
              "        0.06350006, 0.06350006, 0.06350006, 0.06350006, 0.06350006,\n",
              "        0.06350006, 0.06350006, 0.06350006, 0.06350006, 0.06350006,\n",
              "        0.06350006, 0.06350006, 0.06350006, 0.06350006, 0.06350006,\n",
              "        0.06350006, 0.06350006, 0.06350006, 0.06350006, 0.06350006,\n",
              "        0.06350006, 0.06350006, 0.06350006, 0.06350006, 0.06350006,\n",
              "        0.38100038, 0.06350006, 0.06350006, 0.06350006, 0.06350006,\n",
              "        0.19050019, 0.06350006, 0.06350006, 0.06350006, 0.06350006,\n",
              "        0.06350006, 0.06350006, 0.12700013, 0.06350006, 0.06350006,\n",
              "        0.12700013, 0.06350006, 0.06350006, 0.06350006, 0.06350006,\n",
              "        0.06350006, 0.06350006, 0.06350006, 0.19050019, 0.06350006,\n",
              "        0.06350006, 0.06350006, 0.06350006, 0.06350006, 0.06350006,\n",
              "        0.06350006, 0.12700013, 0.06350006, 0.06350006, 0.06350006,\n",
              "        0.06350006, 0.06350006, 0.06350006, 0.06350006, 0.06350006,\n",
              "        0.06350006, 0.06350006, 0.06350006, 0.06350006, 0.25400025,\n",
              "        0.06350006, 0.12700013, 0.06350006, 0.12700013, 0.06350006]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcODCaV6Iney",
        "colab_type": "text"
      },
      "source": [
        "Sekarang akan menerapkan semua teknik yang telah terapkan tadi tapi tidak ada dataset testing sehingga kita akan membuat dataset test sebesar 25% dari dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i955a211ISFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyepeMwlKYB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_train, dataset_test, train_data_label, test_data_label = train_test_split(imdb['review'], imdb['sentiment'], test_size=0.25, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0frmF0-LEXy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "59546431-e749-4515-a37b-e5a4bd6d04a3"
      },
      "source": [
        "print(dataset_train.shape)\n",
        "print(dataset_test.shape)\n",
        "print(train_data_label.shape)\n",
        "print(test_data_label.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(37500,)\n",
            "(12500,)\n",
            "(37500,)\n",
            "(12500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chm_nzR9LhXl",
        "colab_type": "text"
      },
      "source": [
        "Konversi sentimen menjadi bentuk numerikal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2FrHy4dLdGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_label = (train_data_label.replace({'positive' : 1, 'negative' : 0})).values\n",
        "test_data_label = (test_data_label.replace({'positive' : 1, 'negative' : 0})).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyZUyBG6Pe7b",
        "colab_type": "text"
      },
      "source": [
        "Kita akan melakukan cleaning teks dan membuat training dan testing corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h9VAGpdMF-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_train = []\n",
        "corpus_test = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t3bgkgdXpYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(dataset_train.shape[0]):\n",
        "  soup = BeautifulSoup(dataset_train.iloc[i], 'html.parser')\n",
        "  review = soup.get_text()\n",
        "  review = re.sub('\\[[^]]*\\]', ' ', review)\n",
        "  review = re.sub('[^a-zA-Z]', ' ', review)\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "  review = [word for word in review if not word in set(stopwords.words('english'))]\n",
        "  lem = WordNetLemmatizer()\n",
        "  review = [lem.lemmatize(word) for word in review]\n",
        "  review = ' '.join(review)\n",
        "  corpus_train.append(review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln-yx-UZQkqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for j in range(dataset_test.shape[0]):\n",
        "    soup = BeautifulSoup(dataset_test.iloc[j], \"html.parser\")\n",
        "    review = soup.get_text()\n",
        "    review = re.sub('\\[[^]]*\\]', ' ', review)\n",
        "    review = re.sub('[^a-zA-Z]', ' ', review)\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    review = [word for word in review if not word in set(stopwords.words('english'))]\n",
        "    lem = WordNetLemmatizer()\n",
        "    review = [lem.lemmatize(word) for word in review]\n",
        "    review = ' '.join(review)\n",
        "    corpus_test.append(review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFBefadTc3uk",
        "colab_type": "text"
      },
      "source": [
        "Kita lakukan validasi terhadap salah satu sampel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEXMltWpctRM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "e916819b-a3b3-4275-8ddb-d0d27389d2fb"
      },
      "source": [
        "corpus_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'figure alternate reality teen flick precisely ferris bueller type character leader cheat ring yeah know meant compared ferris bueller least orange orange way none le bottom line galaxy away even even minor classic watchable though expecting much said main character charm premise wear thin writing clever movie deliver enough laugh twist tension keep interest honest continue watching watching hope see anything suddenly clicked stylish recommend movie btw seems odd see mary tyler moore principal truly miscast hope paycheck inordinately big'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgK-uJl3c72l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "c22329cf-fca3-4216-b2d7-807b19fc2559"
      },
      "source": [
        "corpus_test[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'really liked summerslam due look arena curtain look overall interesting reason anyways could one best summerslam ever wwf lex luger main event yokozuna time ok huge fat man v strong man glad time changed terrible main event like every match luger terrible match card razor ramon v ted dibiase steiner brother v heavenly body shawn michael v curt hening event shawn named big monster body guard diesel irs v kid bret hart first take doink take jerry lawler stuff hart lawler always interesting ludvig borga destroyed marty jannetty undertaker took giant gonzalez another terrible match smoking gunns tatanka took bam bam bigelow headshrinkers yokozuna defended world title lex luger match boring terrible ending however deserves'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW0pUZLedFbL",
        "colab_type": "text"
      },
      "source": [
        "Kita akan lakukan vectorization\n",
        "\n",
        "###### **Tf-Idf Vectorizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvLZ69u8dAN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_vec = TfidfVectorizer(ngram_range=(1, 3))\n",
        "\n",
        "tfidf_vec_train = tfidf_vec.fit_transform(corpus_train)\n",
        "tfidf_vec_test = tfidf_vec.transform(corpus_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN4z-3qYg_5s",
        "colab_type": "text"
      },
      "source": [
        "###### **Count Vectorizer (binary=False)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi4Qyz0VhEnt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vec = CountVectorizer(ngram_range=(1, 3), binary=False)\n",
        "count_vec_train = count_vec.fit_transform(corpus_train)\n",
        "count_vec_test = count_vec.transform(corpus_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaYC2fcChrBd",
        "colab_type": "text"
      },
      "source": [
        "###### **Count Vectorizer (binary=True)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-mNM0c3hvVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vec_true = CountVectorizer(ngram_range=(1, 3), binary=True)\n",
        "count_vec_true_train = count_vec_true.fit_transform(corpus_train)\n",
        "count_vec_true_test = count_vec_true.transform(corpus_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuzXEHjBelL8",
        "colab_type": "text"
      },
      "source": [
        "##### **First model : Linear SVC (Tf-Idf Vectorizer)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo5LAzhTeDEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import LinearSVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74MR5GMter53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear_svc = LinearSVC(C=0.5, random_state=42)\n",
        "linear_svc.fit(tfidf_vec_train, train_data_label)\n",
        "predict_svc = linear_svc.predict(tfidf_vec_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLnmXM4dfbH1",
        "colab_type": "text"
      },
      "source": [
        "Kita lihat performanya"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNmHBC8pfX7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnBE-Pk8fgA1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "56ecfb10-02e5-42ee-fb81-5c7a48db2a83"
      },
      "source": [
        "print('Classification Report for Linear SVC Model Using Tf-Idf Vectorizer: \\n\\n', classification_report(test_data_label, predict_svc, target_names=['Negative', 'Positive']))\n",
        "print('Confusion Matrix for Linear SVC Model Using Tf-Idf Vectorizer: \\n', confusion_matrix(test_data_label, predict_svc))\n",
        "print()\n",
        "print('Model Accuracy for Linear SVC Model Using Tf-Idf Vectorizer:', accuracy_score(test_data_label, predict_svc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report for Linear SVC Model Using Tf-Idf Vectorizer: \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.91      0.89      0.90      6157\n",
            "    Positive       0.89      0.92      0.91      6343\n",
            "\n",
            "    accuracy                           0.90     12500\n",
            "   macro avg       0.90      0.90      0.90     12500\n",
            "weighted avg       0.90      0.90      0.90     12500\n",
            "\n",
            "Confusion Matrix for Linear SVC Model Using Tf-Idf Vectorizer: \n",
            " [[5467  690]\n",
            " [ 524 5819]]\n",
            "\n",
            "Model Accuracy for Linear SVC Model Using Tf-Idf Vectorizer: 0.90288\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF0CZaE3iZCf",
        "colab_type": "text"
      },
      "source": [
        "##### **Second Model : Linear SVC (Count Vectorizer with binary = False)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaDSpwq2f9mN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear_svc_count = LinearSVC(C=0.5, random_state=42, max_iter=5000)\n",
        "linear_svc_count.fit(count_vec_train, train_data_label)\n",
        "predict_svc_count = linear_svc_count.predict(count_vec_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5xPEdaHjMBm",
        "colab_type": "text"
      },
      "source": [
        "Kita lihat performanya"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FVGSBC8i0Am",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "da521ce0-d271-4ef1-a080-f5ea722c2fbe"
      },
      "source": [
        "print('Classification Report for Linear SVC Model Using Count Vectorizer (binary=False):\\n\\n', classification_report(test_data_label, predict_svc_count, target_names=['Negative', 'Positive']))\n",
        "print('Confusion Matrix for Linear SVC Model Using Count Vectorizer (binary=False):\\n', confusion_matrix(test_data_label, predict_svc_count))\n",
        "print()\n",
        "print('Model Accuracy for Linear SVC Model Using Count Vectorizer (binary=False): ', accuracy_score(test_data_label, predict_svc_count))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report for Linear SVC Model Using Count Vectorizer (binary=False):\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.90      0.89      0.90      6157\n",
            "    Positive       0.90      0.90      0.90      6343\n",
            "\n",
            "    accuracy                           0.90     12500\n",
            "   macro avg       0.90      0.90      0.90     12500\n",
            "weighted avg       0.90      0.90      0.90     12500\n",
            "\n",
            "Confusion Matrix for Linear SVC Model Using Count Vectorizer (binary=False):\n",
            " [[5489  668]\n",
            " [ 611 5732]]\n",
            "\n",
            "Model Accuracy for Linear SVC Model Using Count Vectorizer (binary=False):  0.89768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfulXNz-kMUM",
        "colab_type": "text"
      },
      "source": [
        "##### **Third Model : Linear SVC (Count Vectorizer with binary = True)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU5T_CEykLTt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a6b1c47b-b9c1-4575-abb8-4ffc933a018f"
      },
      "source": [
        "linear_svc_count_true = LinearSVC(C=0.5, random_state=42)\n",
        "linear_svc_count_true.fit(count_vec_true_train, train_data_label)\n",
        "predict_svc_count_true = linear_svc_count_true.predict(count_vec_true_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn4pFbwXFkvH",
        "colab_type": "text"
      },
      "source": [
        "Kita lihat performanya"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P92nSwwvkE0_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "4d68b02f-162f-4107-b271-1bf0986e0469"
      },
      "source": [
        "print('Classification Report for Linear SVC Model Using Count Vectorizer (binary=False): \\n\\n', classification_report(test_data_label, predict_svc_count_true, target_names=['Negative', 'Positive']))\n",
        "print('Confusion Matrix for Linear SVC Model Using Count Vectorizer (binary=False): \\n', confusion_matrix(test_data_label, predict_svc_count_true))\n",
        "print()\n",
        "print('Model Accuracy for Linear SVC Model Using Count Vectorizer (binary=True): ', accuracy_score(test_data_label, predict_svc_count_true))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report for Linear SVC Model Using Count Vectorizer (binary=False): \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.90      0.89      0.89      6157\n",
            "    Positive       0.89      0.90      0.90      6343\n",
            "\n",
            "    accuracy                           0.89     12500\n",
            "   macro avg       0.89      0.89      0.89     12500\n",
            "weighted avg       0.89      0.89      0.89     12500\n",
            "\n",
            "Confusion Matrix for Linear SVC Model Using Count Vectorizer (binary=False): \n",
            " [[5461  696]\n",
            " [ 621 5722]]\n",
            "\n",
            "Model Accuracy for Linear SVC Model Using Count Vectorizer (binary=True):  0.89464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Nh1ZisSGo-X",
        "colab_type": "text"
      },
      "source": [
        "Nilai Akurasi Tertinggi didapat dengan model **Linear SVC memakai Tf-Idf Vectorizer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQGaxRiK5eBb",
        "colab_type": "text"
      },
      "source": [
        "Berikutnya kita akan memakai Multinomial Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhe_Mi9mMtGb",
        "colab_type": "text"
      },
      "source": [
        "**Tf-Idf Vectorizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEbPiXX7GkvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_nb_multi = TfidfVectorizer(ngram_range=(1, 1))\n",
        "tfidf_nb_multi_train = tfidf_nb_multi.fit_transform(corpus_train)\n",
        "tfidf_nb_multi_test = tfidf_nb_multi.transform(corpus_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rgPg9N2IlNE",
        "colab_type": "text"
      },
      "source": [
        "Terdapat 81301 kolom dalam corpus, sehingga kita akan gunakan test Chi-Square untuk mengambil 50000 kolom (features) saja"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRElfgn3M5dS",
        "colab_type": "text"
      },
      "source": [
        "**Count Vectorizer (binary = False)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6NmmlnzM5Eo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_multi_nb = CountVectorizer(ngram_range=(1, 3), binary=False)\n",
        "count_multi_nb_train = count_multi_nb.fit_transform(corpus_train)\n",
        "count_multi_nb_test = count_multi_nb.transform(corpus_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtYspHTDNPeY",
        "colab_type": "text"
      },
      "source": [
        "**Count Vectorizer (binary = True)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54eKvhEkNPLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_multi_nb_true = CountVectorizer(ngram_range=(1, 3), binary=True)\n",
        "count_multi_nb_true_train = count_multi_nb_true.fit_transform(corpus_train)\n",
        "count_multi_nb_true_test = count_multi_nb_true.transform(corpus_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDaKHMkm4KoP",
        "colab_type": "text"
      },
      "source": [
        "##### **Fourth Model : Multinomial Naive Bayes (Tf-Idf Vectorizer)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA3bSol96s26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET9ctsJVIfjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ch2 = SelectKBest(chi2, k=50000)\n",
        "tfidf_nb_multi_train = ch2.fit_transform(tfidf_nb_multi_train, train_data_label)\n",
        "tfidf_nb_multi_test = ch2.transform(tfidf_nb_multi_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj8Eu9X9JWrg",
        "colab_type": "text"
      },
      "source": [
        "Sekarang kita bisa melihat featuresnya"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdUaDX9rJSDO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4dc0a647-8311-45a9-ac5e-a8e58040c8d3"
      },
      "source": [
        "features_names = tfidf_nb_multi.get_feature_names()\n",
        "features_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aa',\n",
              " 'aaa',\n",
              " 'aaaaaaaaaaaahhhhhhhhhhhhhh',\n",
              " 'aaaaaaaargh',\n",
              " 'aaaaagh',\n",
              " 'aaaaah',\n",
              " 'aaaaahhhh',\n",
              " 'aaaaargh',\n",
              " 'aaaaatch',\n",
              " 'aaaaaw',\n",
              " 'aaaahhhhhh',\n",
              " 'aaaahhhhhhh',\n",
              " 'aaaarrgh',\n",
              " 'aaaawwwwww',\n",
              " 'aaah',\n",
              " 'aaahhhhhhh',\n",
              " 'aaam',\n",
              " 'aaand',\n",
              " 'aaargh',\n",
              " 'aaaugh',\n",
              " 'aab',\n",
              " 'aachen',\n",
              " 'aada',\n",
              " 'aadha',\n",
              " 'aag',\n",
              " 'aage',\n",
              " 'aaghh',\n",
              " 'aah',\n",
              " 'aahed',\n",
              " 'aahhhh',\n",
              " 'aahing',\n",
              " 'aaila',\n",
              " 'aailiyah',\n",
              " 'aaja',\n",
              " 'aajala',\n",
              " 'aake',\n",
              " 'aaker',\n",
              " 'aalcc',\n",
              " 'aaliyah',\n",
              " 'aalox',\n",
              " 'aames',\n",
              " 'aamir',\n",
              " 'aamr',\n",
              " 'aamto',\n",
              " 'aan',\n",
              " 'aankh',\n",
              " 'aankhen',\n",
              " 'aap',\n",
              " 'aapke',\n",
              " 'aapkey',\n",
              " 'aaran',\n",
              " 'aardman',\n",
              " 'aardvark',\n",
              " 'aarf',\n",
              " 'aargh',\n",
              " 'aarika',\n",
              " 'aaron',\n",
              " 'aaronanchors',\n",
              " 'aashok',\n",
              " 'aasmaan',\n",
              " 'aasman',\n",
              " 'aatish',\n",
              " 'aaton',\n",
              " 'aau',\n",
              " 'aauugghh',\n",
              " 'aavjo',\n",
              " 'aawip',\n",
              " 'aaww',\n",
              " 'ab',\n",
              " 'aba',\n",
              " 'ababy',\n",
              " 'aback',\n",
              " 'abadi',\n",
              " 'abagail',\n",
              " 'abanazer',\n",
              " 'abandon',\n",
              " 'abandoned',\n",
              " 'abandoning',\n",
              " 'abandoningindian',\n",
              " 'abandonment',\n",
              " 'abandonof',\n",
              " 'abanks',\n",
              " 'abashed',\n",
              " 'abashidze',\n",
              " 'abasing',\n",
              " 'abatement',\n",
              " 'abating',\n",
              " 'abattoir',\n",
              " 'abba',\n",
              " 'abbad',\n",
              " 'abbas',\n",
              " 'abbasi',\n",
              " 'abbe',\n",
              " 'abbey',\n",
              " 'abbie',\n",
              " 'abbot',\n",
              " 'abbott',\n",
              " 'abbotts',\n",
              " 'abbreviate',\n",
              " 'abbreviated',\n",
              " 'abbu',\n",
              " 'abby',\n",
              " 'abbyss',\n",
              " 'abc',\n",
              " 'abcd',\n",
              " 'abd',\n",
              " 'abdalla',\n",
              " 'abderrahmane',\n",
              " 'abdicated',\n",
              " 'abdicates',\n",
              " 'abdicating',\n",
              " 'abdomen',\n",
              " 'abdominal',\n",
              " 'abdoo',\n",
              " 'abdu',\n",
              " 'abduct',\n",
              " 'abducted',\n",
              " 'abductee',\n",
              " 'abducting',\n",
              " 'abduction',\n",
              " 'abductor',\n",
              " 'abducts',\n",
              " 'abdul',\n",
              " 'abdullah',\n",
              " 'abdulrahman',\n",
              " 'abe',\n",
              " 'abecassis',\n",
              " 'abed',\n",
              " 'abedalla',\n",
              " 'abedded',\n",
              " 'abel',\n",
              " 'abell',\n",
              " 'abercrombie',\n",
              " 'aberdeen',\n",
              " 'abernathie',\n",
              " 'abernathy',\n",
              " 'abernethie',\n",
              " 'aberrant',\n",
              " 'aberration',\n",
              " 'aberystwyth',\n",
              " 'abetted',\n",
              " 'abetting',\n",
              " 'abeyance',\n",
              " 'abfab',\n",
              " 'abgail',\n",
              " 'abhay',\n",
              " 'abhays',\n",
              " 'abhi',\n",
              " 'abhijeet',\n",
              " 'abhimaan',\n",
              " 'abhisheh',\n",
              " 'abhishek',\n",
              " 'abhor',\n",
              " 'abhorent',\n",
              " 'abhorr',\n",
              " 'abhorred',\n",
              " 'abhorrence',\n",
              " 'abhorrent',\n",
              " 'abhors',\n",
              " 'abide',\n",
              " 'abides',\n",
              " 'abiding',\n",
              " 'abigail',\n",
              " 'abigil',\n",
              " 'abilene',\n",
              " 'ability',\n",
              " 'abilityof',\n",
              " 'abir',\n",
              " 'abishag',\n",
              " 'abishai',\n",
              " 'abishek',\n",
              " 'abit',\n",
              " 'abject',\n",
              " 'abjectly',\n",
              " 'ablank',\n",
              " 'ablaze',\n",
              " 'able',\n",
              " 'abler',\n",
              " 'ables',\n",
              " 'ableto',\n",
              " 'ably',\n",
              " 'abm',\n",
              " 'abnegated',\n",
              " 'abner',\n",
              " 'abnormal',\n",
              " 'abnormality',\n",
              " 'abnormally',\n",
              " 'abo',\n",
              " 'aboard',\n",
              " 'abode',\n",
              " 'abolish',\n",
              " 'abolished',\n",
              " 'abolition',\n",
              " 'abolitionist',\n",
              " 'abomin',\n",
              " 'abominable',\n",
              " 'abominably',\n",
              " 'abomination',\n",
              " 'abominator',\n",
              " 'abominibal',\n",
              " 'aboooot',\n",
              " 'aboout',\n",
              " 'aborigin',\n",
              " 'aboriginal',\n",
              " 'aborigine',\n",
              " 'aboriginies',\n",
              " 'aborigins',\n",
              " 'aborigone',\n",
              " 'abort',\n",
              " 'aborted',\n",
              " 'aborting',\n",
              " 'abortion',\n",
              " 'abortionist',\n",
              " 'abortive',\n",
              " 'abott',\n",
              " 'abou',\n",
              " 'abound',\n",
              " 'abounded',\n",
              " 'abounding',\n",
              " 'abounds',\n",
              " 'aboutagirly',\n",
              " 'abouts',\n",
              " 'aboutthe',\n",
              " 'abovee',\n",
              " 'abovementioned',\n",
              " 'abra',\n",
              " 'abracadabrantesque',\n",
              " 'abraham',\n",
              " 'abrahimi',\n",
              " 'abrahms',\n",
              " 'abram',\n",
              " 'abrams',\n",
              " 'abraracourcix',\n",
              " 'abrasive',\n",
              " 'abrasively',\n",
              " 'abrasiveness',\n",
              " 'abrazo',\n",
              " 'abre',\n",
              " 'abreast',\n",
              " 'abrh',\n",
              " 'abridge',\n",
              " 'abridged',\n",
              " 'abridgement',\n",
              " 'abril',\n",
              " 'abroad',\n",
              " 'abrogated',\n",
              " 'abromowitz',\n",
              " 'abrupt',\n",
              " 'abruptly',\n",
              " 'abruptlydirection',\n",
              " 'abruptness',\n",
              " 'abscond',\n",
              " 'absconded',\n",
              " 'absconding',\n",
              " 'abseiling',\n",
              " 'absence',\n",
              " 'absense',\n",
              " 'absent',\n",
              " 'absentee',\n",
              " 'absentia',\n",
              " 'absentminded',\n",
              " 'absentmindedly',\n",
              " 'absolom',\n",
              " 'absoloutely',\n",
              " 'absoloutley',\n",
              " 'absolute',\n",
              " 'absolutelly',\n",
              " 'absolutely',\n",
              " 'absoluter',\n",
              " 'absolutey',\n",
              " 'absolution',\n",
              " 'absolutlely',\n",
              " 'absolutley',\n",
              " 'absolutly',\n",
              " 'absolve',\n",
              " 'absolved',\n",
              " 'absolves',\n",
              " 'absorb',\n",
              " 'absorbe',\n",
              " 'absorbed',\n",
              " 'absorbent',\n",
              " 'absorbing',\n",
              " 'absorbingly',\n",
              " 'absorbs',\n",
              " 'absorption',\n",
              " 'absoulely',\n",
              " 'absoutely',\n",
              " 'abstain',\n",
              " 'abstains',\n",
              " 'abstinence',\n",
              " 'abstract',\n",
              " 'abstracted',\n",
              " 'abstracting',\n",
              " 'abstraction',\n",
              " 'abstruse',\n",
              " 'absurd',\n",
              " 'absurder',\n",
              " 'absurdest',\n",
              " 'absurdism',\n",
              " 'absurdist',\n",
              " 'absurdit',\n",
              " 'absurdity',\n",
              " 'absurdly',\n",
              " 'absurdness',\n",
              " 'abt',\n",
              " 'abu',\n",
              " 'abudantly',\n",
              " 'abuelita',\n",
              " 'abuelo',\n",
              " 'abuhab',\n",
              " 'abundance',\n",
              " 'abundant',\n",
              " 'abundantly',\n",
              " 'abuse',\n",
              " 'abused',\n",
              " 'abuser',\n",
              " 'abusin',\n",
              " 'abusing',\n",
              " 'abusive',\n",
              " 'abusively',\n",
              " 'abut',\n",
              " 'abutted',\n",
              " 'abuzz',\n",
              " 'abvious',\n",
              " 'aby',\n",
              " 'abydos',\n",
              " 'abysmal',\n",
              " 'abysmally',\n",
              " 'abyss',\n",
              " 'abyssmal',\n",
              " 'abysymal',\n",
              " 'ac',\n",
              " 'acacia',\n",
              " 'acadamy',\n",
              " 'acadamyhad',\n",
              " 'academe',\n",
              " 'academia',\n",
              " 'academian',\n",
              " 'academic',\n",
              " 'academically',\n",
              " 'academy',\n",
              " 'acadian',\n",
              " 'acadiana',\n",
              " 'acadmey',\n",
              " 'acapella',\n",
              " 'acapulco',\n",
              " 'acc',\n",
              " 'accapella',\n",
              " 'accedes',\n",
              " 'accelerant',\n",
              " 'accelerate',\n",
              " 'accelerated',\n",
              " 'accelerates',\n",
              " 'accelerati',\n",
              " 'accelerating',\n",
              " 'acceleration',\n",
              " 'accelerator',\n",
              " 'accellerant',\n",
              " 'accent',\n",
              " 'accented',\n",
              " 'accentuate',\n",
              " 'accentuated',\n",
              " 'accentuates',\n",
              " 'accentuating',\n",
              " 'accentuation',\n",
              " 'acceotable',\n",
              " 'accept',\n",
              " 'acceptable',\n",
              " 'acceptablefor',\n",
              " 'acceptably',\n",
              " 'acceptance',\n",
              " 'acceptation',\n",
              " 'accepted',\n",
              " 'acceptence',\n",
              " 'accepting',\n",
              " 'acceptingly',\n",
              " 'acception',\n",
              " 'accepts',\n",
              " 'accesible',\n",
              " 'access',\n",
              " 'accessability',\n",
              " 'accessabilty',\n",
              " 'accessed',\n",
              " 'accessibility',\n",
              " 'accessible',\n",
              " 'accessing',\n",
              " 'accession',\n",
              " 'accessorizing',\n",
              " 'accessory',\n",
              " 'accidence',\n",
              " 'accident',\n",
              " 'accidental',\n",
              " 'accidentally',\n",
              " 'accidentee',\n",
              " 'accidentially',\n",
              " 'accidently',\n",
              " 'acclaied',\n",
              " 'acclaim',\n",
              " 'acclaimed',\n",
              " 'acclaiming',\n",
              " 'acclamation',\n",
              " 'acclimatisation',\n",
              " 'accolade',\n",
              " 'accoladed',\n",
              " 'accommodate',\n",
              " 'accommodated',\n",
              " 'accommodates',\n",
              " 'accommodating',\n",
              " 'accommodation',\n",
              " 'accomodations',\n",
              " 'accompanied',\n",
              " 'accompanies',\n",
              " 'accompaniment',\n",
              " 'accompanist',\n",
              " 'accompany',\n",
              " 'accompanying',\n",
              " 'accomplice',\n",
              " 'accomplish',\n",
              " 'accomplished',\n",
              " 'accomplishes',\n",
              " 'accomplishing',\n",
              " 'accomplishment',\n",
              " 'accord',\n",
              " 'accordance',\n",
              " 'accorded',\n",
              " 'accordian',\n",
              " 'according',\n",
              " 'accordingly',\n",
              " 'accordion',\n",
              " 'accorsi',\n",
              " 'accoss',\n",
              " 'accost',\n",
              " 'accosted',\n",
              " 'accosts',\n",
              " 'account',\n",
              " 'accountability',\n",
              " 'accountable',\n",
              " 'accountancy',\n",
              " 'accountant',\n",
              " 'accounted',\n",
              " 'accounting',\n",
              " 'accouterment',\n",
              " 'accoutrement',\n",
              " 'accowmplished',\n",
              " 'accredited',\n",
              " 'accross',\n",
              " 'accrued',\n",
              " 'accrutements',\n",
              " 'acculturation',\n",
              " 'accumulate',\n",
              " 'accumulated',\n",
              " 'accumulates',\n",
              " 'accumulating',\n",
              " 'accumulation',\n",
              " 'accumulator',\n",
              " 'accuracy',\n",
              " 'accurate',\n",
              " 'accurately',\n",
              " 'accursed',\n",
              " 'accusation',\n",
              " 'accusatory',\n",
              " 'accuse',\n",
              " 'accused',\n",
              " 'accusee',\n",
              " 'accuser',\n",
              " 'accuses',\n",
              " 'accusing',\n",
              " 'accussation',\n",
              " 'accussed',\n",
              " 'accustom',\n",
              " 'accustomed',\n",
              " 'acd',\n",
              " 'ace',\n",
              " 'acedemy',\n",
              " 'acerbic',\n",
              " 'acerbity',\n",
              " 'aceves',\n",
              " 'ach',\n",
              " 'achaar',\n",
              " 'achance',\n",
              " 'acharya',\n",
              " 'achcha',\n",
              " 'ache',\n",
              " 'acheaology',\n",
              " 'ached',\n",
              " 'achenbach',\n",
              " 'acherhuis',\n",
              " 'achero',\n",
              " 'achievable',\n",
              " 'achieve',\n",
              " 'achieved',\n",
              " 'achieveing',\n",
              " 'achievement',\n",
              " 'achiever',\n",
              " 'achieves',\n",
              " 'achieving',\n",
              " 'achile',\n",
              " 'achille',\n",
              " 'achillea',\n",
              " 'achilles',\n",
              " 'achillies',\n",
              " 'aching',\n",
              " 'achingly',\n",
              " 'achive',\n",
              " 'acholoic',\n",
              " 'achra',\n",
              " 'achronological',\n",
              " 'achtung',\n",
              " 'acid',\n",
              " 'acidently',\n",
              " 'acidic',\n",
              " 'acidified',\n",
              " 'acidity',\n",
              " 'acidland',\n",
              " 'acin',\n",
              " 'acing',\n",
              " 'aciton',\n",
              " 'acity',\n",
              " 'ack',\n",
              " 'acker',\n",
              " 'ackerman',\n",
              " 'ackland',\n",
              " 'acknowledge',\n",
              " 'acknowledged',\n",
              " 'acknowledgement',\n",
              " 'acknowledges',\n",
              " 'acknowledging',\n",
              " 'acknowledgment',\n",
              " 'ackos',\n",
              " 'ackroyd',\n",
              " 'ackward',\n",
              " 'acl',\n",
              " 'aclear',\n",
              " 'aclu',\n",
              " 'acme',\n",
              " 'acmetropolis',\n",
              " 'acmi',\n",
              " 'acne',\n",
              " 'acog',\n",
              " 'acolyte',\n",
              " 'acommentary',\n",
              " 'acomplete',\n",
              " 'acomplication',\n",
              " 'acording',\n",
              " 'acorn',\n",
              " 'acosta',\n",
              " 'acoustic',\n",
              " 'acp',\n",
              " 'acquaint',\n",
              " 'acquaintaces',\n",
              " 'acquaintance',\n",
              " 'acquainted',\n",
              " 'acquaints',\n",
              " 'acquart',\n",
              " 'acquiesce',\n",
              " 'acquiescence',\n",
              " 'acquire',\n",
              " 'acquired',\n",
              " 'acquires',\n",
              " 'acquiring',\n",
              " 'acquisition',\n",
              " 'acquisitive',\n",
              " 'acquit',\n",
              " 'acquitane',\n",
              " 'acquits',\n",
              " 'acquittal',\n",
              " 'acquittance',\n",
              " 'acquitted',\n",
              " 'acre',\n",
              " 'acreage',\n",
              " 'acrid',\n",
              " 'acrimonious',\n",
              " 'acrimony',\n",
              " 'acrobat',\n",
              " 'acrobatic',\n",
              " 'acrobatics',\n",
              " 'acrobatty',\n",
              " 'acromegaly',\n",
              " 'acronym',\n",
              " 'acronymic',\n",
              " 'acropolis',\n",
              " 'across',\n",
              " 'acrylic',\n",
              " 'act',\n",
              " 'actally',\n",
              " 'acte',\n",
              " 'acted',\n",
              " 'actelone',\n",
              " 'actess',\n",
              " 'acteurs',\n",
              " 'actin',\n",
              " 'acting',\n",
              " 'actingerratically',\n",
              " 'actingits',\n",
              " 'actingjob',\n",
              " 'actingso',\n",
              " 'actingugh',\n",
              " 'actingwise',\n",
              " 'actio',\n",
              " 'action',\n",
              " 'actiona',\n",
              " 'actioned',\n",
              " 'actioneer',\n",
              " 'actioneers',\n",
              " 'actioner',\n",
              " 'actioners',\n",
              " 'actionless',\n",
              " 'actionmovie',\n",
              " 'actionpacked',\n",
              " 'actionscenes',\n",
              " 'actionsequences',\n",
              " 'actium',\n",
              " 'activate',\n",
              " 'activated',\n",
              " 'activates',\n",
              " 'activating',\n",
              " 'activator',\n",
              " 'active',\n",
              " 'actively',\n",
              " 'activest',\n",
              " 'activision',\n",
              " 'activism',\n",
              " 'activist',\n",
              " 'activity',\n",
              " 'actor',\n",
              " 'actores',\n",
              " 'actori',\n",
              " 'actorly',\n",
              " 'actorthe',\n",
              " 'actorwhat',\n",
              " 'actra',\n",
              " 'actress',\n",
              " 'actriss',\n",
              " 'actual',\n",
              " 'actuality',\n",
              " 'actualize',\n",
              " 'actuall',\n",
              " 'actually',\n",
              " 'actualy',\n",
              " 'actuarial',\n",
              " 'actuator',\n",
              " 'actullly',\n",
              " 'acturly',\n",
              " 'acual',\n",
              " 'acually',\n",
              " 'acuhu',\n",
              " 'acuity',\n",
              " 'acumen',\n",
              " 'acuna',\n",
              " 'acupat',\n",
              " 'acupuncture',\n",
              " 'acupuncturist',\n",
              " 'acurate',\n",
              " 'acurately',\n",
              " 'acus',\n",
              " 'acute',\n",
              " 'acutely',\n",
              " 'acuteness',\n",
              " 'ad',\n",
              " 'ada',\n",
              " 'adabted',\n",
              " 'adachi',\n",
              " 'adage',\n",
              " 'adagietto',\n",
              " 'adagio',\n",
              " 'adah',\n",
              " 'adair',\n",
              " 'adajani',\n",
              " 'adalbert',\n",
              " 'adalberto',\n",
              " 'adam',\n",
              " 'adama',\n",
              " 'adamant',\n",
              " 'adamantium',\n",
              " 'adamantly',\n",
              " 'adamason',\n",
              " 'adames',\n",
              " 'adamfontaine',\n",
              " 'adamic',\n",
              " 'adamson',\n",
              " 'adamsons',\n",
              " 'adante',\n",
              " 'adapt',\n",
              " 'adaptable',\n",
              " 'adaptaion',\n",
              " 'adaptation',\n",
              " 'adapted',\n",
              " 'adapter',\n",
              " 'adapting',\n",
              " 'adaption',\n",
              " 'adaptor',\n",
              " 'adapts',\n",
              " 'adarsh',\n",
              " 'aday',\n",
              " 'adays',\n",
              " 'add',\n",
              " 'addam',\n",
              " 'addams',\n",
              " 'addario',\n",
              " 'added',\n",
              " 'addendum',\n",
              " 'adder',\n",
              " 'addict',\n",
              " 'addicted',\n",
              " 'addicting',\n",
              " 'addiction',\n",
              " 'addictive',\n",
              " 'addie',\n",
              " 'adding',\n",
              " 'addio',\n",
              " 'addison',\n",
              " 'addition',\n",
              " 'additionaally',\n",
              " 'additional',\n",
              " 'additionally',\n",
              " 'additive',\n",
              " 'addle',\n",
              " 'addled',\n",
              " 'addons',\n",
              " 'address',\n",
              " 'addressed',\n",
              " 'addressing',\n",
              " 'addtion',\n",
              " 'addtionally',\n",
              " 'addy',\n",
              " 'addytown',\n",
              " 'ade',\n",
              " 'adebesi',\n",
              " 'adebisi',\n",
              " 'adeeper',\n",
              " 'adela',\n",
              " 'adelade',\n",
              " 'adelaide',\n",
              " 'adelawale',\n",
              " 'adele',\n",
              " 'adelightful',\n",
              " 'adelin',\n",
              " 'adell',\n",
              " 'adelle',\n",
              " 'adelphia',\n",
              " 'ademir',\n",
              " 'aden',\n",
              " 'adenine',\n",
              " 'adenoid',\n",
              " 'adentro',\n",
              " 'adeosun',\n",
              " 'adept',\n",
              " 'adeptly',\n",
              " 'adequacy',\n",
              " 'adequate',\n",
              " 'adequately',\n",
              " 'adequtely',\n",
              " 'adevent',\n",
              " 'adeventures',\n",
              " 'adgth',\n",
              " 'adhd',\n",
              " 'adherance',\n",
              " 'adhere',\n",
              " 'adhered',\n",
              " 'adherence',\n",
              " 'adherent',\n",
              " 'adheres',\n",
              " 'adhering',\n",
              " 'adhesive',\n",
              " 'adhura',\n",
              " 'adi',\n",
              " 'adibah',\n",
              " 'adidas',\n",
              " 'adiego',\n",
              " 'adien',\n",
              " 'adieu',\n",
              " 'adios',\n",
              " 'aditi',\n",
              " 'aditiya',\n",
              " 'aditya',\n",
              " 'adj',\n",
              " 'adjacent',\n",
              " 'adjani',\n",
              " 'adjective',\n",
              " 'adjl',\n",
              " 'adjoining',\n",
              " 'adjoins',\n",
              " 'adjournment',\n",
              " 'adjunct',\n",
              " 'adjurdubois',\n",
              " 'adjust',\n",
              " 'adjusted',\n",
              " 'adjuster',\n",
              " 'adjustin',\n",
              " 'adjusting',\n",
              " 'adjustment',\n",
              " 'adjusts',\n",
              " 'adjutant',\n",
              " 'adkins',\n",
              " 'adl',\n",
              " 'adlai',\n",
              " 'adle',\n",
              " 'adleman',\n",
              " 'adler',\n",
              " 'adlibing',\n",
              " 'adm',\n",
              " 'adma',\n",
              " 'adman',\n",
              " 'admarible',\n",
              " 'admin',\n",
              " 'administer',\n",
              " 'administered',\n",
              " 'administering',\n",
              " 'administers',\n",
              " 'administration',\n",
              " 'administrative',\n",
              " 'administrator',\n",
              " 'admins',\n",
              " 'adminsitrative',\n",
              " 'admira',\n",
              " 'admirable',\n",
              " 'admirably',\n",
              " 'admiral',\n",
              " 'admiralty',\n",
              " 'admiration',\n",
              " 'admire',\n",
              " 'admired',\n",
              " 'admirees',\n",
              " 'admirer',\n",
              " 'admires',\n",
              " 'admiring',\n",
              " 'admiringly',\n",
              " 'admissible',\n",
              " 'admission',\n",
              " 'admit',\n",
              " 'admite',\n",
              " 'admitedly',\n",
              " 'admits',\n",
              " 'admitt',\n",
              " 'admittably',\n",
              " 'admittadly',\n",
              " 'admittance',\n",
              " 'admitted',\n",
              " 'admittedly',\n",
              " 'admitting',\n",
              " 'admittingly',\n",
              " 'admixture',\n",
              " 'admonish',\n",
              " 'admonished',\n",
              " 'admonishes',\n",
              " 'admonishing',\n",
              " 'admonition',\n",
              " 'adnan',\n",
              " 'adnausem',\n",
              " 'adness',\n",
              " 'adnum',\n",
              " 'ado',\n",
              " 'adobe',\n",
              " 'adolescence',\n",
              " 'adolescent',\n",
              " 'adolf',\n",
              " 'adolfo',\n",
              " 'adolph',\n",
              " 'adolphe',\n",
              " 'adolphs',\n",
              " 'adon',\n",
              " 'adone',\n",
              " 'adoni',\n",
              " 'adonijah',\n",
              " 'adonis',\n",
              " 'adoor',\n",
              " 'adopt',\n",
              " 'adopted',\n",
              " 'adoptee',\n",
              " 'adopting',\n",
              " 'adoption',\n",
              " 'adoptive',\n",
              " 'adopts',\n",
              " 'ador',\n",
              " 'adorable',\n",
              " 'adorably',\n",
              " 'adoration',\n",
              " 'adorble',\n",
              " 'adore',\n",
              " 'adored',\n",
              " 'adoree',\n",
              " 'adores',\n",
              " 'adorf',\n",
              " 'adorible',\n",
              " 'adoring',\n",
              " 'adoringly',\n",
              " 'adorn',\n",
              " 'adorned',\n",
              " 'adorning',\n",
              " 'adorns',\n",
              " 'adotped',\n",
              " 'adp',\n",
              " 'adr',\n",
              " 'adrenalin',\n",
              " 'adrenaline',\n",
              " 'adreno',\n",
              " 'adreon',\n",
              " 'adressed',\n",
              " 'adri',\n",
              " 'adrian',\n",
              " 'adriana',\n",
              " 'adrianne',\n",
              " 'adriano',\n",
              " 'adriatic',\n",
              " 'adrien',\n",
              " 'adrienne',\n",
              " 'adriensen',\n",
              " 'adrift',\n",
              " 'adroit',\n",
              " 'adroitly',\n",
              " 'adsbreaks',\n",
              " 'adt',\n",
              " 'aduh',\n",
              " 'adulating',\n",
              " 'adulation',\n",
              " 'adult',\n",
              " 'adulterate',\n",
              " 'adulterated',\n",
              " 'adulterating',\n",
              " 'adulterer',\n",
              " 'adulteress',\n",
              " 'adulterous',\n",
              " 'adultery',\n",
              " 'adulthood',\n",
              " 'adultry',\n",
              " 'adultsituations',\n",
              " 'adv',\n",
              " 'advance',\n",
              " 'advanced',\n",
              " 'advancement',\n",
              " 'advancing',\n",
              " 'advani',\n",
              " 'advantage',\n",
              " 'advantaged',\n",
              " 'advantageous',\n",
              " 'advantageously',\n",
              " 'advent',\n",
              " 'adventist',\n",
              " 'adventure',\n",
              " 'adventured',\n",
              " 'adventurer',\n",
              " 'adventuresome',\n",
              " 'adventuring',\n",
              " 'adventurios',\n",
              " 'adventurous',\n",
              " 'adventurously',\n",
              " 'adventurousness',\n",
              " 'adversarial',\n",
              " 'adversary',\n",
              " 'adverse',\n",
              " 'adversely',\n",
              " 'adversion',\n",
              " 'adversity',\n",
              " 'advert',\n",
              " 'adverterous',\n",
              " 'advertise',\n",
              " 'advertised',\n",
              " 'advertisement',\n",
              " 'advertisementsfor',\n",
              " 'advertiser',\n",
              " 'advertises',\n",
              " 'advertising',\n",
              " 'advertized',\n",
              " 'adverture',\n",
              " 'advice',\n",
              " 'advicethose',\n",
              " 'advisable',\n",
              " 'advise',\n",
              " 'advised',\n",
              " 'advisedly',\n",
              " 'advisement',\n",
              " 'adviser',\n",
              " 'advises',\n",
              " 'advising',\n",
              " 'advisor',\n",
              " 'advisory',\n",
              " 'advocacy',\n",
              " 'advocate',\n",
              " 'advocated',\n",
              " 'advocating',\n",
              " 'ae',\n",
              " 'aeddie',\n",
              " 'aegean',\n",
              " 'aegerter',\n",
              " 'aelita',\n",
              " 'aeneas',\n",
              " 'aeon',\n",
              " 'aerial',\n",
              " 'aerialist',\n",
              " 'aeris',\n",
              " 'aerith',\n",
              " 'aero',\n",
              " 'aerobatics',\n",
              " 'aerobic',\n",
              " 'aerobicide',\n",
              " 'aerobics',\n",
              " 'aerodrome',\n",
              " 'aerodynamic',\n",
              " 'aerodynamics',\n",
              " 'aeronautical',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1nY_2QnJ6vA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c3ad3728-9710-4cc4-f230-0c62ca245236"
      },
      "source": [
        "features_names = [features_names[i] for i in ch2.get_support(indices=True)]\n",
        "features_names = np.asarray(features_names)\n",
        "features_names[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'aa'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDFO4fdNKtba",
        "colab_type": "text"
      },
      "source": [
        "Kita akan fit data ke dalam model Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2OJTuYfKZ7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7z7Qzw3K8Dc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multi_nb_clf = MultinomialNB()\n",
        "multi_nb_clf.fit(tfidf_nb_multi_train, train_data_label)\n",
        "predict_multi_nb = multi_nb_clf.predict(tfidf_nb_multi_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm6S2xfYLhjp",
        "colab_type": "text"
      },
      "source": [
        "Kita akan lihat performanya"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBat8EiyLfO9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "512317ba-bfed-4307-80bd-a7dd44b1f493"
      },
      "source": [
        "print('Classification Report for Multinomial NB Using Tf-Idf Vectorizer: \\n\\n', classification_report(test_data_label, predict_multi_nb, target_names=['Negative', 'Positive']))\n",
        "print('Confusion Matrix for Multinomial NB Using Tf-Idf Vectorizer: \\n', confusion_matrix(test_data_label, predict_multi_nb))\n",
        "print()\n",
        "print('Model Accuracy for Multinomial NB Using Tf-Idf Vectorizer: ', accuracy_score(test_data_label, predict_multi_nb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report for Multinomial NB Using Tf-Idf Vectorizer: \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.85      0.88      0.87      6157\n",
            "    Positive       0.88      0.85      0.87      6343\n",
            "\n",
            "    accuracy                           0.87     12500\n",
            "   macro avg       0.87      0.87      0.87     12500\n",
            "weighted avg       0.87      0.87      0.87     12500\n",
            "\n",
            "Confusion Matrix for Multinomial NB Using Tf-Idf Vectorizer: \n",
            " [[5424  733]\n",
            " [ 938 5405]]\n",
            "\n",
            "Model Accuracy for Multinomial NB Using Tf-Idf Vectorizer:  0.86632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayz-36NOOOMN",
        "colab_type": "text"
      },
      "source": [
        "##### **Fifth Model : Multinomial Naive Bayes (Count Vectorizer with binary = False)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RvVHNoQMcYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multi_nb_count_clf = MultinomialNB()\n",
        "multi_nb_count_clf.fit(count_multi_nb_train, train_data_label)\n",
        "predict_multi_nb_count = multi_nb_count_clf.predict(count_multi_nb_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9Fi3noWPdxQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "49cb2b38-eb70-4869-b7ae-30062d3d91a7"
      },
      "source": [
        "print('Classification Report for Multinomial Naive Bayes Using Count Vectorizer with binary = False: \\n\\n', classification_report(test_data_label, predict_multi_nb_count, target_names=['Negative', 'Positive']))\n",
        "print('Confusion Matrix for Multinomial Naive Bayes Using Count Vectorizer with binary = False: \\n', confusion_matrix(test_data_label, predict_multi_nb_count))\n",
        "print()\n",
        "print('Model Accuracy for Multinomial Naive Bayes Using Count Vectorizer with binary = False: ', accuracy_score(test_data_label, predict_multi_nb_count))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report for Multinomial Naive Bayes Using Count Vectorizer with binary = False: \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.88      0.89      0.89      6157\n",
            "    Positive       0.90      0.88      0.89      6343\n",
            "\n",
            "    accuracy                           0.89     12500\n",
            "   macro avg       0.89      0.89      0.89     12500\n",
            "weighted avg       0.89      0.89      0.89     12500\n",
            "\n",
            "Confusion Matrix for Multinomial Naive Bayes Using Count Vectorizer with binary = False: \n",
            " [[5503  654]\n",
            " [ 752 5591]]\n",
            "\n",
            "Model Accuracy for Multinomial Naive Bayes Using Count Vectorizer with binary = False:  0.88752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT8D1x0aREcp",
        "colab_type": "text"
      },
      "source": [
        "##### **Sixth Model : Multinomial Naive Bayes (Count Vectorizer with binary = True)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbZQ_nmFQ19q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multi_nb_count_true_clf = MultinomialNB()\n",
        "multi_nb_count_true_clf.fit(count_multi_nb_true_train, train_data_label)\n",
        "predict_multi_nb_count_true = multi_nb_count_true_clf.predict(count_multi_nb_true_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCQ5P674RwyY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "5be4d032-034d-4445-bd6a-0822e51dc58e"
      },
      "source": [
        "print('Classification Report for Multinomial Naive Bayes Using Count Vectorizer with binary = True: \\n\\n', classification_report(test_data_label, predict_multi_nb_count_true, target_names=['Negative', 'Positive']))\n",
        "print('Confusion Matrix for Multinomial Naive Bayes Using Count Vectorizer with binary = True: \\n', confusion_matrix(test_data_label, predict_multi_nb_count_true))\n",
        "print()\n",
        "print('Model Accuracy for Multinomial Naive Bayes Using Count Vectorizer with binary = True: ', accuracy_score(test_data_label, predict_multi_nb_count_true))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report for Multinomial Naive Bayes Using Count Vectorizer with binary = True: \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.88      0.90      0.89      6157\n",
            "    Positive       0.90      0.88      0.89      6343\n",
            "\n",
            "    accuracy                           0.89     12500\n",
            "   macro avg       0.89      0.89      0.89     12500\n",
            "weighted avg       0.89      0.89      0.89     12500\n",
            "\n",
            "Confusion Matrix for Multinomial Naive Bayes Using Count Vectorizer with binary = True: \n",
            " [[5572  585]\n",
            " [ 777 5566]]\n",
            "\n",
            "Model Accuracy for Multinomial Naive Bayes Using Count Vectorizer with binary = True:  0.89104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swYS4T6rR83Z",
        "colab_type": "text"
      },
      "source": [
        "Nilai Akurasi Tertinggi didapat dengan model **Multinomial Naive Bayes dengan Count Vectorizer memakai binary = True** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW64G32FTKlq",
        "colab_type": "text"
      },
      "source": [
        "Membandingkan dua model terbaik"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ63DphjR6zl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "49a3c923-3c73-4363-cb17-2ecef182485f"
      },
      "source": [
        "print('Nilai Akurasi Linear SVC dengan Tf-Idf Vectorizer adalah                                   : ', accuracy_score(test_data_label, predict_svc))\n",
        "print('Nilai Akurasi Multinomial Naive Bayes dengan Count Vectorizer memakai binary = True adalah : ', accuracy_score(test_data_label, predict_multi_nb_count_true))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nilai Akurasi Linear SVC dengan Tf-Idf Vectorizer adalah                                   :  0.90288\n",
            "Nilai Akurasi Multinomial Naive Bayes dengan Count Vectorizer memakai binary = True adalah :  0.89104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIGD7EpETSLR",
        "colab_type": "text"
      },
      "source": [
        "Model Linear SVC dengan Tf-Idf Vectorizer memberikan nilai akurasi terbaik, sehingga kita akan menjadikannya sebagai model untuk dataset ini. Berikutnya kita akan melihat outcomenya"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBEKKJV0onPG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5ea5f74a-fa37-49c4-fc47-08d901cd0924"
      },
      "source": [
        "dataset_predict = dataset_test.copy()\n",
        "dataset_predict = pd.DataFrame(dataset_predict)\n",
        "dataset_predict.columns = ['review']\n",
        "dataset_predict = dataset_predict.reset_index()\n",
        "dataset_predict.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>33553</td>\n",
              "      <td>I really liked this Summerslam due to the look...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9427</td>\n",
              "      <td>Not many television shows appeal to quite as m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>199</td>\n",
              "      <td>The film quickly gets to a major chase scene w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12447</td>\n",
              "      <td>Jane Austen would definitely approve of this o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>39489</td>\n",
              "      <td>Expectations were somewhat high for me when I ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                                             review\n",
              "0  33553  I really liked this Summerslam due to the look...\n",
              "1   9427  Not many television shows appeal to quite as m...\n",
              "2    199  The film quickly gets to a major chase scene w...\n",
              "3  12447  Jane Austen would definitely approve of this o...\n",
              "4  39489  Expectations were somewhat high for me when I ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVryLFfqTAEa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a28ae221-8445-4fb5-c798-3718d56f7b26"
      },
      "source": [
        "dataset_predict = dataset_predict.drop(['index'], axis=1)\n",
        "dataset_predict.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I really liked this Summerslam due to the look...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not many television shows appeal to quite as m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The film quickly gets to a major chase scene w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Jane Austen would definitely approve of this o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Expectations were somewhat high for me when I ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review\n",
              "0  I really liked this Summerslam due to the look...\n",
              "1  Not many television shows appeal to quite as m...\n",
              "2  The film quickly gets to a major chase scene w...\n",
              "3  Jane Austen would definitely approve of this o...\n",
              "4  Expectations were somewhat high for me when I ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh1as_V3pUOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_actual_label = test_data_label.copy()\n",
        "test_actual_label = pd.DataFrame(test_actual_label)\n",
        "test_actual_label.columns = ['sentiment']\n",
        "test_actual_label['sentiment'] = test_actual_label['sentiment'].replace({1 : 'positive', 0 : 'negative'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FNrV8JTpu9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predicted_label = predict_svc.copy()\n",
        "test_predicted_label = pd.DataFrame(test_predicted_label)\n",
        "test_predicted_label.columns = ['predicted_sentiment']\n",
        "test_predicted_label['predicted_sentiment'] = test_predicted_label['predicted_sentiment'].replace({1 : 'positive', 0 : 'negative'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS_Yj0gBqKdk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4c9286f4-dc1a-4aff-fd11-9a7781b56092"
      },
      "source": [
        "test_result = pd.concat([dataset_predict, test_actual_label, test_predicted_label], axis=1)\n",
        "test_result.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>predicted_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I really liked this Summerslam due to the look...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not many television shows appeal to quite as m...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The film quickly gets to a major chase scene w...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Jane Austen would definitely approve of this o...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Expectations were somewhat high for me when I ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ... predicted_sentiment\n",
              "0  I really liked this Summerslam due to the look...  ...            negative\n",
              "1  Not many television shows appeal to quite as m...  ...            positive\n",
              "2  The film quickly gets to a major chase scene w...  ...            negative\n",
              "3  Jane Austen would definitely approve of this o...  ...            positive\n",
              "4  Expectations were somewhat high for me when I ...  ...            negative\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDxQDzpUxe0A",
        "colab_type": "text"
      },
      "source": [
        "Berikut dapat dilihat hasil prediksi klasifikasi sentimen memakai Model Linear SVC yang divectorize dengan Tf-Idf Vectorizer. Berdasarkan nilai akurasi, sekitar 90% dari hasil real data bisa diprediksi dengan benar memakai model Linear SVC ini."
      ]
    }
  ]
}